<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kubernetes架构介绍]]></title>
    <url>%2F2019%2F05%2F23%2Fkubernetes%2FKubernetes%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Kubernetes集群分为两部分（官网介绍）： 控制平面（Master components provide the cluster’s control plane） etcd分布式持久化存储 API服务器（kube-apiserver） 调度器（kube-scheduler） 控制器管理器（kube-controller-manager） 工作节点（Node components run on every node） kubelet kube-proxy 容器运行时（Container Runtime） 附加组件： Kubernetes DNS服务器 Web UI (Dashboard) Ingress Controller 容器集群监控（Heapster） 容器网络接口插件 组件关系图： etcdKubernetes所创建的对象（Pod、ReplicationController、Service、Secret等）需要以持久化方式存储到某个地方，这样它们在API服务器重启或者失败的时候才不会丢失，因此引入了etcd etcd是一个响应快、分布式、一致的kv存储，可以运行多个etcd实例来获取高可用性和更好的性能，etcd 是Kubernetes存储集群状态和元数据的唯一的地方 唯一能直接和 etcd 通信的是API服务器，所有其他组件通过API服务器间接地读取、写入数据到 etcd，这带来一些好处： 增强乐观锁系统、验证系统的健壮性 通过把实际存储机制从其他组件抽离，未来替换起来也更容易 etcd 使用 RAFT 一致性算法（要求集群大部分节点参与才能进行到下一个状态），确保在任何时间点，每个节点的状态要么是大部分节点的当前状态，要么是之前确认过的状态（部署基数实例数） api serverapi server 作为中心组件，其他组件或者客户端（如kubectl）都会去调用它（以Restful API形式）： 通过认证插件认证客户端 API 服务器会轮流调用这些插件，直到有一个能确认是谁发送了该请求，这是通过检查HTTP请求实现的 通过授权插件授权客户端 它们的作用是决定认证的用户是否可以对请求资源执行请求操作 通过准入控制插件验证AND/OR修改资源请求 如果请求尝试创建、修改或者删除一个资源，请求需要经过准入控制插件的验证，服务器会配置多个准入控制插件，这些插件会因为各种原因修改资源，可能会初始化资源定义中漏配的字段为默认值甚至重写它们，插件甚至会去修改并不在请求中的相关资源，同时也会因为某些原因拒绝一个请求。资源需要经过所有准入控制插件的验证（读取数据不会做准入控制的验证）准入控制插件包括：AlwaysPullImages、ServiceAccount、NamespaceLifecycle等，具体查看官网 验证资源以及持久化存储 其它客户端通过创建到 api server 的 HTTP 连接来监听变更，每当更新对象，api server会将新对象发送给监听了该对象的客户端（比如Controller、Kubectl等等），客户端接收到后执行相应任务 调度器（schedule）通常我们不会去指定pod应该运行在哪个集群节点上，而是交给调度器来完成，调度器不会命令选中的节点（或者节点上的Kubelet）去运行pod，而是通过api server更新pod的定义，然后通知kubelet去创建并且运行pod的容器 调度器最为重要的是调度算法，找到pod最优节点，这个其它篇幅中说明 在集群中可以运行多个调度器，在pod中可以通过设置 schedulerName 属性来指定调度器，未设置由默认调度器调度（default-scheduler） 控制器（controller）Kubernetes中主要有以下控制器： Replication管理器 (ReplicationController资源的管理器) ReplicaSet、 DaemonSet 以及 Job 控制器 Deployment控制器 StatefulSet控制器 Node控制器 Service控制器 Endpoints控制器 Namespace控制器 PersistentVolume控制器 … 总的来说，控制器执行一个“调和“循环，将实际状态调整为期望状态(在资源spec部分定义)，然后将新的实际状态写入资源的 status 部分。 控制器利用监听机制来订阅变更，但是由于使用监听机制并不保证控制器不会漏掉事件， 所以仍然需要定期执行重列举操作来确保不会丢掉什么 KubeletKubelet 运行在工作节点上，负责所有运行在工作节点上的组件： 在api server中创建一个node资源来注册该节点 持续监控api server是否把该节点分配给pod，启动pod 持续监控运行的容器，向api server报告它们的状态、事件和资源消耗 它也是运行容器存活探针的组件，当探针报错时它会重启容器 当pod从api server删除时，Kubelet终止容器，并通知api server该pod已经被终止 Kubelet也可以基于本地指定目录下的pod清淡来运行pod kube-proxy运行在每个节点上，监听 api server 中服务对象的变化，再通过管理 iptables 来实现网络的转发 支持三种模式： userspace（k8s v1.2 后就已经淘汰） iptables（默认方式） ipvs（需要安装ipvsadm、ipset 工具包和加载 ip_vs 内核模块） 参考博客：Kube-Proxy简述]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes组件简单介绍-Storage]]></title>
    <url>%2F2019%2F05%2F21%2Fkubernetes%2FKubernetes%E7%BB%84%E4%BB%B6%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D-Storage%2F</url>
    <content type="text"><![CDATA[卷（Volumes）官方文档 卷是pod的一个组成部分，定义在pod中，不是独立的kubernetes对象 在官网可以看到有很多Volume类型，这里只介绍其中的几种，其它可以查看官网 emptyDir特点： 卷从一个空目录开始，运行在pod内的应用程序可以读写 卷的生命周期和pod的生命周期相关联，当pod删除时，卷的内容就会丢失 12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container # 名为 cache-volume 的卷挂载在容器的 /cache 中 volumeMounts: - mountPath: /cache name: cache-volume volumes: # 定义一个名为 cache-volume 的 emptyDir 卷 - name: cache-volume emptyDir: &#123;&#125; # 指定介质，使用内存存储 # emptyDir: # medium: Memory hostPath大多数pod应该忽略它们的主机节点，因此不应该访问节点文件系统上的文件，但是一些系统级别的pod（通常由DaemonSet管理）需要读取节点的文件 hostPath是一种持久性存储，不会因为pod的删除而丢失内容 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory GCE如果是在GCE（Google Kubernetes Engine）中运行的，那么可以使用GCE持久磁盘作为底层存储机制 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume # This GCE PD must already exist. gcePersistentDisk: pdName: my-data-disk # 文件系统类型 fsType: ext4 持久卷（PV）和持久卷声明（PVC）官方文档 为了使应用能够正常请求存储资源，同时避免处理基础设施细节，引入了两个新的资源：持久卷（PV）和持久卷声明（PVC） 持久卷由集群管理员提供，并被pod通过持久卷声明来消费： 创建持久卷（PV）： 123456789101112131415161718apiVersion: v1kind: PersistentVolumemetadata: name: pv0003spec: capacity: # 定义大小 storage: 5Gi accessModes: # 单个客户端挂载为读写模式 - ReadWriteOnce # 多个客户端挂载为只读模式 - ReadOnlyMany # 回收策略[Retain, Recycle, Delete] persistentVolumeReclaimPolicy: Recycle gcePersistentDisk: pdName: my-data-disk fsType: ext4 持久卷不属于任何命名空间，它跟节点一样是集群层面的资源： 创建持久卷声明（PVC）： 123456789101112131415apiVersion: v1kind: PersistentVolumeClaimmetadata: name: myclaimspec: accessModes: - ReadWriteOnce resources: requests: storage: 8Gi selector: matchLabels: release: "stable" matchExpressions: - &#123;key: environment, operator: In, values: [dev]&#125; Pod配置： 123456789101112131415apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: myfrontend image: nginx volumeMounts: - mountPath: "/var/www/html" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim 相关文章： PV、PVC、StorageClass，这些到底在说啥？ PV、PVC体系是不是多此一举？从本地持久化卷谈起]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes组件简单介绍-Service]]></title>
    <url>%2F2019%2F05%2F21%2Fkubernetes%2FKubernetes%E7%BB%84%E4%BB%B6%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D-Service%2F</url>
    <content type="text"><![CDATA[服务（Service）官方文档 由于一下原因，我们需要引入Service： pod是短暂的，它们随时会启动或者关闭 Kubernetes在pod启动前会给已经调度到节点上的pod分配IP地址，因此客户端不能提前知道提供服务的pod的IP地址 水平伸缩意味着多个pod可能会提供相同的服务，每个pod都有自己的IP YAML描述文件： 12345678910111213141516171819202122232425apiVersion: v1kind: Servicemetadata: name: my-servicespec: # ClientIP：特定客户端产生的所有请求每次都指向同一个pod # None：default sessionAffinity: ClientIP # 使得服务成为headless的 # clusterIP: None # 通过标签选择器匹配pod selector: app: MyApp ports: # TCP（default） - name: http protocol: TCP # Service port port: 80 # 转发到的容器端口 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 8443 pod中可以使用端口命名，所以在Service中配置 targetPort 可以使用pod端口名称，方便端口维护 我们也可以不使用标签选择器，而使用 ExternalName 来连接外部服务： 1234567...spec: type: ExternalName ExternalName: someapi.somcompany.com ports: - port: 80... ExternalName 服务仅在DNS级别实施（为Service创建了简单的CNAME DNS） endpoint使用命令 kubectl describe svc &lt;service-name&gt; 可以看到 Endpoint 信息： 123...Endpoints: 10.108.1.4:8080,10.108.2.5:8080... 当service中定义了pod标签选择器，选择器用于构建IP和端口列表，存储在Endpoint资源中，如果service没有定义寻择期则不会创建Endpoint，我们可以手动创建： 1234567891011apiVersion: v1kind: Endpointmetadata: # Endpoint名称必须和Service的名称相匹配 name: my-servicesubsets: - addresses: - ip: 11.11.11.11 - ip: 22.22.22.22 ports: - port: 80 暴露服务向外部公开服务 NodePort每个集群节点都会在节点上打开一个端口，并将在该端口上接收到的流量重定向到基础服务，该服务仅在内部集群IP和端口上才可访问，但也可以通过所有节点上的专用端口访问 1234567891011121314apiVersion: v1kind: Servicemetadata: name: my-servicespec: # 设置为 NodePort 服务类型 type: NodePort selector: app: MyApp ports: - port: 80 targetPort: 8080 # 通过集群节点的30123端口可以访问该服务，如果不指定会选择一个随机端口 nodePort: 30123 这时EXTERNAL-IP显示，我们可以通过 EXTERNAL-IP:30123 或者 CLUSTER-IP:30123 来访问服务 123kubectl get svc my-serviceNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEmy-service 10.111.254.223 &lt;nodes&gt; 80:30123/TCP 2m LoadBalancer123456789101112apiVersion: v1kind: Servicemetadata: name: my-servicespec: # 设置为 LoadBalancer 服务类型 type: LoadBalancer selector: app: MyApp ports: - port: 80 targetPort: 8080 123kubectl get svc my-serviceNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGEmy-service 10.111.254.223 130.211.53.173 80:30123/TCP 2m 可以通过负载均衡IP：130.211.53.173访问服务 Ingress官方文档 相比与 LoadBalancer 服务都需要自己的负载均衡器以及独有的公有IP地址，Ingress 只需要一个公网IP就能为许多服务提供访问 12345678910111213141516171819202122232425262728apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: test-ingressspec: # TLS配置 tls: - hosts: - test.example.com # 从 tls-secret 中获得私钥和证书 secretName: tls-secret rules: # 将该域名映射到服务 - host: test.example.com http: paths: # 将该路径的请求发送到test服务的80端口 - path: /testpath backend: serviceName: test servicePort: 80 - host: test2.example.com http: paths: - path: /testpath2 backend: serviceName: test2 servicePort: 80 Ingress执行流程：]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes组件简单介绍-Pod、Controller]]></title>
    <url>%2F2019%2F05%2F17%2Fkubernetes%2FKubernetes%E7%BB%84%E4%BB%B6%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D-Pod%E3%80%81Controller%2F</url>
    <content type="text"><![CDATA[Pod官方文档 pod是一组并置的容器（由一个或多个组成），代表了 Kubernetes 中的基本构建模块，在实际应用中我们不会单独部署容器，都是针对一组pod的容器进行部署和操作 重要概念： 标签：使用标签进行pod的分组（通过标签选择器列出 kubectl get po -l key=value） 注解：与标签不同的是，注解可以容纳更多内容，主要用于工具使用，没有标签那样的选择器 命名空间：对资源进行分组 存活探针和就绪探针 YAML描述文件创建pod： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129# 必选，版本号，例如v1apiVersion: v1# 必选，Podkind: Pod# 必选，元数据metadata: # 必选，Pod名称 name: string # 必选，Pod所属的命名空间 namespace: string # 自定义标签 labels: - name: string # 自定义注释列表 annotations: - name: string# 必选，Pod中容器的详细定义spec: # 必选，Pod中容器列表 containers: # 必选，容器名称 - name: string # 必选，容器的镜像名称 image: string # 获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像 imagePullPolicy: [Always | Never | IfNotPresent] # 容器的启动命令列表，如不指定，使用打包时使用的启动命令 command: [string] # 容器的启动命令参数列表 args: [string] # 容器的工作目录 workingDir: string # 挂载到容器内部的存储卷配置 volumeMounts: # 引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 - name: string # 存储卷在容器内mount的绝对路径，应少于512字符 mountPath: string # 是否为只读模式 readOnly: boolean # 需要暴露的端口库号列表 ports: # 端口号名称 - name: string # 容器需要监听的端口号 containerPort: int # 容器所在主机需要监听的端口号，默认与Container相同 hostPort: int # 端口协议，支持TCP和UDP，默认TCP protocol: string # 容器运行前需设置的环境变量列表 env: # 环境变量名称 - name: string # 环境变量的值 value: string # 资源限制和请求的设置 resources: # 资源限制的设置 limits: # cpu的限制，单位为core数，将用于docker run --cpu-shares参数 cpu: string # 内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 memory: string # 资源请求的设置 requests: # cpu请求，容器启动的初始可用数量 cpu: string # 内存请求，容器启动的初始可用数量 memory: string # 对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 livenessProbe: # 对Pod容器内检查方式设置为exec方式 exec: # exec方式需要制定的命令或脚本 command: [string] # 对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port httpGet: path: string port: number host: string scheme: string HttpHeaders: - name: string value: string # 对Pod内个容器健康检查方式设置为tcpSocket方式 tcpSocket: port: number # 容器启动完成后首次探测的时间，单位为秒 initialDelaySeconds: 0 # 对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 timeoutSeconds: 0 # 对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 periodSeconds: 0 successThreshold: 0 failureThreshold: 0 securityContext: privileged: false # Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod restartPolicy: [Always | Never | OnFailure] # 设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 nodeSelector: obeject # Pull镜像时使用的secret名称，以key：secretkey格式指定 imagePullSecrets: - name: string # 是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 hostNetwork: false # 在该pod上定义共享存储卷列表 volumes: # 共享存储卷名称 （volumes类型有很多种） - name: string # 类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 emptyDir: &#123;&#125; # 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 hostPath: string # Pod所在宿主机的目录，将被用于同期中mount的目录 path: string # 类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 secret: scretname: string items: - key: string path: string # 类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 configMap: name: string items: - key: string path: string 控制器（Controllers）ReplicationController官方文档 确保它的pod始终保持运行状态，如果pod因任何原因小时，ReplicationController会注意到缺少的pod并创建替代pod，原有pod将完全丢失 YAML描述文件： 123456789101112131415161718192021222324apiVersion: v1# ReplicationController类型kind: ReplicationControllermetadata: # ReplicationController名称 name: nginxspec: # pod实例的目标数据 replicas: 2 # pod选择器决定了RC的操作对象 selector: app: nginx # 定义pod模板，在这里不需要定义pod名字，就算定义创建的时候也不会采用这个名字而是.metadata.generateName+5位随机数。 template: metadata: # 定义标签，这里必须和selector中定义的KV一样 labels: app: nginx spec: containers: - image: nginx name: nginx ports: - containerPort: 80 注意： 修改RC中的pod模版只会影响后面创建的pod，原有pod不会更改 删除RC时，不会删除对应的pod，原因是RC创建的pod不是RC的组成部分，只是由其进行管理 ReplicaSet官方文档 可以完全替代 ReplicationController，ReplicaSet拥有更强的选择器表达能力 YAML描述文件： 123456789101112131415161718192021apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend template: metadata: labels: tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 使用 matchExpressions 属性重写选择器： 123456selector: matchExpressions: - key: app operator: In values: - tier 操作符： In：Label的值必须与其中一个指定的values匹配 NotIn：Label的值与任何指定的values不匹配 Exists：pod必须包含一个指定名称的标签（值不重要），不需要指定values字段 DoesNotExist：与Exists相反 DaemonSet官方文档 确保在集群的每个节点上运行一个pod（比如日志收集器、资源监控器），如果节点下线，DaemonSet不会在其它地方重建pod，但是当一个新节点加入时，DaemonSet会立刻部署一个新的pod实例在新节点上 YAML描述文件： 1234567891011121314151617181920212223242526272829303132333435apiVersion: apps/v1kind: DaemonSetmetadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-loggingspec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: nodeSelector: # 节点选择器，会选择有disk=ssd标签的节点 disk: ssd containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 DeploymentDeployment 是一种更高阶资源，用于部署应用并以声明的方式升级应用，而不是通过 ReplicationController 或 ReplicaSet 进行部署（更底层） Deployment 由 ReplicaSet 组成，并由它接管 Deployment 的 pod YAML描述文件： 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 # 指定新创建的pod至少要成功运行多久之后，才能将其视为可用，需要容器配置就绪探针 # 当所有容器的就绪探针返回成功时，pod就被标记为就绪状态 minReadySeconds: 10 # 设置升级的超时时间 progressDeadlineSeconds: 60 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 # 定义就绪探针 readlinessProbe: periodSeconds: 1 httpGet: path: / port: 8080 strategy: # 升级策略：[RollingUpdate(Default), Recreate] type: RollingUpdate RollingUpdate: maxSurge: 1 maxUnavailable: 0 升级策略： RollingUpdate（默认）：滚动更新 maxSurge 决定了 Deployment 配置中期望的副本数之外，最多允许超出的pod实例的数量，默认值为25%（也可以是绝对值，比如最多多处一个或两个pod） maxUnavailable 决定了在滚动升级期间，相对于期望副本数能够允许有多少pod实例处于不可用状态，默认值为25% Recreate：一次性删除所有旧pod，创建新的pod JobJob（run to completion）官方文档 运行完成工作后即终止任务 由Job管理的pod会一直被重新安排，直到它们成功完成任务 YAML描述文件： 123456789101112131415161718192021apiVersion: batch/v1kind: Jobmetadata: name: pispec: template: spec: containers: - name: pi image: perl command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"] # 重启策略：[OnFailure, Never, Always(Default)] restartPolicy: Never # 配置job在标记为失败之前可以重试的次数，默认为6 backoffLimit: 4 # 一个job运行多次，将顺序运行5个pod，如果其中一个pod发生故障，job会创建一个新的pod，所以job总共可以创建5个以上pod competions: 5 # 最多2个pod可以平行运行 parallelism: 2 # 限制pod的时间，如果pod运行时间超过该时间，系统将尝试终止pod，并将job标记为失败 activeDeadlineSeconds: 50 Corn Job官方文档 特定的时间运行或者在指定的时间间隔内重复运行 12345678910111213141516171819202122apiVersion: batch/v1kind: CronJobmetadata: name: pispec: # 每天在每小时0，15，30，45分钟运行 schedule: "0,15,30,45 * * * *" # pod最迟必须在预定时间后15秒开始运行，如果没有运行则任务将不会运行，并显示为Failed startingDeadlineSeconds: 15 jobTemplate: spec: template: metadata: labels: app: corn-job spec: containers: - name: pi image: perl command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"] # 重启策略：[OnFailure, Never, Always(Default)] restartPolicy: Never]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch桶聚合]]></title>
    <url>%2F2019%2F05%2F06%2Felasticsearch%2F%E8%81%9A%E5%90%88%E5%88%86%E6%9E%90%2FElasticSearch%E6%A1%B6%E8%81%9A%E5%90%88%2F</url>
    <content type="text"><![CDATA[Bucket 可以理解为一个桶，它会遍历文档中的内容，凡是符合某一要求的就放入一个桶中（类似于SQL中的group by） Terms Aggregation用于分组聚合 根据 language 字段对 books 索引中的文档进行分组，统计各编程语言的书的数量 12345678POST books/_search?size=0&#123; "aggs" : &#123; "per_count" : &#123; "items" : &#123;"feild" : "language"&#125; &#125; &#125;&#125; 结果如下： 12345678910111213&#123; "aggregations" : &#123; "per_count" : &#123; "doc_count_error_upper_bound" : 0, "sum_other_doc_count" : 0, "buckets" : [ &#123;"key" : "java", "doc_count" : 2&#125;, &#123;"key" : "python", "doc_count" : 2&#125;, &#123;"key" : "javascript", "doc_count" : 3&#125; ] &#125; &#125;&#125; Filter / Filters AggregationFilter 是过滤器聚合，将符合过滤器条件的文档分别分到一个桶中 Filters 是多过滤器聚合，将符合多个过滤条件的文档分到不通的桶中 123456789101112131415161718POST books/_search?size=0&#123; "aggs" : &#123; "per_avg_price" : &#123; "filters" : &#123; "filters" : [ &#123;"match" : &#123;"title" : "java"&#125;&#125;, &#123;"match" : &#123;"title" : "python"&#125;&#125; ] &#125;, "aggs" : &#123; "avg_price" : &#123; &#123;"avg" : &#123;"feild" : "price"&#125;&#125; &#125; &#125; &#125; &#125;&#125; 结果如下： 12345678910111213141516&#123; "aggregations" : &#123; "per_avg_price" : &#123; "buckets" : [ &#123; "doc_count" : 2, "avg_price" : &#123;"value" : 58.35&#125; &#125;, &#123; "doc_count" : 4, "avg_price" : &#123;"value" : 67.95&#125; &#125; ] &#125; &#125;&#125; Range / Date Range / IP Range AggregationRange 范围聚合，可以用于数字、日期 123456789101112131415POST books/_search?size=0&#123; "aggs" : &#123; "price_ranges" : &#123; "range" : &#123; "field" : "price", "ranges" : &#123; &#123;"to" : 50&#125;, // 小于 50 &#123;"from" : 50, "to" : 80&#125;, // 大于等于50小于80 &#123;"from" : 80&#125; // 大于等于80 &#125; &#125; &#125; &#125;&#125; Date Range 专门用于日期类型的，与 Range 不通在于日期的起止值可以使用数学表达式 123456789101112131415POST books/_search?size=0&#123; "aggs" : &#123; "publish_ranges" : &#123; "date_range" : &#123; "field" : "publish_time", "format" : "yyyy-MM-dd", "ranges" : &#123; &#123;"to" : "now-24M/M"&#125;, // 两年前 &#123;"from" : "now-24M/M"&#125; // 两年前到现在 &#125; &#125; &#125; &#125;&#125; IP Range 用于对IP类型数据范围聚合 1234567891011121314POST ip_test/_search?size=0&#123; "aggs" : &#123; "ip_ranges" : &#123; "ip_range" : &#123; "field" : "ip", "ranges" : &#123; &#123;"to" : "10.0.0.5"&#125;, &#123;"from" : "10.0.0.5"&#125; &#125; &#125; &#125; &#125;&#125; Date Histogram Aggregation时间直方图聚合，常用于按照日期对文档进行统计并绘制条形图 对 books 索引中的图书和出版日期按月做时间直方图聚合 1234567891011POST books/_search?size=0&#123; "aggs" : &#123; "books_over_time" : &#123; "date_histogram" : &#123; "feild" : "publish_time", "interval" : "month" &#125; &#125; &#125;&#125; 结果如下： 1234567891011121314&#123; "aggregations" : &#123; "books_over_time" : &#123; "buckets" : [ &#123; "key_as_string" : "2007-10-01T00:00:00.000Z", "key" : 1191196800000, "doc_count" : 1 &#125;, ... ] &#125; &#125;&#125; Missing Aggregation空值聚合，将文档集中所有缺失字段的文档分到一个桶中 对 books 索引中缺失 price 字段（包含值为null的）的文档进行聚合 12345678POST books/_search?size=0&#123; "aggs" : &#123; "books_without_a_price" : &#123; "missing" : &#123;"feild" : "price"&#125; &#125; &#125;&#125; 结果如下： 1234567&#123; "aggregations" : &#123; "books_without_a_price" : &#123; "doc_count" : 0 &#125; &#125;&#125; Children Aggregation一种特殊的单桶聚合，可以根据父子分档关系进行分桶 Geo Distance Aggregation用于对地理点（geo_point）做范围统计 1234567891011121314151617POST geo/_search?size=0&#123; "aggs" : &#123; "city_from_beijing" : &#123; "geo_distance" : &#123; "feild" : "location", "origin" : "39.90498900,116.40528500", "unit" : "km", "ranges" : [ &#123;"to" : 500&#125;, &#123;"from" : 500, "to" : 1000&#125;, &#123;"from" : 1000&#125;, ] &#125; &#125; &#125;&#125; 结果如下： 12345678910111213141516171819202122232425&#123; "aggregations" : &#123; "city_from_beijing" : &#123; "buckets" : [ &#123; "key" : "*-500.0", "from" : 0, "to" : 500, "doc_count" : 2 &#125;, &#123; "key" : "500.0-1000.0", "from" : 500, "to" : 1000, "doc_count" : 2 &#125;, &#123; "key" : "1000.0-*", "from" : 1000, "doc_count" : 3 &#125; ] &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch指标聚合]]></title>
    <url>%2F2019%2F05%2F06%2Felasticsearch%2F%E8%81%9A%E5%90%88%E5%88%86%E6%9E%90%2FElasticSearch%E6%8C%87%E6%A0%87%E8%81%9A%E5%90%88%2F</url>
    <content type="text"><![CDATA[Max / Min Aggregation用于最大值/最小值统计 123456789GET books/_search&#123; "size" : 0, "aggs" : &#123; "max_price" : &#123; "max" : &#123;"field" : "price"&#125; &#125; &#125;&#125; 结果如下： 12345&#123; "aggregations" : &#123; "max_price" : &#123;"value" : 81.4&#125; &#125;&#125; Avg / Sum Aggregation用于平均值/总和计算统计 123456789GET books/_search&#123; "size" : 0, "aggs" : &#123; "sum_price" : &#123; "sum" : &#123;"field" : "price"&#125; &#125; &#125;&#125; 结果如下： 12345&#123; "aggregations" : &#123; "sum_price" : &#123;"value" : 815&#125; &#125;&#125; Cardinality Aggregation用于基数统计，类似于SQL中的 distinct 操作，去掉集合中重复项，然后统计排重后的集合长度 例如，在 books 索引中对 language 字段进行 cardinality 操作可以统计出编程语言的种类数量： 123456789GET books/_search&#123; "size" : 0, "aggs" : &#123; "all_lan" : &#123; "cardinality" : &#123;"field" : "language"&#125; &#125; &#125;&#125; 结果如下： 12345&#123; "aggregations" : &#123; "all_lan" : &#123;"value" : 3&#125; &#125;&#125; Stats / Extended Stats AggregationStats 用于基本统计，会一次返回count、max、min、avg和sum 5个指标 Extended Stats 比 Stats 多4个指标：平方和（sum_of_squares）、方差（variance）、标准差（std_deviation）、平均值加/减两个标准差的区间（std_deviation_bounds） 123456789GET books/_search&#123; "size" : 0, "aggs" : &#123; "grades_stats" : &#123; "extended_stats" : &#123;"field" : "price"&#125; &#125; &#125;&#125; 结果如下： 123456789101112131415161718&#123; "aggregations" : &#123; "grades_stats" : &#123; "count" : 5, "min" : 46.5, "max" : 81.4, "avg" : 63.2, "sum" : 395, "sum_of_squares" : 21095.46, "variance" : 148.651999999999967, "std_deviation" : 12.19229264740638, "std_deviation_bounds" : &#123; "upper" : 88.16458529481276, "lower" : 39.41541470518475 &#125; &#125; &#125;&#125; Percentiles Aggregation用于百分位统计，百分位数是一个统计学术语，如果将一组数据从大到小排序，并计算相应的累计百分位，某一百分位所对应数据的值就称为这一百分位的百分位数 123456789GET books/_search&#123; "size" : 0, "aggs" : &#123; "book_price" : &#123; "percentiles" : &#123;"field" : "price"&#125; &#125; &#125;&#125; 结果如下： 123456789101112131415&#123; "aggregations" : &#123; "book_price" : &#123; "values" : &#123; "1.0" : 46.82, "5.0" : 48.1, "25.0" : 54.5, "50.0" : 66.4, "75.0" : 70.2, "95.0" : 79.16, "99.0" : 80.95200000000001, &#125; &#125; &#125;&#125; Value Count Aggregation按字段统计文档数量 例如，统计 books 索引中包含 author 字段的文档数量 123456789POST books/_search&#123; "size" : 0, "aggs" : &#123; "doc_count" : &#123; "value_count" : &#123;"field" : "author"&#125; &#125; &#125;&#125; 结果如下： 12345&#123; "aggregations" : &#123; "doc_count" : &#123;"value" : 3&#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch搜索排序]]></title>
    <url>%2F2019%2F05%2F06%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[默认排序ElasticSearch 是按照查询和文档的相关度进行排序的，默认按评分降序排序 123456GET books/_search&#123; "query" : &#123; "term" : &#123;"title" : "java"&#125; &#125;&#125; 等价于 1234567891011GET books/_search&#123; "query" : &#123; "term" : &#123;"title" : "java"&#125; &#125;, "sort" : &#123; &#123; "_score" : &#123;"order" : "desc"&#125; &#125; &#125;&#125; 对于 match_all 而言，由于只返回所有文档，不需要评分，文档的顺序为添加文档的顺序 多字段排序和 SQL 一样，也支持多字段排序： 123456789GET books/_search&#123; "sort" : &#123; &#123; "price" : &#123;"order" : "desc"&#125;, "year" : &#123;"order" : "asc"&#125; &#125; &#125;&#125; 分片影响评分ElasticSearch 是在每一个分片上单独打分的，分片的数量会影响打分的结果 同时，分词器也会影响评分，原因是使用不同的分词器会使倒排序索引中的词项数发生改变，最终影响得分]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch搜索高亮]]></title>
    <url>%2F2019%2F05%2F06%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E6%90%9C%E7%B4%A2%E9%AB%98%E4%BA%AE%2F</url>
    <content type="text"><![CDATA[自定义高亮片段ElasticSearch 默认会用 &lt;em&gt;&lt;/em&gt; 标签标记关键字。想要自定义标签，只要在高亮属性中给需要高亮的字段加上 pre_tags 和 post_tags 即可： 1234567891011121314GET books/_search&#123; "query" : &#123; "match" : &#123;"title" : "java"&#125; &#125;, "highlight" : &#123; "fields" : &#123; "title" : &#123; "pre_tags" : ["&lt;strong&gt;"], "post_tags" : ["&lt;/strong&gt;"] &#125; &#125; &#125;&#125; 多字段高亮比如，搜索 title 字段的时候，希望 description 字段中的关键字也可以高亮，这时候就需要把 require_field_match 属性设置为 false（默认为true） 12345678910111213GET books/_search&#123; "query" : &#123; "match" : &#123;"title" : "java"&#125; &#125;, "highlight" : &#123; "require_field_match" : false, "fields" : &#123; "title" : &#123;&#125;, "description" : &#123;&#125; &#125; &#125;&#125; 高亮性能分析ElasticSearch 提供了三种高亮器： highlighter 默认高亮器，需要对 _source 中保存的文档进行二次分析，速度最慢，优点是不需要额外的存储空间 postings-highlighter 不需要二次分析，但是需要在字段的映射中设置 index_options 参数为 offsets（即保存关键词的偏移量），速度快于 highlighter fast-vector-highlighter 速度最快，但是需要在字段的映射中设置 ter_vector 参数为 with_positions_offsets（即保存关键字的位置和偏移量），占用的空间最大，是典型的空间换时间的做法]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch位置查询]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E4%BD%8D%E7%BD%AE%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[ElasticSearch 可以对地理位置点 geo_point 类型和地理位置形状 geo_shape 类型的数据进行搜索。 地址位置数据： 12345678&#123;"index" : &#123;"_index" : "geo", "_type" : "city", "_id" : "1"&#125;&#125;&#123;"name" : "北京", "location" : "39.90498900,116.40528500"&#125;&#123;"index" : &#123;"_index" : "geo", "_type" : "city", "_id" : "2"&#125;&#125;&#123;"name" : "上海", "location" : "31.23170600,121.47264400"&#125;&#123;"index" : &#123;"_index" : "geo", "_type" : "city", "_id" : "3"&#125;&#125;&#123;"name" : "广州", "location" : "23.12517800,113.28063700"&#125;&#123;"index" : &#123;"_index" : "geo", "_type" : "city", "_id" : "4"&#125;&#125;&#123;"name" : "杭州", "location" : "30.28745900,120.15357600"&#125; 创建一个索引并设置映射： 123456789101112131415PUT geo&#123; "mappings" : &#123; "city" : &#123; "properties" : &#123; "name" : &#123; "type" : "keyword" &#125; &#125;, "location" : &#123; "type" : "geo_point" &#125; &#125; &#125;&#125; geo_distance querygeo_distance query 可以查找在一个中心点指定范围内的地理点文档，例如查找距离北京200KM以内的城市 12345678910111213141516171819GET geo/_search&#123; "query" : &#123; "bool" : &#123; "must" : &#123; "match_all" : &#123;&#125; &#125;, "filter" : &#123; "geo_distance" : &#123; "distance" : "200km", "location" : &#123; "lat" : 39.90498900, "lon" : 116.40528500 &#125; &#125; &#125; &#125; &#125;&#125; 按各城市离北京的距离排序： 123456789101112GET geo/_search&#123; "query" : &#123; "match_all" : &#123;&#125; &#125;, "sort" : &#123; "_geo_distance" : &#123; "location" : "39.90498900,116.40528500", "unit" : "km" &#125; &#125;&#125; geo_bounding_box querygeo_bounding_box query 用于查找落入指定的矩形内的地址坐标。查询中由两个点确定一个矩形 123456789101112131415161718192021222324GET geo/_search&#123; "query" : &#123; "bool" : &#123; "must" : &#123; "match_all" : &#123;&#125; &#125;, "filter" : &#123; "geo_bounding_box" : &#123; "location" : &#123; "top_left" : &#123; "lat" : 39.90498900, "lon" : 116.40528500 &#125;, "bottom_right" : &#123; "lat" : 30.28745900, "lon" : 120.15357600 &#125; &#125; &#125; &#125; &#125; &#125;&#125; geo_polygon querygeo_polygon query 用于查找在指定多边形内的地理点 123456789101112131415161718192021222324252627282930GET geo/_search&#123; "query" : &#123; "bool" : &#123; "must" : &#123; "match_all" : &#123;&#125; &#125;, "filter" : &#123; "geo_polygon" : &#123; "location" : &#123; "points" : [ &#123; "lat" : 39.90498900, "lon" : 116.40528500 &#125;, &#123; "lat" : 39.90498900, "lon" : 116.40528500 &#125;, &#123; "lat" : 23.12517800, "lon" : 113.28063700 &#125;, ] &#125; &#125; &#125; &#125; &#125;&#125; geo_shape querygeo_shape query 用于查询 get_shape 类型的地理数据，地理形状之间的关系有相交、包含、不相交三种。 创建一个新的索引用于测试，其中 location 字段的类型设为 get_shape 类型： 123456789101112131415PUT geoshape&#123; "mappings" : &#123; "city" : &#123; "properties" : &#123; "name" : &#123; "type" : "keyword" &#125; &#125;, "location" : &#123; "type" : "geo_shape" &#125; &#125; &#125;&#125; 关于经纬度的顺序，geo_point 类型的字段纬度在前经度在后，对于 geo_shape 类型则相反 把西安和郑州连成的线写入索引： 1234567891011POST geoshape/city/1&#123; "name" : "西安-郑州", "location" : &#123; "type" : "linestring", "coordinates" : [ [108.94802400, 34.26316100], [113.66541200, 34.75797500] ] &#125;&#125; 查询包含在由银川和南昌作为对角线上的点组成的矩形的地理形状，由于西安和郑州组成的直线在该矩形区域内，因此可以被查到 123456789101112131415161718192021222324GET geoshape/_search&#123; "query" : &#123; "bool" : &#123; "must" : &#123; "match_all" : &#123;&#125; &#125;, "filter" : &#123; "geo_shape" : &#123; "location" : &#123; "shape" : &#123; "type" : "envelope", "coordinates" : [ [106.27817900, 38.46637000], // 银川 [115.89215100, 28.67649300] // 南昌 ] &#125;, "relation" : "within" &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch嵌套查询]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E5%B5%8C%E5%A5%97%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[在 ElasticSearch 这样的分布式系统中执行 SQL 风格的连接查询代价昂贵，为了实现水平规模的扩展，提供了两种形式的join： nested query（嵌套查询） 文档中可能包含嵌套类型的字段，这些字段用来索引一些数组对象，每个对象都可以作为一条独立的文档被查询出来 has_child query（有子查询）和has_parent query（有父查询） 父子关系可以存在单个的索引的两个类型的文档之间。has_child 返回其子文档能满足特定查询的父文档；has_parent 返回其父文档能满足特定查询的子文档 nested query文档中可能包含嵌套类型的字段，这些字段用来索引一些数组对象，每个对象都可以作为一条独立的文档被查询出来 文档的父子关系在创建索引时在映射中声明 123456789101112PUT /my_index&#123; "mappings" : &#123; "type1" : &#123; "properties" : &#123; "obj1" : &#123; "type" : "nested" &#125; &#125; &#125; &#125;&#125; has_child query这里以员工（employee）和工作城市（branch）为例，它们属于不同的类型，相当于数据库中的两张表，这里需要建立映射关系，员工是 child type，工作城市是 parent type： 1234567891011PUT /company&#123; "mappings" : &#123; "branch" : &#123;&#125;, "employee" : &#123; "_parent" : &#123; "type" : "branch" &#125; &#125; &#125;&#125; 使用 bulk api 索引 branch 类型下的文档： 12345POST company/branch/_bulk&#123;"index" : &#123;"_id" : "london"&#125;&#125;&#123;"name" : "London Westminster", "city" : "London", "country" : "UK"&#125;&#123;"index" : &#123;"_id" : "liverpool"&#125;&#125;&#123;"name" : "Liverpool Central", "city" : "Liverpool", "country" : "UK"&#125; 添加员工数据：1234&#123;"index" : &#123;"_id" : 1, "parent" : "london"&#125;&#125;&#123;"name" : "Alice Smith", "dob" : "1970-10-24", "hobby" : "hiking"&#125;&#123;"index" : &#123;"_id" : 2, "parent" : "liverpool"&#125;&#125;&#123;"name" : "Alice Grand", "dob" : "1980-04-24", "hobby" : "diving"&#125; 搜索1980年以后出生的员工所在工作城市： 123456789101112131415GET company/barnch/_search&#123; "query" : &#123; "has_child" : &#123; "type" : "employee", "query" : &#123; "range" : &#123; "dob" : &#123; "gte" : "1980-01-01" &#125; &#125; &#125; &#125; &#125;&#125; 可以使用 min_children 指定子文档的最小个数，例如搜索最少有两个 employee 的机构： 123456789101112GET company/barnch/_search?pretty&#123; "query" : &#123; "has_child" : &#123; "type" : "employee", "min_children" : 2, "query" : &#123; "match_all" : &#123;&#125; &#125; &#125; &#125;&#125; has_parent query搜索哪些 employee 工作在 UK： 12345678910111213GET company/employee/_search&#123; "query" : &#123; "has_parent" : &#123; "parent_type" : "branch", "query" : &#123; "match" : &#123; "country" : "UK" &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch复合查询]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E5%A4%8D%E5%90%88%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[复合查询就是把一些简单查询组合在一起实现更复杂的查询需求，除此之外还可以控制另外一个查询的行为 constant_score queryconstant_source query 可以包装一个其它类型的查询，并返回匹配过滤器中的查询条件且具有相同评分的文档 下面的查询会返回 title 字段中含有关键词”java”的文档，所有文档评分都是1.2 12345678910111213GET books/_search&#123; "query" : &#123; "constant_score" : &#123; "filter" : &#123; "term" : &#123; "title" : "java" &#125;, "boost" : 1.2 &#125; &#125; &#125;&#125; bool querybool 查询可以把任意多个简单查询组合在一起，使用 must、should、must_not、filter选项来表示简单查询之间的逻辑（可以出现0次或多次）： must：文档必须匹配 must选项下的查询条件，相当于and should：文档可以匹配 should 选项下的查询条件也可以不匹配，相当于or must_not：于 must 相反 filter：和 must 一样，但是 filter 不评分，只起到过滤作用 查询 title 中包含关键字 java，且 price 不高于70，description 可以包含也可以不包含虚拟机的书籍： 123456789101112131415161718192021222324GET books/_search&#123; "query" : &#123; "bool" : &#123; "must" : &#123; "match" : &#123; "title" : "java" &#125; &#125;, "should" : &#123; "match" : &#123; "description" : "虚拟机" &#125; &#125;, "must_not" : &#123; "range" : &#123; "price" : &#123; "gte" : 70 &#125; &#125; &#125; &#125; &#125;&#125; dis_max querydis_max query 与 bool query 有一定联系也有一定区别，dis_max query 支持多并发查询，可返回与任意查询条件子句匹配的任何文档类型。与 bool 查询可以将所有匹配查询的分数相结合的方式不通，dis_max 查询只使用最佳匹配查询条件的分数 123456789101112131415161718192021GET _search&#123; "query" : &#123; "dis_max" : &#123; "tie_breaker" : 0.7, "boost" : 1.2, "queries" : [ &#123; "term" : &#123; "age" : 34 &#125; &#125;, &#123; "term" : &#123; "age" : 35 &#125; &#125; ] &#125; &#125;&#125; function_score queryfunction_score query 可以修改查询的文档得分，比如通过评分函数计算文档得分代价较高，可以改用过滤器加自定义评分函数的方式来取代传统的评分方式 用户需要定义一个查询和一到多个评分函数，评分函数会对查询到的每个文档分别计算得分 下面这条语句会返回books索引中的所有文档，最大得分为5，每个文档的得分随机生成，权重的计算模式为相乘模式： 12345678910111213GET books/_search&#123; "query" : &#123; "function_score" : &#123; "query" : &#123; "match_all" : &#123;&#125; &#125;, "boost" : "5", "random_score" : &#123;&#125;, "boost_mode" : "multiply" &#125; &#125;&#125; 使用脚本自定义评分公式，这里把 price 值的十分之一开方作为每个文档的得分： 1234567891011121314151617GET books/_search&#123; "query" : &#123; "function_score" : &#123; "query" : &#123; "match" : &#123; "title" : "java" &#125; &#125;, "script_score" : &#123; "script" : &#123; "inline" : "Math.sqrt(doc('price').value/10)" &#125; &#125; &#125; &#125;&#125; boosting queryboosting 查询用于需要对两个查询的评分进行调整的场景，boosting 查询会把两个查询封装在一起并降低其中一个查询的评分。 boosting 查询包括 positive、negative 和 negative_boost 三个部分： positive：查询评分保持不变 negative：查询会降低文档评分 negative_boost：指明 negative 中降低的权值（之前得分的XX倍） 1234567891011121314151617181920GET books/_search&#123; "query" : &#123; "boosting" : &#123; "positive" : &#123; "match" : &#123; "title" : "python" &#125; &#125;, "negative" : &#123; "range" : &#123; "publish_time" : &#123; "lte" : "2015-01-01" &#125; &#125; &#125;, "negative_boost" : 0.2 &#125; &#125;&#125; indices queryindices query 适用于需要在多个索引之间进行查询的场景，它允许指定一个索引名字列表和内部查询。 由 query 和 no_match_query 两部分组成： query：用于搜索指定索引列表中的文档 no_match_query：用于搜索指定索引列表之外的文档 123456789101112131415161718GET _search&#123; "query" : &#123; "indices" : &#123; "indices" : ["books", "books2"], "query" : &#123; "match" : &#123; "title" : "javascript" &#125; &#125;, "no_match_query" : &#123; "term" : &#123; "title" : "basketball" &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch词项查询]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E8%AF%8D%E9%A1%B9%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[全文搜索在执行查询之前会分析查询字符串，词项搜索时对倒排序索引中存储的词项进行精确操作。常用于结构化数据，如数字、日期和枚举类型 term queryterm 查询用来查找指定字段中包含给定单词的文档，term 查询不被解析，只有查询词和文档中的词精确匹配才会被搜索到 12345678GET books/_search&#123; "query" : &#123; "term" : &#123; "title" : "java" &#125; &#125;&#125; terms query是 term 的升级，可以用来查询文档中包含多个词的文档 12345678GET books/_search&#123; "query" : &#123; "terms" : &#123; "title" : ["java", "python"] &#125; &#125;&#125; range queryrange 查询用于匹配某一范围内的数值型、日期类型或者字符串字段的文档，支持的参数： gt：大于 gte：大于等于 lt：小于 lte：小于等于 12345678910111213141516GET books/_search&#123; "query" : &#123; "range" : &#123; "price" : &#123; "gt" : 50, "lte" : 70 &#125;, "publish_time" : &#123; "gte" : "2018-01-01", "lte" : "2019-12-31", "format" : "yyyy-MM-dd" &#125; &#125; &#125;&#125; exists queryexists 查询会返回字段中至少有一个非空值的文档： 12345678GET _search&#123; "query" : &#123; "exists" : &#123; "field" : "user" &#125; &#125;&#125; 以下会匹配： {&quot;user&quot; : &quot;jane&quot;} {&quot;user&quot; : &quot;&quot;} {&quot;user&quot; : &quot;-&quot;} {&quot;user&quot; : [&quot;jane&quot;]} {&quot;user&quot; : [&quot;jane&quot;, null]} 以下不会匹配： {&quot;user&quot; : null} {&quot;user&quot; : []} {&quot;user&quot; : [null]} {&quot;foo&quot; : bar} 没有user字段 prefix queryprefix 查询用于查询某个字段中以给定前缀开始的文档： 12345678GET books/_search&#123; "query" : &#123; "prefix" : &#123; "description" : "win" &#125; &#125;&#125; wildcard query通配符查询，支持单字符通配符和多字符通配符： ? 匹配一个任意字符 * 匹配零个或多个字符 和 prefix 查询一样，wildcard 查询的性能不是很高，需要消耗较多的CPU资源 12345678GET books/_search&#123; "query" : &#123; "wildcard" : &#123; "author" : "陈*" &#125; &#125;&#125; regexp query正则表达式查询 12345678GET _search&#123; "query" : &#123; "regexp" : &#123; "oistcide" : "W[0-9].+" &#125; &#125;&#125; fuzzy query编辑距离又称 Levenshtein 距离，是指两个字符串之间，由一个转成另一个所需的最少编辑操作次数（许可操作包括替换、插入、删除一个字符） fuzzy 查询就是通过计算词项与文档的编辑距离来得到结果的，但是需要消耗的资源比较大，效率不高，适用于需要模糊查询的场景 12345678GET books/_search&#123; "query" : &#123; "fuzzy" : &#123; "title" : "javascritp" // 将 javascript 打成了 javascritp &#125; &#125;&#125; type query用于查询具有指定类型的文档： 12345678GET _search&#123; "query" : &#123; "type" : &#123; "value" : "IT" &#125; &#125;&#125; ids query用于查询具有指定id的文档 类型是可选的，也可以省略，也可以接受一个数组： 123456789GET _search&#123; "query" : &#123; "ids" : &#123; "type" : "IT", "value" : ["1", "2", "3"] &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch搜索机制]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E6%90%9C%E7%B4%A2%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[摘自《从Lucene到ElasticSearch：全文检索实战》 搜索流程图如下： 第一象限：用户 第二象限：原始文档 第三象限：ElasticSearch 第四象限：搜索结果 索引过程：原始文档有 title 和 content 两个字段，当把这条文档写入到 ElasticSearch 之后，默认情况下会保存两份内容，一份是该文档的原始内容，也就是 _source 中的文档内容，另一份是索引时通过分词、过滤等一系列过程生成的倒排序索引文件（保存了词项和文档的对应关系） 搜索过程：ElasticSearch 收到用户查询关键词之后，到倒排序索引中进行查询，找到关键词对应的文档集合，然后做评分、排序、高亮处理，最终返回结果给用户]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch全文查询]]></title>
    <url>%2F2019%2F05%2F05%2Felasticsearch%2F%E6%90%9C%E7%B4%A2%E6%9F%A5%E8%AF%A2%2FElasticSearch%E5%85%A8%E6%96%87%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[高级别的全文搜索通常用于在全文字段上进行全文搜索，通过全文查询理解被查询字段是如何被索引和分析的，在执行之前将每个字段的分词器应用于查询字符串（摘自《从Lucene到ElasticSearch：全文检索实战》） match querymatch query 会对查询语句进行分词，分词后查询语句中的任何一个词项被匹配，文档就会被搜索到： 1234567891011GET books/_search&#123; "query" : &#123; "match" : &#123; "title" : &#123; "query" : "java", "operator" : "or" &#125; &#125; &#125;&#125; match_phrase querymatch_phrase query 首先会把 query 内容分词，分词器可以自定义，同时文档需要满足以下两个条件才会被搜索到： 分词后所有词项都要出现在该字段中 字段中的词项顺序要一致 下面只有前两个文档会被匹配： 123456789101112131415161718192021GET test/_search&#123; "query" : &#123; "match_phrase" : &#123; "foo" : "hello world" &#125; &#125;&#125;// 1&#123; "foo" : "I just said hello world"&#125;// 2&#123; "foo" : "Hello world"&#125;// 3&#123; "foo" : "World Hello"&#125; match_phrase_prefix query与 match_phrase 类似，只不过 match_phrase_prefix 支持最后一个 term 前缀匹配 12345678GET test/_search&#123; "query" : &#123; "match_phrase_prefix" : &#123; "foo" : "hello w" &#125; &#125;&#125; multi_match querymulti_match 是 match 的升级，用于搜索多个字段 123456789GET books/search&#123; "query" : &#123; "multi_match" : &#123; "query" : "java", "fields" : ["title", "description"] &#125; &#125;&#125; multi_match 支持对要搜索的字段的名称使用通配符： 123456789GET books/search&#123; "query" : &#123; "multi_match" : &#123; "query" : "java", "fields" : ["title", "*_name"] &#125; &#125;&#125; 也可以用指数符指定搜索字段的权重，指定关键字出现在 title 中的权重是出现在 description 字段中的3倍： 123456789GET books/search&#123; "query" : &#123; "multi_match" : &#123; "query" : "java", "fields" : ["title^3", "description"] &#125; &#125;&#125; common_terms querycommon_terms query 是一种在不牺牲性能的情况下替代停用词提高搜索准确率和召回率的方案 查询中的每个词项都有一定的代价，以搜索”The brown fox”为例，query会解析成三个词项”the”、”brown”和”fox”，每个词项都会到索引中执行一次查询。很显然包含”the”的文档非常多，传统的解决方案是把”the”当作停用词处理，去除停用词之后可以减少索引大小，同时在搜索时减少对停用词的收缩 虽然停用词对文档评分影响不大，但是当停用词仍然有重要意义的时候，就无法区分”happy”和”not happy”，不会在索引中存在，搜索的准确率和召回率就会降低 common_terms query 提高了解决方案，它把 query 分词后的词项分成重要词项（低频词项）和不重要的词项（高频词项，也就是之前的停用词）。在搜索时，首先搜索重要词项匹配的文档，这些文档是词项出现较少并且词项对其评分影响较大的文档。然后执行搜索对评分影响较小的高频词项，但是不计算所有文档的评分，而是只计算第一次查询已经匹配的文档得分。如果一个查询中只包含高频词项，那么会通过 and 连接符执行一个单独的查询（搜索所有词项） 词项是否是高频词是通过 cutoff_frequency 来设置阈值的，值可以是绝对频率（&gt;1）或者相对频率（0～1），它能自适应特定领域的停用词（将高频词自动表现为停用词，无需保留手动列表） 比如，文档频率高于0.1%的词项会被当做高频词项，用 low_freq_operator、high_freq_operator 参数连接，设置低频词项操作法为”and”是所有的低频词都是必须搜索的： 123456789101112GET _search&#123; "query" : &#123; "common" : &#123; "body" : &#123; "query" : "nelly the elephant as a cartoon", "cutoff_frequency" : 0.001, "low_freq_operator" : "and" &#125; &#125; &#125;&#125; 等价于：1234567891011121314151617181920212223242526272829303132333435363738394041GET _search&#123; "query" : &#123; "bool" : &#123; "must" : [ &#123; "term" : &#123; "body" : "nelly" &#125; &#125;, &#123; "term" : &#123; "body" : "elephant" &#125; &#125;, &#123; "term" : &#123; "body" : "cartoon" &#125; &#125;, ], "should" : [ &#123; "term" : &#123; "body" : "the" &#125; &#125;, &#123; "term" : &#123; "body" : "as" &#125; &#125;, &#123; "term" : &#123; "body" : "a" &#125; &#125;, ] &#125; &#125;&#125; query_string queryquery_string query 是与 Lucene 查询语句的语法结合非常紧密的一种查询，允许在一个查询语句中使用多个特殊条件关键字（AND、OR、NOT）对多个字段进行查询，建议熟悉 Lucene 查询语法的用户去使用 simple_query_stringsimple_query_string 是一种适合直接暴露给用户，并且具有非常完善的查询语法的查询语句，接受 Lucene 查询语法，解析过程中发送错误不会抛出异常 1234567891011GET _search&#123; "query" : &#123; "simple_query_string" : &#123; "query" : "\"fried eggs\" + (eggplant | potato) - frittata", "analyzer" : "snowball", "fields" : ["body^5", "_all"], "default_operator" : "and" &#125; &#125;&#125;]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
        <tag>从Lucene到ElasticSearch：全文检索实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty相关重要类简介]]></title>
    <url>%2F2019%2F04%2F25%2Fnetty%2FNetty%E7%9B%B8%E5%85%B3%E9%87%8D%E8%A6%81%E7%B1%BB%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 这里简单介绍Netty重要的类，深入了解可以参考《Netty权威指南》 ByteBuf当我们进行数据传输时，往往需要使用到缓冲区，常用的是JDK NIO类库提供的 java.nio.Buffer，但是它有如下缺点： ByteBuffer长度固定，一旦分配完成，容量不能动态扩展和收缩，当需要编码大对象时，可能会发生索引越界异常 ByteBuffer只有一个标识位置的指针position，读写需要手动调用 flip() 和 rewind()，且必须小心使用，很容易导致程序处理失败 ByteBuffer的API功能有限，一些高级特性不支持，需要自己实现 由于以上缺点，Netty提供了自己的 ByteBuffer 实现：ByteBuf 功能介绍： 顺序读操作 顺序写操作 readerIndex 和 writerIndex：提供两个指针变量用于支持顺序读写操作 Discardable bytes Readable bytes 和 Writable bytes clear操作 Mark 和 Rest 查找操作 Derived buffers 转换成标准的ByteBuffer 随机读写（set 和 get） 相关辅助类： ByteBufHolder：ByteBuf容器，实现该接口定制化需求 ByteBufAllocator：字节缓冲区分配器 CompositeByteBuf：允许多个 ByteBuf 的实例组装到一起 ByteBufUtil：工具类 Channel和UnsafeChannelio.netty.channel.Channel 是Netty网络操作抽象类，包含了： 网络IO操作 客户端发起连接、主动关闭连接、链路关闭 获取通信双方的网络地址 获取该 Channel 的 EventLoop 获取缓冲分配器 ByteBufAllocator 和 pipeline … UnsafeUnsafe 接口实际上是 Channel 接口的辅助接口，它不应该被用户代码直接调用到，实际的IO操作都是由Unsafe接口完成的 ChannelPipeline和ChannelHandlerNetty 的 ChannelPipeline 和 ChannelHandler 机制类似于 Servlet 和 Filter 过滤器 Netty 的 Channel 过滤器实现原理与 Servlet Filter 机制一直，它将 Channel 的数据管道抽象成 ChannelPipeline，消息在 ChannelPipeline 中流动和传递， ChannelPipeline 持有IO事件拦截器 ChannelHandler 的链表，由 ChannelHandler 对IO事件进行拦截和处理 EventLoop 和 EventLoopGroup见Netty线程模型 Future 和 PromiseFutureFuture 最早来源于JDK的 java.util.concurrent.Future，它用于代表异步操作的结果 由于Netty的Future都是与异步IO操作相关，因此命名为 ChannelFuture，代表与Channel操作相关 PromisePromise 是可写的 Future，Future 自身并没有写操作相关的接口，Netty通过Promise对Future进行扩展，用于设置IO操作的结果]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>Netty权威指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty线程模型（EventLoop、EventLoopGroup）]]></title>
    <url>%2F2019%2F04%2F24%2Fnetty%2FNetty%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%EF%BC%88EventLoop%E3%80%81EventLoopGroup%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 在我们讨论Netty线程模型的时候，都会想到经典的Reactor线程模型 Reactor单线程模型Reactor单线程模型，是指所有的IO操作都在同一个NIO线程上面完成，NIO线程职责如下： 作为NIO服务端，接收客户端的TCP连接 作为NIO客户端，向客户端发起TCP连接 读取通信对端的请求或者应答消息 向通信对端发送消息或者应答消息 由于 Reactor 模式使用的是异步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独立处理所有IO相关操作。例如通过 Acceptor 类接收客户端的TCP连接，当链路建立成功后，通过 Dispatch 将对应的 ByteBuffer 派发到指定的 Handler 上，进行消息解码，用户线程消息编码后通过NIO线程将消息发送给客户端 这种模型对于高负载、大并发的应用场景却不适合，原因如下： 一个NIO线程同时处理成百上千的链路，性能上无法支撑，无法满足海量消息的编码、解码、读取和发送 当NIO线程负载锅中之后，处理速度将变慢，会导致大量客户端连接超时，超时往往会进行重发，会导致大量消息积压和处理超时，成为性能瓶颈 一旦NIO线程出现意外，或者进入死循环，会导致整个系统通信模块不可用 Reactor多线程模型Reactor多线程模型与单线程最大的区别就是有一组NIO线程来处理IO操作： 特点如下： 有专门一个NIO线程（Acceptor线程）用于监听TCP连接请求 网络IO操作（读、写等）由一个NIO线程池负责，线程池可以用JDK线程池实现，它包含一个任务队列和N个可用的线程，这些NIO线程负责消息的读取、解码、编码和发送 一个NIO线程可以同时处理N条链路，但是一个链路只对应一个NIO线程，防止发生并发操作问题 在绝大多数场景下，该模型可以满足性能要求，但是当并发百万客户端连接，或者服务端需要对客户端进行安全认证，单独一个Acceptor线程可能存在性能不足的问题 主从Reactor多线程模型它的特点是：服务端用于接收客户端连接的不再是一个单独的NIO线程，而是一个线程池。Acceptor接收到客户端TCP连接请求并处理完成后（可能包含接入认证等），将新创建的 SocketChannel 注册到IO线程池（sub reactor线程池）的某个线程上，由它负责 SocketChannel 的读写和编解码工作，Acceptor线程池只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端 subReactor 线程池的IO线程上 这样就可以解决一个服务端无法有效处理所有客户端连接的性能不足问题 Netty线程模型Netty线程模型不是一成不变的，它取决于用户的启动参数配置，可以支持Reactor单线程模型、Reactor多线程模型和主从Reactor多线程模型 通过服务端代码了解其线程模型： 1234567891011NioEventLoopGroup bossGroup = new NioEventLoopGroup();NioEventLoopGroup workGroup = new NioEventLoopGroup();ServerBootstrap b = new ServerBootstrap();b.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; // ... &#125; 创建了两个 NioEventLoopGroup，一个用于接收客户端的TCP连接，另一个用户处理IO相关读写操作，或者执行系统Task、定时任务Task等 用于接收客户端请求的线程池职责： 接收客户端TCP连接，初始化 Channel 参数 将链路状态变更事件通知给 ChannelPipeline 处理IO操作的 Reactor 线程池职责： 异步读取通信对端的数据，发送读事件到 ChannelPipeline 异步发送消息到通信对端，调用 ChannelPipeline 的消息发送接口 执行系统调用Task 执行定时任务Task，如链路空闲状态检测定时任务 为了尽可能提升性能，Netty在很多地方进行了无锁化的设计，比如在IO线程内部进行串行操作，避免多线程竞争导致的性能下降，表面上看这种设计CPU利用率不高，并发度不够，但是通过调整NIO线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部的无锁化串行线程设计比一个队列多个工作线程的模型性能更好 Netty的 NioEventLoop 读取到消息后，直接调用 ChannelPipeline 的 fireChannelRead(Object msg)。只要用户不主动切换线程，一直都是由 NioEventLoop 调用用户的 Handler，期间不进行线程切换，避免多线程操作导致的锁的竞争 最佳实践Netty多线程编程最佳实践如下： 创建两个 NioEventLoopGroup，用户逻辑隔离NIO Acceptor和NIO IO线程 尽量不要在 ChannelHandler 中启动用户线程（解码后用于将消息派发到后端业务线程的例外） 解码要放在NIO线程调用的解码Handler中进行，不要切换到用户线程中完成消息的解码 如果业务逻辑操作非常简单，没有可能会导致线程被阻塞的磁盘操作、数据库操作、网络操作等，可以直接在NIO线程上完成业务逻辑，不需要切换到用户线程 乳沟业务逻辑处理复杂，不要在NIO线程上完成，建议将解码后的消息封装成Task，派发到业务线程池中由业务线程执行，以保证NIO线程尽快被释放，处理其它IO操作 推荐的线程数量计算公式： 线程数量 = （线程总时间/瓶颈资源时间） * 瓶颈资源的线程并行数 QPS = 1000/线程总时间 * 线程数 由于用户场景的不同，对于一些复杂的系统，实际上很难计算，职能根据测试数据和用户场景，结合公式给出一个相对合理的范围，然后对范围内的数据进行性能测试，选择相对最优值]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>Netty权威指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty UDP协议开发]]></title>
    <url>%2F2019%2F04%2F23%2Fnetty%2FNetty-UDP%E5%8D%8F%E8%AE%AE%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 介绍UDP是用户数据协议（User Datagram Protocol），作用是将网络数据流量压缩成数据报形式，提供面向事务的简单信息传送服务。与TCP不同，UDP直接利用IP协议进行UDP数据报的传输，它提供面向无连接的、不可靠的数据报投递服务 由于UDP具有资源消耗小、处理速度快的优点，通常视屏、音频等可靠性要求不高的数据传输一般会使用UDP UDP是无连接的，通信双方不需要建立物理链路连接。在网络中它用于处理数据包，在OSI模型中，处于第四层传输层，位于IP协议上一层。它不对数据报分组、组装、校验和排序 其数据报格式有首部和数据两个部分，首部很简单，为8个字节，包含： 源端口：2个字节，最大值为65535 目的端口：2个字节，最大值为65535 长度：2个字节，UDP用户数据报的总长度 校验和：2个字节，用于校验UDP数据报的数字段和包含UDP数据报首部的”伪首部”（其校验方法类似于IP分组首部中的首部校验和） UDP协议的特点： 传送数据前并不与对方建立连接，在传送数据前，发送方和接收方相互交换信息使双方同步 对接收到的数据报不发送确认信号，发送端不知道数据是否正确接收，也不会重复发送 比TCP快速，系统开销少 Netty UDP Demo源码地址 服务端：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ChineseProverbServer &#123; public static void main(String[] args) throws InterruptedException &#123; new ChineseProverbServer().run(8080); &#125; public void run(int port) throws InterruptedException &#123; NioEventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group) // UDP通信，使用 NioDatagramChannel 来创建 .channel(NioDatagramChannel.class) .option(ChannelOption.SO_BROADCAST, true) // UDP不存在客户端和服务端的实际连接，因此不需要为连接（ChannelPipeline）设置 handler .handler(new ChineseProverbServerHandler()); b.bind(port).sync().channel().closeFuture().await(); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125; private static class ChineseProverbServerHandler extends SimpleChannelInboundHandler&lt;DatagramPacket&gt; &#123; private static final String[] DICTIONARY = &#123; "只要功夫深，铁杵磨成针", "旧时王谢堂前燕，飞入寻常百姓家", "洛阳亲友如想问，一片冰心在玉壶", "一寸光阴一寸金，寸金难买寸光阴" &#125;; private String nextQuote() &#123; int index = ThreadLocalRandom.current().nextInt(DICTIONARY.length); return DICTIONARY[index]; &#125; @Override protected void messageReceived(ChannelHandlerContext ctx, DatagramPacket packet) throws Exception &#123; String req = packet.content().toString(CharsetUtil.UTF_8); System.out.println(req); if ("谚语字典查询?".equals(req)) &#123; ctx.writeAndFlush(new DatagramPacket( Unpooled.copiedBuffer("谚语查询结果：" + nextQuote(), CharsetUtil.UTF_8), packet.sender())); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; &#125;&#125; 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ChineseProverbClient &#123; public static void main(String[] args) throws InterruptedException &#123; new ChineseProverbClient().run(8080); &#125; public void run(int port) throws InterruptedException &#123; NioEventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap b = new Bootstrap(); b.group(group) .channel(NioDatagramChannel.class) .option(ChannelOption.SO_BROADCAST, true) .handler(new ChineseProverbClientHandler()); Channel ch = b.bind(0).sync().channel(); // 创建UDP Channel完成之后，客户端就要主动发送广播消息： // TCP客户端是在客户端和服务端链路建立成功之后由客户端的业务handler发送消息，这是两者的区别 ch.writeAndFlush(new DatagramPacket(Unpooled.copiedBuffer("谚语字典查询?", CharsetUtil.UTF_8), new InetSocketAddress("255.255.255.255", port))).sync(); // 等待15s秒接收服务端的应答消息，然后退出 if (!ch.closeFuture().await(15000)) &#123; System.out.println("查询超时！"); &#125; &#125; finally &#123; group.shutdownGracefully(); &#125; &#125; private class ChineseProverbClientHandler extends SimpleChannelInboundHandler&lt;DatagramPacket&gt; &#123; @Override protected void messageReceived(ChannelHandlerContext ctx, DatagramPacket msg) throws Exception &#123; String resp = msg.content().toString(CharsetUtil.UTF_8); System.out.println(resp); ctx.close(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>Netty权威指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty WebSocket协议开发]]></title>
    <url>%2F2019%2F04%2F23%2Fnetty%2FNetty-WebSocket%E5%8D%8F%E8%AE%AE%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 HTTP协议弊端 HTTP协议为半双工协议，数据可以在客户端和服务端两个方向上传输，但是不能同时传输 HTTP消息冗长而繁琐，它包含消息头、消息体、换行符等，通常采用文本方式传输，相比于其它的二进制通信协议，冗长而繁琐 针对服务器推送的黑客攻击 WebSocket介绍WebSocket 基于 TCP 的双向全双工进行消息传输，相比于HTTP的半双工，性能得到很大提升，其特点： 单一的TCP连接，采用全双工模式通信 对代理、防火墙和路由器透明 无头部信息、Cookie和身份验证 无安全开销 通过”ping/pong”帧保持链路激活 服务器可以主动传递消息给客户端，不再需要客户端轮询 WebSocket生命周期浏览器通过 JavaScript 向服务器发出建立 WebSocket 连接的请求，客户端和服务器可以通过TCP连接直接交换数据。因为 WebSocket 连接本质上就是一个TCP连接，所以在数据传输的稳定性和传输量大小方面，比轮询以及 Comet 技术有很大的性能优势 为了建立一个 WebSocket 连接，浏览器首先要向服务器发起一个HTTP请求，包含了一些附加头信息，其中附加头信息 Upgrade:WebSocket 表明这是一个申请协议升级的HTTP请求 服务端返回给客户端的应答消息： 握手成功以后，可以通过”messages”的方式进行通信了，一个消息由一个或者多个帧组成，WebSocket 的消息并不一定对应一个特定网络层的帧，可以被分隔或者被合并 帧都有属于自己的类型，属于同一个消息的多个帧具有相同类型的数据，可以是文本数据、二进制数据和控制帧（协议级信令，如信号） 连接关闭为关闭 WebSocket 连接，客户端和服务器需要通过一个安全的方法关闭底层TCP连接以及TLS会话，如果合适，丢弃任何可能已经接收的字节；必要时（受到攻击），可以通过任何可用的手段关闭连接 底层的TCP连接，在正常情况下，应该首先由服务器关闭。在异常情况下（例如在一个合理的时间周期后没有接收到服务器的TCP Close），客户端可以发起TCP Close。因此，当服务器被指示关闭 WebSocket 连接时，它应该立即发起一个TCP Close操作，客户端应该等待服务器的TCP Close WebSocket 的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个Close控制帧，当对端接收到关闭控制帧指令时，需要主动关闭 WebSocket 连接 Netty WebSocket Demo源码地址 目前主流的浏览器都已经支持 WebSocket 功能如下：浏览器通过 WebSocket 协议发送请求消息到服务器，服务器对请求进行判断，如果是合法的 WebSocket 请求，则获取请求消息（文本），并在后面追加字符串返回 服务端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127public class WebSocketServer &#123; public static void main(String[] args) throws InterruptedException &#123; new WebSocketServer().run(8080); &#125; public void run(int port) throws InterruptedException &#123; NioEventLoopGroup bossGroup = new NioEventLoopGroup(); NioEventLoopGroup workGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline() // 将请求和应答消息编码或者解码为HTTP消息 .addLast("http-codec", new HttpServerCodec()) // 将HTTP消息的多个部分组合成一个完整的HTTP消息 .addLast("aggregator", new HttpObjectAggregator(65535)) // 向客户端发送HTML5文件，主要用于支持浏览器和服务端进行WebSocket通信 .addLast("http-chunked", new ChunkedWriteHandler()) // 增加服务端handler .addLast("handler", new WebSocketServerHandler()); &#125; &#125;); Channel channel = b.bind(port).sync().channel(); System.out.println(String.format("Web socket server started at port : %d", port)); System.out.println(String.format("Open your browser and navigate to http://localhost:%d/", port)); channel.closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125; private class WebSocketServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; &#123; private WebSocketServerHandshaker handshaker; @Override protected void messageReceived(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 普通HTTP接入，第一次接入是通过HTTP if (msg instanceof FullHttpRequest) &#123; handleHttpRequest(ctx, (FullHttpRequest) msg); &#125; // WebSocket接入 else if (msg instanceof WebSocketFrame) &#123; handleWebSocketFrame(ctx, (WebSocketFrame) msg); &#125; &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; private void handleHttpRequest(ChannelHandlerContext ctx, FullHttpRequest req) &#123; // 判断是否header里是否有Upgrade为websocket if (!req.decoderResult().isSuccess() || (!"websocket".contentEquals(req.headers().get("Upgrade")))) &#123; sendHttpResponse(ctx, req, new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.BAD_REQUEST)); return; &#125; // 建立websocket连接 WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory("ws://localhost:8080/websocket", null, false); handshaker = wsFactory.newHandshaker(req); if (handshaker == null) &#123; WebSocketServerHandshakerFactory.sendUnsupportedVersionResponse(ctx.channel()); &#125; else &#123; handshaker.handshake(ctx.channel(), req); &#125; &#125; private void sendHttpResponse(ChannelHandlerContext ctx, FullHttpRequest req, FullHttpResponse resp) &#123; // 返回客户端应答 if (resp.status().code() != 200) &#123; ByteBuf buf = Unpooled.copiedBuffer(resp.status().toString(), CharsetUtil.UTF_8); resp.content().writeBytes(buf); buf.release(); HttpHeaderUtil.setContentLength(resp, resp.content().readableBytes()); &#125; ChannelFuture f = ctx.channel().writeAndFlush(resp); if (!HttpHeaderUtil.isKeepAlive(req) || resp.status().code() != 200) &#123; f.addListener(ChannelFutureListener.CLOSE); &#125; &#125; private void handleWebSocketFrame(ChannelHandlerContext ctx, WebSocketFrame frame) &#123; // 是否是关闭链路的命令 if (frame instanceof CloseWebSocketFrame) &#123; handshaker.close(ctx.channel(), ((CloseWebSocketFrame) frame).retain()); return; &#125; // 是否是Ping消息 if (frame instanceof PingWebSocketFrame) &#123; ctx.channel().write(new PongWebSocketFrame(frame.content().retain())); return; &#125; // 本demo仅支持文本消息，不支持二进制消息 if (!(frame instanceof TextWebSocketFrame)) &#123; throw new UnsupportedOperationException( String.format("%s frame types not supported", frame.getClass().getName())); &#125; // 返回应答消息 String request = ((TextWebSocketFrame) frame).text(); System.out.println(String.format("%s received %s", ctx.channel(), request)); ctx.channel().write(new TextWebSocketFrame( String.format("%s , 欢迎使用Netty WebSocket服务，现在时刻：%s", request, new Date().toString()))); &#125; &#125;&#125; 浏览器HTML：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Netty WebSocket 时间服务器&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt; var socket; if (!window.WebSocket) &#123; window.WebSocket = window.MozWebSocket; &#125; if (window.WebSocket) &#123; socket = new WebSocket("ws://localhost:8080/websocket"); socket.onmessage = function (ev) &#123; var ta = document.getElementById("responseText"); ta.value = ""; ta.value = ev.data; &#125;; socket.onopen = function (ev) &#123; var ta = document.getElementById("responseText"); ta.value = "打开 WebSocket 服务正常，浏览器支持 WebSocket！"; &#125;; socket.onclose = function (ev) &#123; var ta = document.getElementById("responseText"); ta.value = ""; ta.value = "WebSocket 关闭！"; &#125; &#125; else &#123; alert("抱歉，您的浏览器不支持 WebSocket 协议"); &#125; function send(message) &#123; if (!window.WebSocket) &#123; return; &#125; if (socket.readyState === WebSocket.OPEN) &#123; socket.send(message); &#125; else &#123; alert("WebSocket 连接没有建立成功！"); &#125; &#125;&lt;/script&gt;&lt;form onsubmit="return false;"&gt; &lt;input type="text" name="message" value="Netty WebSocket"/&gt; &lt;br/&gt; &lt;input type="button" value="发送 WebSocket 请求消息" onclick="send(this.form.message.value)"/&gt; &lt;hr color="blur"/&gt; &lt;h3&gt;服务端返回的消息&lt;/h3&gt; &lt;textarea id="responseText" style="width: 500px;height: 300px"&gt;&lt;/textarea&gt;&lt;/form&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>Netty权威指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 序列化的缺点]]></title>
    <url>%2F2019%2F04%2F22%2Fjava%2Fio%2FJava-%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 JDK1.1版本提供了Java序列化，只需要实现 java.io.Serializable 接口并生成序列ID即可，但是在远程服务调用（RPC）时，很少使用Java序列化进行消息的编解码和传输 源码地址 无法跨语言由于Java序列化是Java语言内部的私有协议，其它语言并不支持，对于用户来说完全是黑盒，其序列化后的字节数组，别的语言无法进行反序列化 目前几乎所有流行的Java RPC通信框架，都没有使用Java序列化，原因就是它无法跨语言，而一般情况下，RPC框架都需要支持跨语言应用 序列化后的码流太大通过下面的例子看下Java序列化后的字节数组大小： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Getter@Setterpublic class UserInfo implements Serializable &#123; private static final long serialVersionUID = 1L; private String userName; private int userId; public UserInfo buildUserName(String userName) &#123; this.userName = userName; return this; &#125; public UserInfo buildUserId(int userId) &#123; this.userId = userId; return this; &#125; public byte[] codeC() &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); byte[] value = this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.userId); buffer.flip(); value = null; byte[] result = new byte[buffer.remaining()]; buffer.get(result); return result; &#125; public static void main(String[] args) throws IOException &#123; UserInfo userInfo = new UserInfo(); userInfo.buildUserId(100).buildUserName("hello"); ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream os = new ObjectOutputStream(bos); os.writeObject(userInfo); os.flush(); os.close(); byte[] b = bos.toByteArray(); System.out.println("The jdk serializable length is : " + b.length); bos.close(); System.out.println("----------------------------------------------"); System.out.println("The byte array serializable length is : " + userInfo.codeC().length); &#125;&#125; 执行后的结果：123The jdk serializable length is : 106----------------------------------------------The byte array serializable length is : 13 可以发现，使用Java序列化后的字节数组很大，这样就导致占用空间大、网络传输更占带宽，导致系统的吞吐量降低 序列化性能太低将上面的例子改造成性能测试版本 123456789101112131415161718192021222324252627282930313233public class JavaSerializePerformTest &#123; public static void main(String[] args) throws IOException &#123; UserInfo userInfo = new UserInfo(); userInfo.buildUserId(100).buildUserName("hello"); int loop = 1000000; ByteArrayOutputStream bos; ObjectOutputStream os; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; loop; i++) &#123; bos = new ByteArrayOutputStream(); os = new ObjectOutputStream(bos); os.writeObject(userInfo); os.flush(); os.close(); byte[] b = bos.toByteArray(); bos.close(); &#125; long endTime = System.currentTimeMillis(); System.out.println("The jdk serializable cost time is : " + (endTime - startTime) + " ms"); System.out.println("----------------------------------------------"); startTime = System.currentTimeMillis(); for (int i = 0; i &lt; loop; i++) &#123; userInfo.codeC(); &#125; endTime = System.currentTimeMillis(); System.out.println("The byte array serializable cost time is : " + (endTime - startTime) + " ms"); &#125;&#125; 执行结果：123The jdk serializable cost time is : 2667 ms----------------------------------------------The byte array serializable cost time is : 160 ms 简单的例子可以看出，Java序列化的性能很低]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Netty权威指南</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java AIO编程]]></title>
    <url>%2F2019%2F04%2F19%2Fjava%2Fio%2FJava-AIO%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 JDK7 的 NIO2.0 引入了新的异步通道的概念，并提供了异步文件通道和异步套接字通道的实现。异步通道提供两种方式获取操作结果： 通过 java.util.concurrent.Future 类来表示异步操作的结果 在执行异步操作的时候传入一个 java.nio.channels CompletionHandler 接口的实现类作为操作完成的回调 NIO2.0的异步套接字通道是真正的异步非阻塞I/O，它对应UNIX网络编程中的事件驱动I/O（AIO），它不需要通过多路复用器对注册的通道进行轮询操作即可实现异步读写，简化了NIO的编程思想 仍旧以事件服务器为例，源码地址 服务端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class AsyncTimeServer implements Runnable &#123; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; public static void main(String[] args) &#123; new Thread(new AsyncTimeServer(8080), "AIO-AsyncTimeServer-001").start(); &#125; public AsyncTimeServer(int port) &#123; try &#123; // 创建 AsynchronousServerSocketChannel，并绑定端口 this.asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); this.asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); System.out.println("The time server is start in port : " + port); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; // 初始化 CountDownLatch 对象，作用是在完成一组正在执行的操作之前，允许当前线程一直阻塞 this.latch = new CountDownLatch(1); doAccept(); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; /** * 接收客户端的请求 */ private void doAccept() &#123; // 由于是异步操作，可以通过 CompletionHandler 实例来接收 accept 操作成功的通知消息 this.asynchronousServerSocketChannel.accept(this, new CompletionHandler&lt;AsynchronousSocketChannel, AsyncTimeServer&gt;() &#123; @Override public void completed(AsynchronousSocketChannel channel, AsyncTimeServer asyncTimeServer) &#123; // 为什么还要再次调用 accept 方法呢？ // 当我们调用 AsynchronousServerSocketChannel 的 accept 方法后，如果有新的客户端接入，系统将回调我们传入的 CompletionHandler 实例的 completed 方法 // 表示新的客户端已经接入成功，因为一个 AsynchronousServerSocketChannel 可以接收成千上万个客户端，所以需要继续调用它的 accept 方法， // 接收其它客户端连接，最终形成一个循环，每当接收一个客户端连接成功后，再异步接收新的客户端连接 asyncTimeServer.asynchronousServerSocketChannel.accept(asyncTimeServer, this); ByteBuffer buffer = ByteBuffer.allocate(1024); // 进行异步读操作，参数详解： // ByteBuffer dst：接收缓冲区，用于从异步 Channel 中读取数据包 // A attachment：异步 Channel 携带的附件，通知回调的时候作为入参使用 // CompletionHandler&lt;Integer,? super A&gt; handler：接收通知回调的业务handler channel.read(buffer, buffer, new ReadCompletionHandler(channel)); &#125; @Override public void failed(Throwable exc, AsyncTimeServer attachment) &#123; exc.printStackTrace(); attachment.latch.countDown(); &#125; &#125;); &#125; private class ReadCompletionHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private AsynchronousSocketChannel channel; public ReadCompletionHandler(AsynchronousSocketChannel channel) &#123; this.channel = channel; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; attachment.flip(); byte[] bytes = new byte[attachment.remaining()]; attachment.get(bytes); String req = new String(bytes, StandardCharsets.UTF_8); System.out.println("The time server receive order : " + req); String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(req) ? new Date(System.currentTimeMillis()).toString() : "BAD ORDER"; doWrite(currentTime); &#125; private void doWrite(String response) &#123; if (response == null || response.length() &lt;= 0) &#123; return; &#125; byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); this.channel.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; // 如果没有发送完成，继续发送 if (buffer.hasRemaining()) &#123; channel.write(buffer, buffer, this); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer buffer) &#123; try &#123; channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; this.channel.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class AsyncTimeClient implements Runnable, CompletionHandler&lt;Void, AsyncTimeClient&gt; &#123; private String host; private int port; private CountDownLatch latch; private AsynchronousSocketChannel client; public static void main(String[] args) &#123; new Thread(new AsyncTimeClient("127.0.0.1", 8080), "AIO-AsyncTimeClient-001").start(); &#125; public AsyncTimeClient(String host, int port) &#123; this.host = host == null ? "127.0.0.1" : host; this.port = port; try &#123; this.client = AsynchronousSocketChannel.open(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; this.latch = new CountDownLatch(1); // 通过 connect 发起异步操作 // A attachment：AsynchronousSocketChannel 的附件，用户回调通知时作为入参被传递 // CompletionHandler&lt;Void,? super A&gt; handler：异步操作回调通知接口 this.client.connect(new InetSocketAddress(host, port), this, this); try &#123; latch.await(); this.client.close(); &#125; catch (InterruptedException | IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void completed(Void result, AsyncTimeClient attachment) &#123; byte[] req = "QUERY TIME ORDER".getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); this.client.write(writeBuffer, writeBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; // 还有未发送的数据，则继续发送 if (buffer.hasRemaining()) &#123; client.write(buffer, buffer, this); &#125; // 发送完成，则异步读取响应数据 else &#123; ByteBuffer readBuffer = ByteBuffer.allocate(1024); client.read(readBuffer, readBuffer, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer buffer) &#123; buffer.flip(); byte[] bytes = new byte[buffer.remaining()]; buffer.get(bytes); String body = new String(bytes, StandardCharsets.UTF_8); System.out.println("Now is : " + body); latch.countDown(); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer buffer) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;); &#125; @Override public void failed(Throwable exc, AsyncTimeClient attachment) &#123; try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125;&#125; 通过线程堆栈可以发现，JDK底层通过线程池来执行回调通知，最终回调 CompletionHandler 的 completed 方法，完成回调通知 我们不需要像NIO那样创建一个独立的IO线程来处理读写操作，对于 AsynchronousServerSocketChannel 和 AsynchronousSocketChannel，它们都有JDK底层的线程池负责回调并驱动读写操作，所以基于NIO2.0新的异步非阻塞 Channel 进行编程比NIO编程更为简单]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Netty权威指南</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java NIO编程]]></title>
    <url>%2F2019%2F04%2F19%2Fjava%2Fio%2FJava-NIO%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 Java NIO是 JDK1.4 引入的，弥补了原来BIO的不足 概念缓冲区 Buffer在 NIO 库中，所有数据都是用缓冲区处理的，任何时候访问 NIO 中的数据，都是通过缓冲区进行操作的。 最常用的缓冲区是 ByteBuffer，提供了一组功能用于操作byte数组，还有其它的一些缓冲区，关系图如下： 通道 ChannelChannel 是一个通道，可以通过它读取和写入数据，与流的不同之处在于通道是双向的（可以读、写或者同时读写），流只是一个方向上移动（流必须是 InputStream 或 OutputStream 的子类） 因为 Channel 是全双工的，可以比流更好地映射操作系统地API，特别是在 UNIX 网络编程模型中，底层操作系统地通道都是全双工的，同时支持读写操作。其继承关系如下： 多路复用器 Selector多路复用器提供选择已经就绪的任务的能力，它会不断地轮询注册在其上的 Channel，如果某个 Channel 上面有新的 TCP 连接接入、读和写事件，那么这个 Channel 就处于就绪状态，会被 Selector 轮询出来，然后通过 SelectionKey 可以获取就绪的 Channel 的集合，进行后续的IO操作 一个 Selector 可以同时轮询多个 Channel，由于 JDK 使用了 epoll() 代替了传统的 select 实现，所以没有最大连接句柄限制 详解源码地址 服务端NIO服务端序列图： 将之前的 TimeServer 改造成 NIO 模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public class MultiplexerTimeServer implements Runnable &#123; private Selector selector; private ServerSocketChannel serverSocketChannel; private volatile boolean stop; public static void main(String[] args) &#123; new Thread(new MultiplexerTimeServer(8080), "NIO-MultiplexerTimeServer-001").start(); &#125; /** * 初始化多路复用器、绑定监听端口 * * @param port */ public MultiplexerTimeServer(int port) &#123; try &#123; // 创建多路复用器 this.selector = Selector.open(); // 创建通道，并设置成非阻塞模式，绑定监听端口，最后注册到多路复用器（监听 SelectionKey.OP_ACCEPT） this.serverSocketChannel = ServerSocketChannel.open(); this.serverSocketChannel.configureBlocking(false); this.serverSocketChannel.socket().bind(new InetSocketAddress(port), 1024); this.serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println("The time server is start in port : " + port); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; public void stop() &#123; this.stop = true; &#125; @Override public void run() &#123; while (!this.stop) &#123; try &#123; this.selector.select(1000); // 当有处于就绪状态的 Channel 时，selector 将返回就绪状态的 Channel 的 SelectionKey 集合 Set&lt;SelectionKey&gt; selectionKeys = this.selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectionKeys.iterator(); SelectionKey key; while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; // 进行网络的异步读写操作 handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) &#123; key.channel().close(); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 处理客户端请求 * * @param key * @throws IOException */ private void handleInput(SelectionKey key) throws IOException &#123; // 通过 SelectionKey 的操作位进行判断即可获知网络事件的类型 if (key.isValid()) &#123; if (key.isAcceptable()) &#123; ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); // 接受客户端的连接请求并创建 SocketChannel 实例，相当于完成了TCP的三次握手 SocketChannel sc = ssc.accept(); // 设置为非阻塞 sc.configureBlocking(false); // 注册到 selector，并设置为读操作 sc.register(this.selector, SelectionKey.OP_READ); &#125; if (key.isReadable()) &#123; SocketChannel sc = (SocketChannel) key.channel(); // 创建一个 ByteBuffer，由于无法得知客户端发送的大小，这里开辟一个1K的缓冲区 ByteBuffer readBuffer = ByteBuffer.allocate(1024); // SocketChannel 读取缓冲区数据 int readBytes = sc.read(readBuffer); // 由于 SocketChannel 设置为非阻塞的，因此read操作也是非阻塞的，需要通过返回值判断读到的字节数 // 大于0：读到了字节；等于0：没有读到字节；小于0：链路已关闭，需要释放相关资源； if (readBytes &gt; 0) &#123; // 将缓冲区当前的limit设置为position，position设置为0，用于后续会缓冲区的读取操作 readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, StandardCharsets.UTF_8); System.out.println("The time server receive order : " + body); String currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()).toString() : "BAD ORDER"; doWrite(sc, currentTime); &#125; else if (readBytes &lt; 0) &#123; key.cancel(); sc.close(); &#125; &#125; &#125; &#125; /** * 应答消息异步发送给客户端 * * @param channel * @param response * @throws IOException */ private void doWrite(SocketChannel channel, String response) throws IOException &#123; if (response == null || response.length() &lt;= 0) &#123; return; &#125; byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); // 将字节数据复制到缓冲区 writeBuffer.put(bytes); writeBuffer.flip(); // 将缓冲区中的字节数组发送出去 // 由于 SocketChannel 的write方法是异步非阻塞的，不保证一次能够发送完，会出现"写半包"的问题 // 需要注册写操作，不断轮询 selector 将没有发送完的 ByteBuffer 发送完毕 // 可以通过 ByteBuffer 的 hasRemaining 方法判断消息是否发送完成，这里没演示 channel.write(writeBuffer); &#125;&#125; 客户端NIO客户端序列图： 将之前的 TimeClient 改造成 NIO 模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141public class MultiplexerTimeClient implements Runnable &#123; private String host; private int port; private Selector selector; private SocketChannel socketChannel; private volatile boolean stop; public static void main(String[] args) &#123; new Thread(new MultiplexerTimeClient("127.0.0.1", 8080), "NIO-MultiplexerTimeClient-001").start(); &#125; public MultiplexerTimeClient(String host, int port) &#123; this.host = host == null ? "127.0.0.1" : host; this.port = port; try &#123; this.selector = Selector.open(); this.socketChannel = SocketChannel.open(); this.socketChannel.configureBlocking(false); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; @Override public void run() &#123; try &#123; doConnect(); &#125; catch (IOException e) &#123; e.printStackTrace(); System.exit(1); &#125; while (!this.stop) &#123; try &#123; this.selector.select(1000); Set&lt;SelectionKey&gt; selectionKeys = this.selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectionKeys.iterator(); SelectionKey key; while (it.hasNext()) &#123; key = it.next(); it.remove(); try &#123; handleInput(key); &#125; catch (Exception e) &#123; if (key != null) &#123; key.cancel(); if (key.channel() != null) &#123; key.channel().close(); &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); System.exit(1); &#125; &#125; if (this.selector != null) &#123; try &#123; // 释放 selector，由于在其注册的 channel 可能是成千上万的，一一释放显然不合适 // 因此，JDK底层会自动释放所有跟此 selector 相关联的资源 this.selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; SocketChannel sc = (SocketChannel) key.channel(); // 如果处于连接状态，说明服务端已经返回ACK应答消息 if (key.isConnectable()) &#123; // 说明连接成功，注册成 SelectionKey.OP_READ，通过 doWrite 发送 if (sc.finishConnect()) &#123; sc.register(this.selector, SelectionKey.OP_READ); doWrite(sc); &#125; else &#123; System.exit(1); &#125; &#125; // 判断是否收到了服务端的应答消息，如果是，则 SocketChannel 是可读的 if (key.isReadable()) &#123; ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) &#123; readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, StandardCharsets.UTF_8); System.out.println("Now is : " + body); this.stop = true; &#125; else if (readBytes &lt; 0) &#123; key.channel(); sc.close(); &#125; &#125; &#125; &#125; /** * 连接 * * @throws IOException */ private void doConnect() throws IOException &#123; // 如果连接成功，将 Channel 注册到 selector 上，进行请求写操作 if (this.socketChannel.connect(new InetSocketAddress(this.host, this.port))) &#123; this.socketChannel.register(this.selector, SelectionKey.OP_READ); doWrite(this.socketChannel); &#125; // 如果没有连接成功，不代表连接失败，注册成 SelectionKey.OP_CONNECT，当服务端返回TCP syn-ack消息后， // selector就能轮询到这个 SocketChannel 处于连接就绪状态 else &#123; this.socketChannel.register(selector, SelectionKey.OP_CONNECT); &#125; &#125; /** * 发送数据 * * @param channel * @throws IOException */ private void doWrite(SocketChannel channel) throws IOException &#123; byte[] req = "QUERY TIME ORDER".getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); channel.write(writeBuffer); // 通过 writeBuffer.hasRemaining() 进行判断是否消息全部发送完毕 if (!writeBuffer.hasRemaining()) &#123; System.out.println("Send order 2 server succeed."); &#125; &#125;&#125; 总结通过上述例子，NIO编程难度要比BIO大很多（这里并没有考虑”半包读”和”半包写”），其优点： 客户端发起的连接操作是异步的，可以通过在 selector 上注册 OP_CONNECT 等待后续结果 SocketChannel 的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回，这样IO线程可以处理其它的链路 线程模型优化，JDK的selector在Linux等主流操作系统上通过epoll实现，没有连接句柄的限制，意味着一个selector线程可以同时处理成千上万个客户端连接，而性能不会线性下降，适合做高性能、高负载的网络服务器]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Netty权威指南</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java BIO编程和伪异步I/O编程]]></title>
    <url>%2F2019%2F04%2F18%2Fjava%2Fio%2FJava-BIO%E7%BC%96%E7%A8%8B%E5%92%8C%E4%BC%AA%E5%BC%82%E6%AD%A5IO%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[摘自《Netty权威指南》 BIOBIO通信模型： 问题显而易见：每个客户端都需要创建一个线程，并发访问量大时，系统会出现堆栈溢出、创建新线程失败等问题 代码演示功能：时间服务器 服务端：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public class TimeServer &#123; public static void main(String[] args) throws IOException &#123; // 监听8080端口 int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; port = Integer.valueOf(args[0]); &#125; ServerSocket server = null; try &#123; server = new ServerSocket(port); System.out.println("The time server is start in port : " + port); Socket socket; while (true) &#123; socket = server.accept(); // 这里创建一个线程去执行业务 new Thread(new TimeServerHandler(socket)).start(); &#125; &#125; finally &#123; if (server != null) &#123; System.out.println("The time server close"); server.close(); &#125; &#125; &#125;&#125;/** * 具体执行的线程 */public class TimeServerHandler implements Runnable&#123; private Socket socket; public TimeServerHandler(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; BufferedReader in = null; PrintWriter out = null; try &#123; in = new BufferedReader(new InputStreamReader(this.socket.getInputStream())); out = new PrintWriter(this.socket.getOutputStream(), true); String currentTime; String body; while (true) &#123; body = in.readLine(); if (body == null) &#123; break; &#125; System.out.println("The time server receive order : " + body); currentTime = "QUERY TIME ORDER".equalsIgnoreCase(body) ? new Date(System.currentTimeMillis()).toString() : "BAD ORDER"; out.println(currentTime); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放相关资源 if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (out != null) &#123; out.close(); &#125; if (this.socket != null) &#123; try &#123; this.socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; this.socket = null; &#125; &#125; &#125;&#125; 客户端：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class TimeClient &#123; public static void main(String[] args) &#123; int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) &#123; port = Integer.valueOf(args[0]); &#125; Socket socket = null; BufferedReader in = null; PrintWriter out = null; try &#123; socket = new Socket("127.0.0.1", port); in = new BufferedReader(new InputStreamReader(socket.getInputStream())); out = new PrintWriter(socket.getOutputStream(), true); out.println("QUERY TIME ORDER"); System.out.println("Send order 2 server succeed."); String resp = in.readLine(); System.out.println("Now is : " + resp); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放相关资源 if (in != null) &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (out != null) &#123; out.close(); &#125; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 伪异步I/O伪异步I/O模型图： 可以看到，伪异步I/O只是加入了一个线程池，避免了每次请求都创建线程的问题（这里就不写demo了） 但是通过对输入和输出流的API文档分析，了解到读和写操作都是同步阻塞的，阻塞的时间取决于对方I/O线程的处理速度和网络I/O的传输速度。我们无法保证生产环境的网络状况和对端的应用程序能足够快，所以它的可靠性就非常差。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Netty权威指南</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx之Openresty最佳实践]]></title>
    <url>%2F2019%2F04%2F18%2Fnginx%2FNginx%E4%B9%8BOpenresty%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[我们都知道Nginx有很多的特性和好处，但是在Nginx上开发成了一个难题，Nginx模块需要用C开发，而且必须符合一系列复杂的规则，最重要的用C开发模块必须要熟悉Nginx的源代码，使得开发者对其望而生畏。为了开发人员方便，所以接下来我们要介绍一种整合了Nginx和lua的框架，那就是OpenResty，它帮我们实现了可以用lua的规范开发，实现各种业务，并且帮我们弄清楚各个模块的编译顺序。关于OpenResty，我想大家应该不再陌生，随着系统架构的不断升级、优化，OpenResty在被广泛的应用。 Openresty是一个通过Lua扩展Nginx实现的可伸缩的Web平台，内部集成了大量精良的Lua库、第三方模块以及大多数的依赖项。用于方便的搭建能够处理超高并发、扩展性极高的动态Web应用、Web服务和动态网关。 官网：http://openresty.org 官方中文文档：https://openresty.org/download/agentzh-nginx-tutorials-zhcn.html 案例汇总：https://blog.csdn.net/forezp/article/details/78616856 执行模块流程： Nginx本身在处理一个用户请求时，会按照不同的阶段进行处理，总共分为11个阶段。而Openresty的执行指令，就是在这11个步骤中挂载lua脚本实现扩展： init_by_lua：当Nginx master进程加载配置文件时会运行该lua脚本，一般用来注册全局变量或者预加载lua模块 init_worker_by_lua：每个Nginx worker进程启动时会执行的lua脚本，可以用来做健康检查 set_by_lua：设置变量 rewrite_by_lua：在rewrite阶段执行，为每个请求执行指定的lua脚本 access_by_lua：为每个请求在访问阶段调用lua脚本 content_by_lua：通过lua脚本生成content输出给http响应 balancer_by_lua：实现动态负载均衡，如果不走conten_by_lua，则走proxy_pass，在通过upstream进行转发 header_filter_by_lua：通过lua来设置headers或者cookie body_filter_by_lua：对响应数据进行过滤 log_by_lua：在log阶段执行的脚本，一般用来做数据统计，将请求数据传输到后端进行分析]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx进程模型]]></title>
    <url>%2F2019%2F04%2F18%2Fnginx%2FNginx%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[进程模型Nginx是经典的多进程模型，Nginx启动后以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程，具体如下图： master进程主要用来管理worker进程，具体包括如下4个主要功能： 接收来自外界的信号 向各worker进程发送信号 监控woker进程的运行状态 当woker进程退出后（异常情况下），会自动重新启动新的woker进程 woker进程主要用来处理网络事件，各个woker进程之间是对等且相互独立的，它们同等竞争来自客户端的请求，一个请求只可能在一个woker进程中处理，woker进程个数一般设置为机器CPU核数。 进程控制对Nginx进程的控制主要是通过master进程来做到的，主要有两种方式： 手动发送信号 master接收信号以管理众woker进程，那么，可以通过kill向master进程发送信号，比如kill -HUP pid用以通知Nginx从容重启。所谓从容重启就是不中断服务：master进程在接收到信号后，会先重新加载配置，然后再启动新进程开始接收新请求，并向所有老进程发送信号告知不再接收新请求并在处理完所有未处理完的请求后自动退出 自动发送信号 可以通过带命令行参数启动新进程来发送信号给master进程，比如./nginx -s reload用以启动一个新的Nginx进程，而新进程在解析到reload参数后会向master进程发送信号（新进程会帮我们把手动发送信号中的动作自动完成）。当然也可以这样./nginx -s stop来停止Nginx 网络事件Nginx采用异步非阻塞的方式来处理网络事件，类似于Libevent，具体过程如下图： master进程先建好需要listen的socket后，然后再fork出多个woker进程，这样每个work进程都可以去accept这个socket。当一个client连接到来时，所有accept的work进程都会受到通知，但只有一个进程可以accept成功，其它的则会accept失败。Nginx提供了一把共享锁accept_mutex来保证同一时刻只有一个work进程在accept连接，从而解决惊群问题。当一个worker进程accept这个连接后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完成的请求就结束了。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx应用实战]]></title>
    <url>%2F2019%2F04%2F18%2Fnginx%2FNginx%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[反向代理nginx反向代理的指令不需要新增额外的模块，默认自带proxy_pass指令，只需要修改配置文件就可以实现反向代理。 1234567server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://192.168.11.161:8080; &#125;&#125; 负载均衡网络负载均衡的大致原理是利用一定的分配策略将网络负载平衡地分摊到网络集群的各个操作单元上，使得单个重负载任务能够分担到多个单元上并行处理，使得大量并发访问或数据流量分担到多个单元上分别处理，从而减少用户的等待响应时间 upstream是Nginx的HTTP Upstream模块，这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡，其算法： 轮询算法（默认），如果后端服务器宕机以后，会自动踢出 ip_hash算法，根据请求的ip地址进行hash 权重轮询 配置方式：123456789101112131415161718192021# 定义一个名为tomcat的upstreamupstream tomcat &#123; server 192.168.11.161:8080 max_fails=2 fail_timeout=60s; server 192.168.11.159:8080;&#125;# 在server中使用server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://tomcat; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout http_500 http_503; proxy_connect_timeout 60s; proxy_send_timeout 60s; proxy_read_timeout 60s; &#125;&#125; 其它配置proxy_next_upstream语法：1proxy_next_upstream [error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_404 | off ]; 默认:proxy_next_upstream error timeout; 配置块:http、server、location 这个配置表示当向一台上有服务器转发请求出现错误的时候，继续换一台上后服务器来处理这个请求。 默认情况下，上游服务器一旦开始发送响应数据，Nginx反向代理服务器会立刻把应答包转发给客户端。因此，一旦Nginx开始向客户端发送响应包，如果中途出现错误也不允许切换到下一个上有服务器继续处理的。这样做的目的是保证客户端只收到来自同一个上游服务器的应答。 proxy_connect_timeout 语法: proxy_connect_timeout time; 默认: proxy_connect_timeout 60s; 范围: http, server, location 用于设置nginx与upstream server的连接超时时间，比如我们直接在location中设置proxy_connect_timeout 1ms，1ms很短，如果无法在指定时间建立连接，就会报错。 proxy_send_timeout向后端写数据的超时时间，两次写操作的时间间隔如果大于这个值，也就是过了指定时间后端还没有收到数据，连接会被关闭 proxy_read_timeout从后端读取数据的超时时间，两次读取操作的时间间隔如果大于这个值，那么nginx和后端的链接会被关闭，如果一个请求的处理时间比较长，可以把这个值设置得大一些 proxy_upstream_fail_timeout设置了某一个upstream后端失败了指定次数(max_fails)后，在fail_timeout时间内不再去请求它，默认为10秒 语法 server address [fail_timeout=30s] 123upstream backend &#123; server 192.168.218.129:8080 weight=1 max_fails=2 fail_timeout=600s; server 192.168.218.131:8080 weight=1 max_fails=2 fail_timeout=600s; &#125; Nginx动静分离在Nginx的conf目录下，有一个mime.types文件：12345678910types &#123; text/html html htm shtml; text/css css; text/xml xml; image/gif gif; image/jpeg jpeg jpg; application/javascript js; application/atom+xml atom; application/rss+xml rss; .... 用户访问一个网站，然后从服务器端获取相应的资源通过浏览器进行解析渲染最后展示给用户，而服务端可以返回各种类型的内容，比如xml、jpg、png、gif、flash、MP4、html、css等等，那么浏览器就是根据mime-type来决 定用什么形式来展示的 服务器返回的资源给到浏览器时，会把媒体类型告知浏览器，这个告知的标识就是Content-Type，比如Content- Type:text/html。 演示：1234# 将静态资源到static-resource目录下访问location ~ .*\.(js|css|png|svg|ico|jpg)$ &#123; root static-resource;&#125; 缓存当一个客户端请求web服务器，请求的内容可以从以下几个地方获取：服务器、浏览器缓存中或缓存服务器中。这取决于服务器端输出的页面信息 浏览器缓存将文件保存在客户端，好的缓存策略可以减少对网络带宽的占用，可以提高访问速度，提高用户的体验，还可以减轻服务器的负担nginx缓存配置 Nginx可以通过expires设置缓存，比如我们可以针对图片做缓存，因为图片这类信息基本上不会改变。 在location中设置expires：1expires 30s|m|h|d 压缩我们一个网站一定会包含很多的静态文件，比如图片、脚本、样式等等，而这些css/js可能本身会比较大，那么在网络传输的时候就会比较慢，从而导致网站的渲染速度。因此Nginx中提供了一种Gzip的压缩优化手段，可以对后端的文件进行压缩传输，压缩以后的好处在于能够降低文件的大小来提高传输效率 可以在http中设置： gzip on|off 是否开启gzip压缩 gzip_buffers 4 16k 设置gzip申请内存的大小，作用是按指定大小的倍数申请内存空间。4 16k代表按照原始数据大小以16k为单位的4倍申请内存。 gzip_comp_level[1-9] 压缩级别， 级别越高，压缩越小，但是会占用CPU资源 gzip_disable 正则匹配UA 表示什么样的浏览器不进行gzip gzip_min_length 开始压缩的最小长度(小于多少就不做压缩)，可以指定单位，比如 1k Gzip_http_version 1.0|1.1表示开始压缩的http协议版本 gzip_proxied nginx做前端代理时启用该选项，表示无论后端服务器的headers头返回什么信息，都无条件启用压缩 gzip_type text/pliain，application/xml对那些类型的文件做压缩 (conf/mime.conf) gzip_vary on|off 是否传输gzip压缩标识； 启用应答头”Vary:Accept-Encoding”；给代理服务器用的，有的浏览器支持压缩，有的不支持，所以避免浪费不支持的也压缩，所以根据客户端的HTTP头来判断，是否需要压缩 演示：12345678910111213141516171819 http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 60; include extra/*.conf; gzip on; gzip_min_length 5k; gzip_comp_level 3; gzip_types application/javascript image/jpeg image/svg+xml; gzip_buffers 4 32k; gzip_vary on;&#125; 防盗链一个网站上会有很多的图片，如果你不希望其他网站直接用你的图片地址访问自己的图片，或者希望对图片有版权保护。再或者不希望被第三方调用造成服务器的负载以及消耗比较多的流量问题，那么防盗链就是你必须要做的 在Nginx中配置防盗链其实很简单： 语法: valid_referers none | blocked | server_names | string …; 范围：server、location Referer请求头为指定值时，内嵌变量$invalid_referer被设置为空字符串，否则这个变量会被置成“1”。 查找匹配时不区分大小写，其中none表示缺少referer请求头、blocked表示请求头存在，但是它的值被防火墙或者代理服务器删除、server_names表示referer请求头包含指定的虚拟主机名 配置：1234567location ~ .*.(gif|jpg|ico|png|css|svg|js)$ &#123; valid_referers none blocked 192.168.11.153; if ($invalid_referer) &#123; return 404; &#125; root static; &#125; 需要注意的是伪造一个有效的“Referer”请求头是相当容易的，因此这个模块的预期目的不在于彻底地阻止这些非法请求，而是为了阻止由正常浏览器发出的大规模此类请求。还有一点需要注意，即使正常浏览器发送的合法请求，也可能没有“Referer”请求头。 跨域访问如果两个节点的协议、域名、端口、子域名不同，那么进行的操作都是跨域的，浏览器为了安全问题都是限制跨域访问，所以跨域其实是浏览器本身的限制。 配置方法：1234567891011121314151617181920server&#123; listen 80; server_name localhost; location / &#123; proxy_pass http://192.168.11.154:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_send_timeout 60s; proxy_read_timeout 60s; proxy_connect_timeout 60s; add_header &apos;Access-Control-Allow-Origin&apos; &apos;*&apos;; // #允许来自所有的访问地址 add_header &apos;Access-Control-Allow-Methods&apos; &apos;GET,PUT,POST,DELETE,OPTIONS&apos;; //支持的请求方式 add_header &apos;Access-Control-Allow-Header&apos; &apos;Content-Type,*&apos;; //支持的媒体类型 &#125; location ~ .*\.(gif|jpg|ico|png|css|svg|js)$ &#123; root static; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群主从复制原理]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E9%9B%86%E7%BE%A4%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[复制的作用是把redis的数据复制多个副本部署在不同的服务器上，如果其中一台服务器出现故障，也能快速迁移到其它服务器上提供服务。 主从复制就是我们常见的master/slave模式，主redis可以进行读写操作，当写操作导致数据发生变化时，会讲数据同步到从reids，而一般情况下，从redis是只读的，并接收主redis同步过来的数据。一个主redis可以有多个从redis 配置在redis中配置master/slave是非常容易的，只需要在slave的配置文件中加入slaveof主redis的地址、端口。而master不需要做任何变化 比如两台服务器，分别安装redis：server01和server02，将server01作为master，server02作为slave，配置如下： 在从节点server02的redis.conf文件中增加slaveof server01-ip server01-port 将主节点server01的bindip注释掉，允许所有ip访问 访问从节点server02的redis客户端，输入INFO replication，可以查看节点信息 原理（复制方式）redis提供了3中主从复制方式： 全量复制 增量复制 无硬盘复制 全量复制Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份 完成上面几个步骤后就完成了slave服务器数据初始化的所有操作，savle服务器此时可以接收来自用户的读请求。 master/slave复制策略是采用乐观复制，也就是说可以容忍在一定时间内master/slave数据的内容是不同的，但是两者的数据会最终同步。具体来说，redis的主从同步过程本身是异步的，意味着master执行完客户端请求的命令后会立即返回结果给客户端，然后异步的方式把命令同步给slave。这一特征保证启用master/slave后master的性能不会受到影响。 另一方面，如果在这个数据不一致的窗口期间，master/slave因为网络问题断开连接，而这个时候，master 是无法得知某个命令最终同步给了多少个slave数据库。不过redis提供了一个配置项来限制只有数据至少同步给多少个slave的时候，master才是可写的: min-slaves-to-write 3：表示只有当3个或以上的slave连接到master，master才是可写的 min-slaves-max-lag 10：表示允许slave最长失去连接的时间，如果10秒还没收到slave的响应，则master认为该slave以断开 增量复制从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份 master node会在内存中创建一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制 但是如果没有找到对应的offset，那么就会执行一次全量同步 无硬盘复制Redis复制的工作原理基于RDB方式的持久化实现的，也就是master在后台保存RDB快照，slave接收到rdb文件并载入，但是这种方式会存在一些问题： 当master禁用RDB时，如果执行了复制初始化操作，Redis依然会生成RDB快照，当master下次启动时执行该 RDB文件的恢复，但是因为复制发生的时间点不确定，所以恢复的数据可能是任何时间点的。就会造成数据出现问题 当硬盘性能比较慢的情况下(网络硬盘)，那初始化复制过程会对性能产生影响 因此2.8.18以后的版本，Redis引入了无硬盘复制选项，可以不需要通过RDB文件去同步，直接发送数据，通过以下配置来开启该功能：1repl-diskless-sync yes master在内存中直接创建rdb，然后发送给slave，不会在落地到自己本地磁盘]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cluster]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis-Cluster%2F</url>
    <content type="text"><![CDATA[即使是使用哨兵，此时的redis集群的每个数据库依然存有集群中的所有数据，从而导致集群的总数据存储量受限于可用存储内存最小的节点，形成木桶效应。因为redis是基于内存存储的，所以这个问题尤为突出。 在redis3.0之前，我们是通过在客户端去做分片，通过hash的方式对key进行分片存储。分片虽然能够解决各个节点的存储压力，但是维护成本高，增加、移除节点比较繁琐。因此在3.0之后的版本支持了集群功能，集群的特点在于拥有和单机实例一样的性能，同时在网络分区以后能够提供一定的可访问性以及对主数据库故障恢复的支持。 哨兵和集群是两个独立的功能，当不需要对数据进行分片使用哨兵就够了，如果要进行水平扩容，集群是一个比较好的方式 拓扑结构一个redis-cluster由多个redis节点构成，不同节点组服务的数据没有交集。 节点组内分为主备两类节点，对应master和slave节点，两者数据准实时一致，通过异步化的主备复制机制来保证。一个节点组有且只有一个master节点，可以有0到多个slave节点，在这个节点组中只有master节点对用户提供写服务，读服务可以由master和slave提供 redis-cluster是基于gossip协议实现的无中心化节点的集群，因为去中心化的架构不存在统一的配置中心，各个节点对整个集群状态的认知是来自于节点之间的信息交互。在redis-cluster中，这个信息交互是通过Redis Cluster Bus来完成的 数据分区分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，每个节点负责整个数据的一个子集，redis-cluster采用哈希分区规则，采用虚拟槽分区。 虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合中，整数定义为槽（slot）。redis-cluster槽的范围是0 ~ 16383。 槽是集群内数据管理和迁移的基本单位，采用大范围的槽的主要目的是为了方便数据的拆分和集群的扩展，每个节点负责一定数量的槽，计算公式：1slot = CRC16(key)%16383 如下图所示： HashTags通过分片手段，可以将数据合理的划分到不同的节点上，但是有时候，我们希望对相关联的业务以原子方式进行操作，比如： 在单节点上执行MSET，是一个原子操作，但是在集群环境下，它的操作就不是原子操作，是因为多个key可能会被分配到不同的机器上 所以，就会有一个矛盾点，即要求key尽可能的分散在不同机器上，又要求相关联的key分配到相同的机器上，这该如何解决呢？ 从之前的分析中可以了解到，分片其实就是一个hash的过程，对key做hash取模后划分到不同的机器上。所以要做到上面这点，需要考虑如何让相关联的key得到的hash值都相同，在redis中引入了HashTags的概念，可以使得数据分布算法可以根据key的某一个部分进行计算，然后让相关的key落到同一个数据分片中。 举个例子：加入对于用户的信息进行存储：user:user1:id、user:user1:name，那么通过hashtag的方式：user:{user1}:id、user:{user1}:name 当一个key包含{}的时候，就不对整个key做hash，而是仅对{}包含的字符串做hash 重定向客户端Redis Cluster并不会代理查询，那么如果客户端访问了一个key并不存在的节点，该如何处理？比如获取key为msg的值，msg计算出来的槽编号为254，当前节点正好不负责编号为254的槽，那么就会返回客户端下面的信息：1-MOVED 254 127.0.0.1:6381 表示客户端想要的254槽由运行在IP为127.0.0.1，端口为6381的master示例服务上，如果恰好由当前节点负责，则当前节点会立即返回结果 分片迁移在一个稳定的redis-cluster下，每一个slot对应的节点是确定的，但是在以下情况节点和分片对应的关系会发生变更： 新加入master节点 某个节点宕机 也就是说当动态添加或减少节点时，需要将16384个槽做个再分配，槽中的键值也要迁移（这一过程处于半自动状态，需要人工介入） 新增一个主节点： 新增一个节点D，redis-cluster从各个节点的前面各拿取一部分slot到D上，最后大致会变成： 节点A覆盖1365 ～ 5460 节点B覆盖6827 ～ 10922 节点C覆盖12288 ～ 16383 节点D覆盖0 ～ 1364，5461 ～ 6826，10923 ～ 12287 删除一个节点： 先将节点的数据移动到其它节点上，然后执行删除 槽迁移的过程槽迁移的过程中有一个不稳定状态，这个不稳定状态会有一些规则，这些规则定义客户端的行为，从而使得redis-cluster不必宕机的情况下也可以执行槽的迁移。如下图（迁移槽编号为1，2，3的）： 简单的工作流程： 向Master B发送状态变更命令，把Master B对应的slot状态设置为IMPORTING 向Master A发送状态变更命令，把Master A对应的slot状态设置为MIGRATING 当状态变成IMPROTING或者MIGRATING时，对于slot内部数据提供读写服务的行为和通常状态下是有区别的 MIGRATING状态 如果客户端访问的key还没有迁移出去，则正常处理这个key 如果key已经迁移或者根本就不存在这个key，则回复客户端ASK信息让它跳转到Master B去执行 IMPORTING状态当来自客户端的正常访问不是从ASK跳转过来的，说明客户端还不知道迁移正在进行，很有可能操作了一个目前还没迁移完成的并且还存在与Master A上的key，如果此时在A上已经修改了，那么B和A的修改则会发生冲突。 对于Master B上的slot所有非ASK跳转过来的操作，Master B都不会去处理，而是通过MOVED命令让客户端调转到Master A上去处理]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵机制]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[再master/slave模式中，当master遇到异常中断后，需要从slave中选举一个新的master继续对外提供服务，这种机制有很多，比如在zk中的leader选举、kafka中可以基于zk的节点实现master选举。所以在redis中也需要一种机制去实现master的决策，redis没有提供自动master选举功能，需要借助一个哨兵来进行监控。 哨兵的作用就是监控redis系统的运行情况，功能包括两个： 监控master和slave是否正常运行 master出现故障时自动将slave数据库升级为master 哨兵是一个独立的进程，使用哨兵后的架构图： 哨兵集群为了解决master选举问题，又引出了一个单点问题，就是哨兵的可用性问题，在一个一主多从的redis系统中，可以使用多个哨兵进行监控来保证系统足够稳定，此时哨兵不仅会监控master和slave，同时还会互相监控。这种方式成为哨兵集群，哨兵集群需要解决故障发现和master决策协商机制问题。 哨兵之间的相互感知哨兵节点之间会因为共同监视同一个master从而产生关联，一个新加入的哨兵节点需要和其他监视相同master节点的哨兵相互感知： 需要相互感知的哨兵都向他们共同监视的master节点订阅channel:sentinel:hello 新键入的哨兵节点向这个channel发布一条消息，包含自己本身的信息，这样订阅了这个channel的哨兵就可以发现这个新的哨兵 新加入的哨兵和其他哨兵节点建立长连接 master故障发现sentinel节点会定期向master节点发送心跳包来判断存活状态，一旦master节点没有正确响应，sentinel会把master设置为“主观不可用状态”，然后会把“主观不可用”发送给其他所有的sentinel节点去确认，当确认的sentinel节点数大于quorum时，则会认为master是“客观不可用”，接着就开始进入选举新的master流程。 这里会遇到一个问题，就是sentinel中，本身是一个集群，如果多个节点同时发现master节点达到客观不可用状态，那谁来决策选择哪个节点作为master呢？ 这个时候就需要从sentinel集群中选择一个leader来做决策，这里用到了一致性算法Raft算法，它和Paxos算法类似，都是分布式一致性算法，但是它比Paxos算法更容易理解，它们都是基于投票算法，只要保证半数节点通过提议即可 动画演示地址：http://thesecretlivesofdata.com/raft 配置实现创建sentinel.conf文件，文件主要配置：1234567891011// sentinel monitor name ip port quorum// name表示要监控的master的名字，自定义// ip和port表示master的ip和端口号// quorum表示最低通过票数，也就是说需要几个哨兵节点统一才可以sentinel monitor mymaster 192.168.11.131 6397 1// 表示如果5s内mymaster没响应，就认为SDOWNsentinel down-after-milliseconds mymaster 5000// 表示15s后，mymaster仍没活过来，则启动failover，从剩下的slave中选一个升级为mastersentinel failover-timeout mymaster 15000 两种方式启动哨兵：12redis-sentinel sentinel.confredis-server /path/sentinel.conf --sentinel 哨兵监控一个系统时，只需要配置监控master即可，哨兵会自动发现所有slave]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis中字符串的二进制安全]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E4%B8%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[什么是二进制安全 二进制安全是指，在传输数据时，保证二进制数据的信息安全，也就是不被篡改、破译等，如果被攻击，能够及时检测出来。 Redis中的二进制安全C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。 举个例子，如果有一种使用空字符来分割多个单词的特殊数据格式，如下图所示，那么这种格式就不能使用C字符串来保存，因为C字符串所用的函数只会识别出其中的”Redis”，而忽略之后的”Cluster”。 虽然数据库一般用于保存文本数据，但使用数据库来保存二进制数据的场景也不少见，因此，为了确保Redis可以适用于各种不同的使用场景，SDS的API都是二进制安全的（binary-safe），所有SDS的API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。 这也是我们将SDS的buf属性称为字节数组的原因：Redis不是用这个数组来保存字符，而是用它来保存一系列二进制数据。 例如，使用SDS来保存之前提到的特殊数据格式就没有任何问题，因为SDS使用len属性的值而不是空字符来判断字符串是否结束 通过使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单线程的Redis性能为什么这么快]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2F%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84Redis%E6%80%A7%E8%83%BD%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[Redis采用了一种非常简单的做法，单线程来处理来自所有客户端的并发请求，Redis把任务封闭在一个线程中从而避免了线程安全问题。 至于为什么是单线程的，官方的解释是，CPU并不是Redis的瓶颈所在，Redis的瓶颈主要在机器的内存和网络的带宽。 Redis采用的是基于内存的、单进程、单线程模型的KV数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的KV数据库Memcached差！有兴趣的可以参考官方的基准程序测试《How fast is Redis？》（https://redis.io/topics/benchmarks） Redis为什么这么快： 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 多路I/O复用 Redis是跑在单线程中的，所有的操作都是按照顺序执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以I/O操作在一般情况下往往不能直接返回，这回导致某一文件的I/O阻塞导致整个进程无法对其他客户端提供服务，而I/O多路复用就是为了解决这个问题而出现的。 在这之前，先简单了解下几种I/O模型： 同步阻塞IO（Blocking IO）：传统的IO模型 同步非阻塞IO（Non-blocking IO）：默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK IO多路复用（IO Multiplexing）：也叫异步阻塞IO，即经典的Reactor设计模式，java中的selector和Linux中的epoll都是这种模型 异步IO（Asynchronous IO）：也叫异步非阻塞IO，即经典的Proactor设计模式 异步和同步、阻塞和非阻塞，感觉原理都差不多，来简单了解下： 同步和异步，是指用户线程和内核的交互方式 阻塞和非阻塞，是指用户线程调用内核IO操作的方式是阻塞还是非阻塞的]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的过期策略以及内存淘汰机制]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis采用的是定期删除+惰性删除策略，官方文档解释：https://redis.io/commands/expire 为什么不用定时删除策略定时删除，用一个定时器来负责监视key，过期则自动删除，虽然内存及时释放，但是十分消耗CPU资源。 在大并发请求下，CPU要将事件应用在处理请求，而不是删除key，因此没有采用这一策略。 定期删除+惰性删除定期删除，redis默认每隔100ms检查，是否有过期的key，有过期key则删除，需要说明的是，redis不是每隔100ms将所有的key检查一次，而是随机进行检查。 因此，如果只采用定期删除策略，会导致很多key到时间没有删除，于是，惰性删除派上用场了，也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间，那么是否过期了，过期此时就会删除。 若果定期删除没有删除key，然后也没有去请求key，也就是惰性删除也没有发生，这样，redis的内存会越来越高，那么就应该采用内存淘汰机制。 在redis.conf中有一行配置：1maxmemory-policy volatile-lru 该配置就是配内存淘汰策略的 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（推荐使用） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又当持久化存储的时候采用 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之Lua脚本]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E4%B9%8BLua%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[为什么要使用Lua脚本Redis中内嵌了对Lua环境的支持，允许开发者使用Lua语言编写脚本传到Redis中执行，直接在服务端原子的执行多个Redis命令。 Lua是一个高效的轻量级脚本语言（JavaScript、shell、sql、python、ruby…），用标准C语言编写并以源代码形式开放，其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和制定功能。 使用Lua脚本的好处： 减少网络开销，在Lua脚本中可以把多个命令放在同一个脚本中运行 原子操作，redis会将整个脚本作为一个整体执行，中间不会被其他命令插入 复用性，客户端发送的脚本会永远存储在redis中，其他客户端可以复用这一脚本来完成同样的逻辑 Lua脚本使用在Lua脚本中调用Redis命令在Lua脚本中调用Redis命令，可以使用redis.call函数调用：12redis.call(&apos;set&apos;, &apos;hello&apos;, &apos;world&apos;)local value = redis.call(&apos;get&apos;, &apos;hello&apos;) redis.call函数的返回值就是redis命令的执行结果，redis.call函数会将redis的数据类型返回值转换对应的Lua的数据类型，在脚本中可以使用return语句将值返回给redis客户端，如果没有执行return，默认返回为nil EVAL命令格式：1[EVAL][脚本内容][key参数的数量][key...][arg...] 可以通过key和arg这两个参数向脚本中传递数据，他们的值可以在脚本中分别使用KEYS和ARGV这两个类型的全局变量访问，比如： Lua脚本：1return redis.call(&apos;set&apos;,KEYS[1],ARGV[1]) // KEYS和ARGV必须大写 EVAL命令：1eval &quot;return redis.call(&apos;set&apos;,KEYS[1],ARGV[1])&quot; 1 lua1 hello 注意：EVAL命令是根据key参数的数量，也就是上面例子中的1来将后面所有参数分别存入脚本中KEYS和ARGV两个表类型的全局变量。当脚本不需要任何参数时也不能省略这个参数，如果没有则设置为0：1eval &quot;return redis.call(&apos;get&apos;,&apos;lua1&apos;)&quot; 0 EVALSHA命令考虑到通过eval执行lua脚本，脚本比较长的情况下，每次调用脚本都需要把整个脚本传给redis，比较占用带宽。为了解决这个问题，redis提供了EVALSHA命令，允许通过脚本内容的SHA1摘要来执行脚本。 该命令用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要： Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中 执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了就执行，否则返回“NOSCRIPT No matching script, Please use EVAL” 将脚本加入缓存并生成sha1摘要：1script load &quot;return redis.call(&apos;get&apos;,&quot;lua1&quot;)&quot; 使用EVALSHA执行：1evalsha &quot;a5a402e90df3hkfakyi32970058233hjfd574&quot; 0 我们在调用eval命令之前，先执行evalsha命令，如果提示脚本不存在，则再调用eval命令]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的数据持久化]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis支持两种方式的持久化： RDB方式：根据指定的规则“定时”将内存中的数据存储在硬盘上 AOF(append-only-file)方式：每次执行命令后将命令本身记录下来 两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用 RDB方式当符合一定条件时，Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，等 到持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失 fork的作用是复制一个与当前进程一样的进程。新进程的所有数据(变量、环境变量、程序计数器等)数值都和 原进程一致，但是是一个全新的进程，并作为原进程的子进程 什么情况下会进行RDB快照Redis会在以下几种情况下对数据进行快照: 根据配置规则进行自动快照 用户执行SAVE或者GBSAVE命令 执行FLUSHALL命令 执行复制(replication)时 根据配置规则进行自动快照Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下： 第一个参数是时间窗口 第二个是键的个数 也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。redis默认配置了三个规则：123save 900 1save 300 10save 60 10000 每条快照规则占一行，每条规则之间是“或”的关系。 在900秒(15分)内有一个以上的键被更改则进行快照。 用户执行SAVE或者GBSAVE命令除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务： save命令 当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令 bgsave命令 bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作。 通过LASTSAVE命令可以获取最近一次成功执行快照的时间; (自动快照采用的是异步快照操作) 执行FLUSHALL命令该命令会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作 执行复制时该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。 这里只需要了解当执行复制操作时，即使没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件 AOF方式当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程终止导致的数据丢失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这一过程会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高AOF的性能 开启AOF默认情况下Redis没有开启AOF(append only file)方式的持久化，可以通过appendonly参数启用，在redis.conf中找到appendonly yes开启AOF持久化后每执行一条会更改Redis中的数据的命令后，Redis就会将该命令写入硬盘中的AOF文件。 AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是apendonly.aof。可以在redis.conf中的属性appendfilename appendonlyh.aof修改 AOF的实现AOF文件以纯文本的形式记录Redis执行的写命令例如开启AOF持久化的情况下执行如下4条命令：1234set foo 1set foo 2set foo 3get redis会将前3条命令写入AOF文件中，通过vim的方式可以看到aof文件中的内容 我们会发现AOF文件的内容正是Redis发送的原始通信协议的内容，从内容中我们发现Redis记录了3条命令，然后这时有一个问题是前面2条命令其实是冗余的，因为这两条的执行结果都会被第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，其实内存中实际的数据可能没有多少，那这样就会造成磁盘空间以及redis数据还原的过程比较长的问题。因此我们希望Redis可以自动优化AOF文件，就上面这个例子来说，前面两条是可以被删除的。而实际上Redis也考虑到了，可以配置一个条件，每当达到一定条件时Redis就会自动重写AOF文件，这个条件的配置：12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb auto-aof-rewrite-percentage表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据 auto-aof-rewrite-min-size表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。 另外，还可以通过BGREWRITEAOF命令手动执行AOF，执行完以后冗余的命令已经被删除了 在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些 AOF的重写原理Redis可以在AOF文件体积变得过大时，自动地在后台对 AOF进行重写: 重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。 重写的流程是这样： 主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。 在fork子进程这个过程中，服务端仍然可以对外提供服务，那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办?不用担心，这个过程中，主进程的数据更新操作，会缓存到aof_rewrite_buf中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。 当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名，此后所有的操作都会被写入新的aof文件。 如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构深入分析]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Redis提供了丰富的数据类型，包括了字符串、列表、hash、集合、有序集合。redis相关命令可查阅：http://doc.redisfans.com/ 字符串（String）字符串类型是redis中最基本的数据类型，它是二进制安全的（意思是redis的string可以包含任何数据，比如jpg图片或者序列化的对象）。一个字符类型键允许存储的最大容量是512M 内部数据结构在Redis内部，String类型通过int、SDS(simple dynamic string)作为结构存储： int用来存放整型数据 sds存放字节/字符串和浮点型数据 在C的标准字符串结构下进行了封装，用来提升基本操作的性能，同时也充分利用已有的 C的标准库，简化实现逻辑。我们可以在redis的源码中【sds.h】中看到具体实现 redis3.2分支引入了五种sdshdr类型，目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存，每次在创建一个sds时根据sds的实际长度判断应该选择什么类型的sdshdr，不同类型的sdshdr占用的内存空间不同。这样细分一下可以省去很多不必要的内存开销，下面是3.2的sdshdr定义 123456789/* 8表示字符串最大长度是2^8-1 (长度为255) */struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len;/*表示当前sds的长度(单位是字节)*/ uint8_t alloc;/*表示已为sds分配的内存大小(单位是字节)*/ /*用一个字节表示当前sdshdr的类型，因为有sdshdr有五种类型，所以至少需要3位来表示*/ /*000:sdshdr5，001:sdshdr8，010:sdshdr16，011:sdshdr32，100:sdshdr64。高5位用不到所以都为0。*/ unsigned char flags; char buf[];/*sds实际存放的位置*/&#125;; 列表（List）列表类型(list)可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素或者获得列表的某一个片段。 列表类型内部使用双向链表实现，所以向列表两端添加元素的时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是很快的 内部数据结构redis版本不同，实现列表的方式是不同的： redis3.2之前，List类型的value对象内部以linkedlist或者ziplist来实现，当list的元素个数和单个元素的长度比较小的时候，Redis会采用ziplist(压缩列表)来实现来减少内存占用。否则就会采用linkedlist(双向链表)结构。 redis3.2之后，采用的一种叫quicklist的数据结构来存储list，列表的底层都由quicklist实现。 这两种存储方式都有优缺点： 双向链表在链表两端进行push和pop操作，在插入节点上复杂度比较低，但是内存开 销比较大; ziplist存储在一段连续的内存上，所以存储效率很高，但是插入和删除都需要频繁申请和释放内存; quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist，其实就是linkedlist和ziplist的结合，quicklist中每个节点ziplist都能够存储多个数据元素。其数据结构图如下： quicklist由quicklistnode组成，quicklistnode可以存放ziplist，也可以存放quicklistLZF，ziplist能够存储多个数据元素 列表结构的应用场景我们可以根据列表的数据结构特点，以及redis对列表操作来应用到以下几个场景： 栈（FILO）：使用LPUSH、LPOP命令实现 队列（FIFO）：使用LPUSH、RPOP命令实现 消息队列：使用LPUSH、BRPOP命令实现 具体的命令可以查看：http://doc.redisfans.com/ hashRedis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 数据结构map提供两种结构来存储，一种是hashtable、另一种是ziplist（数据量小的时候使用ziplist）。在redis中，哈希表分为三层（源码地址【dict.h】）： dictEntry管理一个key-value，同时保留同一个桶中相邻元素的指针，用来维护哈希桶的内部链：12345678910111213typedef struct dictEntry &#123; void *key; union &#123; // 因为value有多种类型，所以value用了union来存储 void *val; uint64_t u64; int64_t s64; double d; &#125; v; // 洗一个节点的地址，用来处理hash碰撞 // 所有分配到同一索引的元素通过next指针链接起来形成链表 // key和v都可以报错多种类型的数据 struct dictEntry *next;&#125; dictEntry; dictht实现一个hash表会使用一个buckets存放dictEntry的地址，一般情况下通过hash(key)%len得到的值就是buckets的索引，这个值决定了我们要将此dictEntry节点放入buckets的哪个索引里，这个buckets实际上就是我们说的hash表： 123456typedef struct dictht &#123; dictEntry **table; // buckets的地址 unsigned long size; // buckets的大小，总保持为2^n unsigned long sizemask; // 掩码，用来计算hash值对应的buckets索引 unsigned long used;// 当前dictht有多少个dictEntry节点&#125; dictht; dictdictht实际上就是hash表的核心，但是只有一个dictht还不够，比如rehash、遍历hash等操作，所以redis定义了一个叫dict的结构以支持字典的各种操作，当dictht需要扩容/缩容时，用来管理dictht的迁移： 1234567typedef struct dict &#123; dictType *type;// dictType里存放的时一堆工具函数的函数指针 void *privdata;// 保存type中的某些函数需要作为参数的数据 dictht ht[2];// 两个dictht，ht[0]平时用，ht[1]rehash时用 long rehashidx;// 当前rehash到buckets的哪个索引，-1时表示非rehash状态 int iterators;// 安全迭代器的计数&#125; dict; 比如我们要将一个数据存储到hash表中，那么会先计算key对应的hashcode，然后根据hashcode取模得到bucket的位置，再插入到链表中 集合（Set）集合类型中，每个元素都是不同的，也就是不能有重复数据，同时集合类型中的数据是无序的，集合类型和列表类型最大的区别就是有序性和唯一性 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在。由于集合类型在redis内部是使用的值为空的散列表（hash table），所以这些操作的时间复杂度都是O(1) 数据结构Set在底层数据结构是以intset或者hashtable存储的： 当set中只包含整数型的元素时，采用intset来存储 其它则用hashtable来存储，但是hashtable的value值为null，通过key来存储元素 有序集合（SortedSet/ZSet）有序集合，顾名思义，和之前的集合多了有序的功能。 在集合的基础上，有序集合为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除和判断元素是否操作等集合支持的操作，还能获得分数最高（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作（虽然集合中每个元素都是不同的，但是它们的分数却可以相同） 数据结构Zset的数据结构比较复杂一点，内部是以ziplist或者skiplist+hashtable来实现的，这里面最核心的一个结构就是skiplist（跳跃表）]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文章收藏]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%96%87%E7%AB%A0%E6%94%B6%E8%97%8F%2F</url>
    <content type="text"><![CDATA[阿里技术Nacos： Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 2019.04.12 Spring Cloud Alibaba系列教程-03-搭建生产可用的Nacos集群 2019.04.12 Sentinel： Spring Cloud Alibaba基础教程：使用Sentinel实现接口限流 2019.04.12 Sentinel Client: 整合Apollo规则持久化 2019.04.01 阿里Sentinel控制台: 整合Apollo规则持久化 2019.04.15 Spring Cloud Alibaba基础教程：Sentinel使用Nacos存储规则 2019.04.17 Seata： 开发者说：深度剖析开源分布式事务方案 Seata 的事务协调器 2019.04.12 源码｜详解分布式事务之 Seata-Client 原理及流程 2019.04.18 Dubbo： 提升不止一点点，Dubbo 3.0 预览版详细解读 2019.04.18 RocketMQ： 从RocketMQ我们学到了什么？（NameServer篇） 2019.04.03 Spring生态Spring CloudSpring Cloud Bus： 干货｜Spring Cloud Bus 消息总线介绍 2019.04.12 Spring Cloud Stream： 干货｜Spring Cloud Stream 体系及原理介绍 2019.04.03 Service MeshIstio： 什么是 istio 2018-08-26 中间件Mysql： 抱歉，没早点把这么全面的InnoDB锁机制发给你 2019.03.18 面试实践架构师之路（58沈剑）： 架构师之路18年精选100篇 2019.03.11 炸！业界难题，跨库分页的几种常见方案 2019.05.13 其它： 到底什么时候该使用MQ？ 2017-04-05 一个经典面试题：如何保证缓存与数据库的双写一致性？ 2019.05.15]]></content>
      <categories>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用skywalking做分布式系统链路监控]]></title>
    <url>%2F2019%2F04%2F12%2Fmicro-service%2Fapm%2F%E4%BD%BF%E7%94%A8skywalking%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E9%93%BE%E8%B7%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[版本： skywalking：6.0.0-GA elasticsearch：6.5.4 rocketbot：最新（master分支）2019.04.12 skywalking官网 skywalking 可以使用 H2、elasticsearch、MySql做为数据存储，推荐使用 elasticsearch 网上有相关的 docker-compose （参考），但是只有 5.0.0 版本的 Install安装 elasticsearch本次安装的版本：6.5.4（单机部署），使用 docker 安装 skywalking 6.0.0-GA 支持 6.x 版本以上 elasticsearch（用过 5.x 版本，安装失败，未使用 7.x 版本） 官方安装文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 12docker pull elasticsearch:6.5.4docker run -p 9200:9200 -p 9300:9300 -v esdata:/usr/share/elasticsearch/data -d --name es 93109ce1d590 docker images： 1elasticsearch 6.5.4 93109ce1d590 3 months ago 774MB 设置阿里镜像，不然很慢 安装 skywalkingskywalking 使用本地单机方式安装 下载在 apache 官网下载：https://www.apache.org/dyn/closer.cgi/incubator/skywalking/6.0.0-GA/apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 传至服务器并解压： 1tar -zxvf apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 配置配置 ./config/application.yml 设置地址信息和TTL信息： 1234567891011121314151617core: default: restHost: 0.0.0.0 restPort: 12800 restContextPath: / gRPCHost: 192.168.173.113 gRPCPort: 11800 downsampling: - Hour - Day - Month # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted. recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; # Unit is minute minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; # Unit is minute hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; # Unit is hour dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; # Unit is day monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; # Unit is month 使用 elasticsearch 做为 storage，注释掉默认的 H2 配置 12345678910111213141516171819storage:# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125; elasticsearch: # nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html # Execute the bulk every 2000 requests bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # flush the bulk every 20mb bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 10 seconds whatever the number of requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # the number of concurrent requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; 相关告警规则设置：./config/alarm-settings.yml 启动在 ./bin 目录下，有相关的启动脚本，主要的是： startup.sh 启动 server 和 UI oapService.sh 单独启动 server webappService.sh 单独启动UI Agent官方文档 将 /agent 目录 copy 至需要监控服务的服务器，目录结构： activations config：配置 logs：日志 optional-plugins：可选插件 plugins：启用的插件 skywalking-agent.jar：执行jar文件 配置配置文件：./config/agent.config 123456# 配置应用的名称 The service name in UIagent.service_name=$&#123;SW_AGENT_NAME:Your_ApplicationName&#125;# 配置server collector地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.173.113:11800&#125;# 日志级别logging.level=$&#123;SW_LOGGING_LEVEL:DEBUG&#125; 启动这里使用的是用 jar 启动的方式（tomcat war启动的方式见官方文档） 在 java -jar 中增加 skywalking agent 参数（必须在 -jar 前面）: 1java -javaagent:/home/wl/skywalking-agent/skywalking-agent.jar -DSW_AGENT_NAME=xxx -jar xxx.jar 安装 Rocketbot由于 skywalking 自带的UI不是特别友好，这里选择使用 Rocketbot GitHub地址：https://github.com/TinyAllen/rocketbot 这里使用的是 docker 安装的方式，按照 GitHub 的教程安装即可（此次安装由于 Rocketbot 的 shell 脚本问题，搞的久了点） 按照步骤： 1234npm installnpm run builddocker build -t rocketbot .docker run -p 8080:80 -d -e SKYWALKING_URL=192.168.173.113:12800 rocketbot 注意：在 docker run 的时候，由于 rockerbot 容器中没有 skywalking，指定的 SKYWALKING_URL 必须是ip地址 相关参考 elasticsearch 官网 skywalking 官网 APM巅峰对决：skywalking P.K. Pinpoint]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>skywalking</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos版本迭代整理（持续更新）]]></title>
    <url>%2F2019%2F03%2F07%2Fmicro-service%2Fnacos%E7%89%88%E6%9C%AC%E8%BF%AD%E4%BB%A3%E6%95%B4%E7%90%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[官方文档：https://nacos.io/zh-cn/index.html 官方博客：https://nacos.io/zh-cn/blog/index.html 核心功能： 注册中心 配置中心 nacos服务监控：https://nacos.io/zh-cn/docs/monitor-guide.html 0.9.0发布时间：2019.2.28 Nacos 0.9.0 发布，稳定的快速迭代 Nacos 0.9.0版本发布啦 更新内容： Nacos-Sync稳定性提升 Nacos Server功能拆分部署（通过启动参数实现拆分部署） 启动Nacos server时候，增加-f参数，意思是function mode，和对应模块标示来进行启动，如果不穿，或者传入有误，都将启动全部功能。 配置中心参数对应config，注册中心参数对应naming Nacos python语言体系的支持 1.0.0发布时间：2019.4.10 Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 相关博客 阿里巴巴基于 Nacos 实现环境隔离的实践 2019.3.13 Spring Cloud Alibaba系列教程-03-搭建生产可用的Nacos集群 2019.04.12]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos做为注册中心]]></title>
    <url>%2F2019%2F03%2F06%2Fmicro-service%2Fnacos%E5%81%9A%E4%B8%BA%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[Nacos 是一个更易于帮助构建云原生应用的动态服务发现、配置和服务管理平台，提供「注册中心」、「配置中心」和「动态DNS服务」三大功能。 使用的相关版本： nacos server：0.9.0 nacos client：0.9.1 spring boot：1.5.17.RELEASE spring cloud：Edgware.SR4 spring-cloud-starter-alibaba-nacos-discovery：0.1.1.RELEASE（对应spring boot 1.x版本） nacos官方文档：https://nacos.io 部署nacos server，按照官方文档部署就行（分为单机部署和集群部署，两者的启动方式稍有不同），现已支持拆分部署 下面介绍的是和spring cloud做集成 相关对比 比较点 Eureka Zookeeper Consul Nacos 运维熟悉度 相对陌生 熟悉 更陌生 陌生 一致性（CAP） AP CP AP AP 一致性协议 HTTP 定时轮训 ZAB RAFT ～ 通讯方式 HTTP REST 自定义协议 HTTP REST ～ 更新机制 Peer 2 Peer（服务器之间） + Scheduler（服务器和客户端） ZK Watch Agent 监听的方式 ～ 适用规模 &lt; 30K &lt;20K &lt;5K 100K+ 性能问题 简单的更新机制、复杂设计、规模较大时 GC 频繁 扩容麻烦、规模较大时 GC 频繁 3K 节点以上，更新列表缓慢 刚开源 dashboard 有 没有，可以自己实现 有 有 各自缺点： Eureka： 客户端注册服务上报所有信息，节点多的情况下，网络，服务端压力过大，且浪费内存 客户端更新服务信息通过简单的轮询机制，当服务数量巨大时，服务器压力过大。 集群伸缩性不强，服务端集群通过广播式的复制，增加服务器压力 Eureka2.0 闭源（Spring Cloud最新版本还是使用的1.X版本的Eureka） Zookeeper： 维护成本较高，客户端，session状态，网络故障等问题，会导致服务异常 集群伸缩性限制，内存，GC和连接 主节点挂的情况下，会进行leader选举，在此过程中服务将不可用 无控制台管理 Consul： 未经大规模市场验证，无法保证可靠性 Go语言编写，内部异常排查困难 Nacos： 刚刚开源不久，社区热度不够，依然存在bug 上面对比摘自与 小马哥技术周报 简单使用加入依赖： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;!-- spring boot 1.x使用0.1.x版本，spring boot 2.x使用0.2.x版本 --&gt; &lt;version&gt;0.1.1.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 这里需要替换 nacos-client 版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 注意点： spring-cloud-starter-alibaba-nacos-discovery 依赖的版本和 spring boot 版本有关 spring-cloud-starter-alibaba-nacos-discovery 默认使用的 nacos-client 的版本较低，会有问题（比如namespace设置无效），这里替换了较高的版本 application.properties： 123456spring.application.name=nacos-testserver.port=8525# nacos server地址spring.cloud.nacos.discovery.server-addr=192.168.173.80:8848# namespace idspring.cloud.nacos.discovery.namespace=077d70f7-e430-4b4c-926a-44a9bfef003c 其它配置可以参考官网 注意：这里设置的namespace是界面上显示的id，不设置会进入public默认的命名空间 namespace：常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等 启动服务：]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java拦截器（interceptor）和过滤器（filter）]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E6%8B%A6%E6%88%AA%E5%99%A8%EF%BC%88interceptor%EF%BC%89%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%88filter%EF%BC%89%2F</url>
    <content type="text"><![CDATA[从概念上来讲，filter是servlet规范定义的，而interceptor是spring定义的 过滤器和拦截器在对请求进行拦截时： 发生的时机不一样，filter是在servlet容器外，interceptor在servlet容器内，且可以对请求的3个关键步骤进行拦截处理 另外filter在过滤是只能对request和response进行操作，而interceptor可以对request、response、handler、modelAndView、exception进行操作。 相关DEMO： 过滤器（Filter）：12345678910111213141516171819202122232425262728293031323334353637383940@Component@WebFilter(filterName = "urlFilter", urlPatterns = "/test")// 配置拦截路径public class UrlFilter implements Filter &#123; /** * filter初始化的时候调用，即web容器启动时调用 * web容器启动时根据web.xml文件，依次加载ServletContext -&gt; listener -&gt; filter -&gt; servlet * * @param filterConfig * @throws ServletException */ @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println("UrlFilter init..."); &#125; /** * filter执行功能，根据参数来看，可以对request,response和chain（是否放行）进行操作 * * @param request * @param response * @param chain * @throws IOException * @throws ServletException */ @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println("UrlFilter doFilter before..."); chain.doFilter(request, response); System.out.println("UrlFilter doFilter after..."); &#125; /** * filter在服务器正常关闭(比如System.exit(0))等情况下会调用 */ @Override public void destroy() &#123; System.out.println("UrlFilter destroy..."); &#125;&#125; 拦截器（Interceptor）12345678910111213141516171819@Componentpublic class UrlInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("UrlInterceptor preHandle..."); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("UrlInterceptor postHandle..."); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("UrlInterceptor afterCompletion..."); &#125;&#125; 注册拦截器：1234567891011@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Autowired private UrlInterceptor urlInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(urlInterceptor).addPathPatterns("/test"); &#125;&#125; 执行结果分析 这里用的是spring boot来搭建并启动web服务（使用spring boot bean的方式配置） 123456789@RestControllerpublic class TestController &#123; @GetMapping(value = "/test") public String test() &#123; System.out.println("do test..."); return "ok"; &#125;&#125; 访问该api打印日志：123456UrlFilter doFilter before...UrlInterceptor preHandle...do test...UrlInterceptor postHandle...UrlInterceptor afterCompletion...UrlFilter doFilter after... 相关博客文章： https://blog.csdn.net/dshf_1/article/details/81112595]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java各版本异步并发编程]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E5%90%84%E7%89%88%E6%9C%AC%E5%BC%82%E6%AD%A5%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[所谓异步调用其实就是实现一个可无需等待被调用函数的返回值而让操作继续运行的方法。在 Java 语言中，简单的讲就是另启一个线程来完成调用中的部分计算，使调用继续运行或返回，而不需要等待计算结果 java5之前在java5之前，主要通过 Thread 或者实现 Runnable 来创建线程，可以通过 Thread 的一些方法来控制线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ThreadDemo &#123; public static void main(String[] args) &#123; normalThread(); completableThread(); &#125; /** * 普通线程 */ private static void normalThread() &#123; Thread thread = new Thread(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()), "Sub"); thread.start(); System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); &#125; /** * 获取线程是否已经完成 * 在获取 completableRunnable.isCompleted() 值时并不一定是true * 我们会想到可见性的问题，所以在 completed 字段加上 volatile 关键字 * 但是还是会出现上面的问题，这里涉及到线程的执行顺序，当Sub线程还未执行到 completed = true; 时，主线程已经执行完了 * 要解决这个问题需要使用 thread.join() 方法，主线程等待Sub线程执行完成 */ private static void completableThread() &#123; CompletableRunnable completableRunnable = new CompletableRunnable(); Thread thread = new Thread(completableRunnable, "Sub"); thread.start();// try &#123;// thread.join();// &#125; catch (InterruptedException e) &#123;// e.printStackTrace();// &#125; System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); System.out.printf("runnable is completed : " + completableRunnable.isCompleted()); &#125; /** * 可完成的 */ private static class CompletableRunnable implements Runnable&#123; private boolean completed = false; @Override public void run() &#123; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()); completed = true; &#125; public boolean isCompleted() &#123; return completed; &#125; &#125;&#125; java5之前实现的局限性： 缺少线程管理的原生支持（没有线程池） 缺少”锁”的api（缺少Lock这样的api） 缺少执行完成的原生支持 执行结果获取困难 java5线程池java5增加了线程池，由 Doug Lea 编写 12345678910111213public class ExecutorDemo &#123; public static void main(String[] args) &#123; // 执行器服务，线程池 ThreadPoolExecutor 是它的一种实现 ExecutorService executor = Executors.newFixedThreadPool(1); executor.execute(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName())); // 合理的关闭线程池是非常重要的 executor.shutdown(); &#125;&#125; Future增加了 Future，提供了可以获取执行结果的方法（Callable是有返回值操作，相对于Runnable） 12345678910111213141516171819202122232425public class FutureDemo &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(1); Future&lt;String&gt; future = executorService.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return "[Thread : " + Thread.currentThread().getName() + "]Hello World..."; &#125; &#125;); // 可以知道该线程是否执行完成// future.isDone(); try &#123; String v = future.get(); System.out.println(v); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; executorService.shutdown(); &#125;&#125; Future的限制： 无法手动完成 阻塞式结果返回 future.get() 无法链式调用多个Future，从 ExecutorService#invokeAll 方法中只能返回Future的集合 无法合并多个Future的结果，从 ExecutorService#invokeAll 方法中只能返回Future的集合 java7Fork/JoinForkJoin是Java7提供的原生多线程并行处理框架，其基本思想是将大人物分割成小任务，最后将小任务聚合起来得到结果。 它非常类似于HADOOP提供的MapReduce框架，只是MapReduce的任务可以针对集群内的所有计算节点，可以充分利用集群的能力完成计算任务。ForkJoin更加类似于单机版的MapReduce Fork/Join使用两个类完成以上两件事情： ForkJoinTask： 我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join的操作机制，通常我们不直接继承ForkjoinTask类，只需要直接继承其子类。 RecursiveAction，用于没有返回结果的任务 RecursiveTask，用于有返回值的任务 ForkJoinPool： task要通过ForkJoinPool来执行，分割的子任务也会添加到当前工作线程的双端队列中，进入队列的头部。当一个工作线程中没有任务时，会从其他工作线程的队列尾部获取一个任务。 计算整数之和 DEMO：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ForkJoinDemo &#123; public static void main(String[] args) &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); LongAccumulator accumulator = new LongAccumulator(((left, right) -&gt; left + right), 0); List&lt;Long&gt; params = new ArrayList&lt;&gt;(); for (long i = 0; i &lt; 10000000; i++) &#123; params.add(i); &#125; long start = System.currentTimeMillis(); forkJoinPool.invoke(new LongSumTask(params, accumulator)); long end = System.currentTimeMillis(); System.out.println(accumulator.get()); System.out.printf("消耗时间：%d %s\n", end - start, "ms"); forkJoinPool.shutdown(); &#125; static class LongSumTask extends RecursiveAction &#123; private final List&lt;Long&gt; elements; private final LongAccumulator accumulator; LongSumTask(List&lt;Long&gt; elements, LongAccumulator accumulator) &#123; this.elements = elements; this.accumulator = accumulator; &#125; @Override public void compute() &#123; int size = elements.size(); int parts = size / 2; // 使用简单的二分法，将计算平分，当元素只有一个的时候使用 LongAccumulator 进行累加计算 if (size &gt; 1) &#123; List&lt;Long&gt; left = elements.subList(0, parts); List&lt;Long&gt; right = elements.subList(parts, size); new LongSumTask(left, accumulator).fork().join(); new LongSumTask(right, accumulator).fork().join(); &#125; else &#123; if (elements.isEmpty()) &#123; return; &#125; Long num = elements.get(0); accumulator.accumulate(num); &#125; &#125; &#125;&#125; java8CompletableFuture在Java8中，CompletableFuture 提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法 CompletableFuture 实现了 Future 和 CompletionStage123public class CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt; &#123; // ...&#125; 相关的操作可以查看官方API或者相关博客 DEMO：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class CompletableFutureDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 1. 完成操作（可以被其它线程去做）// CompletableFuture&lt;String&gt; completableFuture = new CompletableFuture&lt;&gt;();// completableFuture.complete("Hello World");// String v = completableFuture.get();// System.out.println(v); // 2. runAsync 异步执行，阻塞操作// CompletableFuture asyncCompletableFuture = CompletableFuture.runAsync(() -&gt; &#123;// System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// // 这里仍然是阻塞的// asyncCompletableFuture.get();//// System.out.println("Starting..."); // 3. supplyAsync 异步执行，阻塞操作// CompletableFuture&lt;String&gt; asyncCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123;// // 获取数据操作，比如来自于数据库// return String.format("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// String v = asyncCompletableFuture.get();// System.out.println(v);// System.out.println("Starting..."); // 4. 合并操作 CompletableFuture&lt;String&gt; combinedCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; // 获取数据操作，比如来自于数据库 return String.format("[Thread : %s]Hello World...", Thread.currentThread().getName()); &#125;).thenApply(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " - 来自于数据库"; &#125;).thenApplyAsync(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " at " + LocalDate.now(); &#125;).exceptionally(e -&gt; &#123; // 异常处理 e.printStackTrace(); return ""; &#125;); while (!combinedCompletableFuture.isDone()) &#123; &#125; String v = combinedCompletableFuture.get(); System.out.println(v); System.out.println("Starting..."); &#125;&#125; 事实上，如果每个操作都很简单的话，没有必要用这种多线程异步的方式，因为创建线程还需要时间，还不如直接同步执行来得快。 事实证明，只有当每个操作很复杂需要花费相对很长的时间（比如，调用多个其它的系统的接口）的时候用 CompletableFuture 才合适，不然区别真的不大，还不如顺序同步执行。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在sonarqube的pmd插件中整合阿里p3c开发规范]]></title>
    <url>%2F2019%2F02%2F28%2Fdevops%2F%E5%A6%82%E4%BD%95%E5%9C%A8sonarqube%E7%9A%84pmd%E6%8F%92%E4%BB%B6%E4%B8%AD%E6%95%B4%E5%90%88%E9%98%BF%E9%87%8Cp3c%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[sonar-pmd是sonar官方的支持pmd的插件，但是还不支持p3c，需要在pmd插件源码中添加p3c支持(p3c是阿里在pmd基础上根据阿里巴巴开发手册实现了其中的49开发规则) 插件源码下载地址：https://github.com/mrprince/sonar-p3c-pmd 阿里p3c github：https://github.com/alibaba/p3c 此次使用的sonar版本：6.5 此源码工程已经添加了P3C支持：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.p3c&lt;/groupId&gt; &lt;artifactId&gt;p3c-pmd&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 在这个PMD插件中，已经在默认的268条规则上增加了48条阿里代码规则 修改PMD插件源码相关文件： pmd.properties (src/main/resources/org/sonar/l10n/pmd.properties) rules-p3c.xml (src/main/resources/org/sonar/plugins/pmd/rules-p3c.xml) pmd-model.xml (src/main/resources/com/sonar/sqale/pmd-model.xml) 增加规则该规范中少了一条 AvoidManuallyCreateThreadRule 规则，以添加该规则为例子 在 pmd.properties 中增加规则名称：1rule.pmd.AvoidManuallyCreateThreadRule.name=[p3c]avoid manually create thread. 在 rules-p3c.xml 中增加对应的p3c规则：1234&lt;rule key="AvoidManuallyCreateThreadRule"&gt; &lt;priority&gt;MAJOR&lt;/priority&gt; &lt;configKey&gt;&lt;![CDATA[rulesets/java/ali-concurrent.xml/AvoidManuallyCreateThreadRule]]&gt;&lt;/configKey&gt;&lt;/rule&gt; 在 pmd-model.xml 增加：12345678910111213&lt;chc&gt; &lt;rule-repo&gt;pmd&lt;/rule-repo&gt; &lt;rule-key&gt;AvoidManuallyCreateThreadRule&lt;/rule-key&gt; &lt;prop&gt; &lt;key&gt;remediationFunction&lt;/key&gt; &lt;txt&gt;CONSTANT_ISSUE&lt;/txt&gt; &lt;/prop&gt; &lt;prop&gt; &lt;key&gt;offset&lt;/key&gt; &lt;val&gt;2&lt;/val&gt; &lt;txt&gt;min&lt;/txt&gt; &lt;/prop&gt;&lt;/chc&gt; 在 src/main/resources/org/sonar/l10n/pmd/rules/pmd-p3c 包中增加相关sonar举例（必须增加，不然测试用例跑不通）：12345&lt;p&gt;Look for qualified this usages in the same class.&lt;/p&gt;&lt;p&gt;Examples:&lt;/p&gt;&lt;pre&gt; // 新增规则，没有示例&lt;/pre&gt; 如果要删除规则，按照上面的方式删除即可 其它设置修改p3c提示语可以下载阿里p3c源码，源码地址：https://github.com/alibaba/p3c 描述内容都在 p3c/p3c-pmd/src/main/resources/messages.xml 文件中，修改其中的描述内容即可 然后将其maven打包（可以deploy在公司的私有仓库中） 修改pmd插件在sonarqube中的插件显示名可以修改 sonar-p3c-pmd 工程中的 PmdConstants 类 REPOSITORY_NAME 值即可 sonar配置整合插件将 sonar-p3c-pmd 插件通过maven打包，然后将打好的jar包放在sonar目录下的 extensions/plugins 目录中 重启 sonar 服务，通过 ./bin/linux-x86-64/sonar.sh restart 命令 查看插件是否安装正确（如果sonar启动失败，表示插件有问题） 创建质量配置在质量配置页面中，创建一个java规则 创建完成以后，进行激活规则操作，在资源库中找到上传的插件进行激活相关p3c规则 在项目中配置对应的质量规则即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置优化]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参数作用域 全局参数（global）： 1set global autocommit = ON/OFF; 会话参数（session），会话参数不单独设置则会采用全局参数： 1set session autocommit = ON/OFF; 注意点： 全局参数的设定对于已经存在的会话无法生效（需要重新开启会话） 会话参数的设定随着会话的销毁而失效 全局类的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效 配置文件mysql --help 寻找配置文件的位置和加载顺序： 12Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 因为参数比较多，可以通过命令过滤： 1mysql --help | grep -A 1 &apos;Default options are read from the following files in the given order&apos; 连接数配置设置 max_connections 可配置最大连接数，mysql5.6 默认是151个连接： 12345+--------------------+-------+| Variable_name | Value |+--------------------+-------+| max_connections | 151 |+--------------------+-------+ 这个设置受其它两个配置影响： 系统句柄数配置 使用 ulimit -a 或者查看 /etc/security/limits.conf 配置文件 1open files (-n) 65535 mysql句柄数配置 查看 /usr/lib/systemd/system/mysqld.service 配置文件 1LimitNOFILE = 6000 内存参数配置 sort_buffer_size connection 排序缓冲区大小 当查询语句中有需要文件排序功能时，马上为 connection 分配配置的内存大小，建议256K（默认值）～ 2M之内 join_buffer_size connection关联查询缓冲区大小 当查询语句中有关联查询时，马上分配配置大小的内存用这个关联查询，所以有可能在一个查询语句中会分配很多个关联查询缓冲区 ，建议256K（默认值）～1M之间 Innodb_buffer_pool_size innodb buffer/cache 的大小（默认128M） innodb buffer/cache中存着数据缓存、索引缓存、缓冲数据、内部结构这些数据，所以大的缓冲池可以减小多次磁盘I/O访问相同的表数据以提高性能 计算公式： 1Innodb_buffer_pool_size = (总物理内存 - 系统运行所用 - connection 所用) * 90% 其它参数配置参考帖子：https://www.cnblogs.com/wyy123/p/6092976.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql MVCC]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-MVCC%2F</url>
    <content type="text"><![CDATA[MVCC：Multiversion concurrency control （多版本并发控制） 并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的堵塞，从而引发读操作的并发问题。 Mysql中MVCC逻辑流程在我们的 mysql 表中，都会有个默认列： DB_TRX_ID：数据行的版本号 DB_ROLL_PT：删除版本号 这些版本号就是事务ID 插入 在数据行版本号中，加入当前的事务ID 删除 在删除版本号中，加入当前的事务ID 这里需要注意的是，虽然数据删除了，但是 mysql 中还是有记录的 修改 修改操作是先做命中的数据行的copy，将原行数据的删除版本号的值设置为当前的事务ID 查询 规则： 查询数据行版本早于当前事务版本的数据行 行的版本号小于或等于事务ID，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的 查找删除版本号为NULL或者大于当前事务版本号的记录 确保取出来的行记录在事务开启之前没有被删除 Mysql中MVCC版本控制案例数据准备： 12insert into teacher(name,age) value (&apos;seven&apos;,18); insert into teacher(name,age) value (&apos;qing&apos;,20); 执行语句： 123456789##### tx1 #####begin; -- 1select * from users ; -- 2commit;##### tx2 #####begin; -- 3update teacher set age =28 where id =1; -- 4commit; 案例一上面的执行语句顺序：1，2，3，4，2 按照MVCC的流程，当update语句还没有提交之前，再去select查询时，还是读到的是之前的数据，符合预期 案例二上看的执行语句顺序：3，4，1，2 这次是先update，然后在select，这里都没有做commit操作，按照MVCC的流程，select读取到了update没有提交的数据，为什么会这样？ 如果按照MVCC流程会有这个问题，但是，在执行update时，会上X锁，这时候select会去做快照读，看下面的分析 Undo log 实现事务的原子性 事务处理过程中如果出现了错误或者用户执行了 ROLLBACK 语句，Mysql可以利用Undo Log中的备份将数据恢复到事务开始之前的状态 在 InnoDB 中用来实现多版本并发控制 事务未提交之前，Undo保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读 快照读： SQL读取的数据是快照版本，也就是历史版本，普通的SELECT就是快照读 InnoDB快照读，数据的读取将由 cache（事务修改过的数据） + undo（原本数据） 两部分组成 当前读： SQL读取的数据是最新版本 通过锁机制来保证读取的数据无法通过其他事务进行修改 UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE都是当前读 Redo logredo log是为了实现事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的未入磁盘数据进行持久化这一特性 指定redo log记录在 {datadir}/ib_logfile1&amp;ib_logfile2 可通过 innodb_log_group_home_dir 配置指定 目录存储 一旦事务成功提交且数据持久化落盘之后，此时redo log中的对应事务数据记录就失去了意义，所以redo log的写入是日志文件循环写入的 指定redo log日志文件组中的数量 innodb_log_files_in_group 默认为2 指定redo log每一个日志文件最大存储量 innodb_log_file_size 默认48M 指定redo log在 cache/buffer 中的 buffer 池大小 innodb_log_buffer_size 默认16M Redo buffer 持久化Redo log的策略， Innodb_flush_log_at_trx_commit : 取值 0 每秒提交 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（可能丢失一秒内的事务数据） 取值 1 每次事务提交执行 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（默认值，最安全，性能最差的方式） 取值 2 每次事务提交执行 Redo buffer -&gt; Redo log OS cache 再每一秒执行 -&gt; flush cache to disk]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql InnoDB锁机制]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-InnoDB%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[表锁和行锁锁是用于管理不同事务对共享资源的并发访问 表锁与行锁的区别: 锁定粒度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 InnoDB 存储引擎支持行锁和表锁（表锁是通过行锁实现的） InnoDB 锁类型锁类型： 共享锁（行锁）：Shared Locks 排它锁（行锁）：Exclusive Locks 意向共享锁（表锁）：IntentionShared Locks 意向排它锁（表锁）：Intention Exclusive Locks 自增锁：AUTO-INC Locks 行锁的算法： 记录锁 Record Locks 间隙锁 Gap Locks 临键锁 Next-key Locks 共享锁与排他锁共享锁又称为读锁，简称 S锁 ，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改 加锁释锁方式： 12select * from users WHERE id=1 LOCK IN SHARE MODE; commit/rollback; 举个例子： 12345678### session1 ###begin;select * from sys_user where id=1 lock in share mode; # 获取S锁commit;### session2 ###select * from sys_user where id=1; # 可以正常执行update sys_user set name=&apos;k2&apos; where id=1; # 当上面没有commit，该语句将被阻塞 排他锁又称为写锁，简称 X锁 ，排他锁不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的锁（共享锁、排他锁），只有该获取了排他锁的事务是可以对数据行进行读取和修改，（其他事务要读取数据可来自于快照） 加锁释锁方式： 123delete / update / insert 默认加上X锁SELECT * FROM table_name WHERE ... FOR UPDATE;commit/rollback; 例子： 123456789### session1 ###begin;update sys_user set name=&apos;k3&apos; where id=1; # 自动获取X锁commit;### session2 ###select * from sys_user where id=1 for update; # 等待上面commitselect * from sys_user where id=1 lock in share mode; # 等待上面commitselect * from sys_user where id=1; # 没影响 那么 InnoDB 行锁到底锁了什么？InnoDB的行锁是通过给索引上的索引项加锁来实现的 只有通过索引条件进行数据检索，InnoDB才使用行级锁，否则，InnoDB 将使用表锁（锁住索引的所有记录） 所以在执行 delete / update / insert 时，也需要考虑索引，因为没有命中索引会变成表锁 表锁： 1lock tables xx read/write; 意向共享锁与意向排它锁 意向共享锁（IS） 表示事务准备给数据行加入共享锁，即一个数据行加共享锁前必须先取得该表的IS锁 意向排它锁（IX） 表示事务准备给数据行加入排他锁，即一个数据行加排他锁前必须先取得该表的IX锁 简单来说，这两种锁就是一个标志位，在拿锁之前，先要判断IS/IX 意向锁（IS、IX）是 InnoDB 数据操作之前自动加的，不需要用户干预 当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁 自增锁针对自增列自增长的一个特殊的表级别锁 1show variables like &apos;innodb_autoinc_lock_mode&apos;; 默认取值1，代表连续，事务未提交ID永久丢失 记录锁、间隙锁、临键锁临键锁（Next-Key）临键锁是 InnoDB 默认的行锁算法 当sql执行按照索引进行数据的检索时，查询条件为范围查找（between and、&lt;、&gt;等）并有数据命中，则此时sql语句加上的锁为 Next-Key locks，锁住索引的记录 + 区间（左开右闭） 例子： 当数据库里与 id 为1、4、7、10四条数据，那么： 它可以有效的方式幻读 间隙锁（Gap）当sql执行按照索引进行数据的检索时，查询条件的数据不存在，这时sql语句加上的锁即为Gap locks，锁住索引不存在的区间（左开右开） Gap locks只在RR事务隔离级别存在 记录锁（Record）当sql执行按照唯一性（Primary key、Unique key）索引进行数据的检索时，查询条件等值匹配且查询的数据时存在，这时sql语句加上的锁为记录锁，锁住具体的索引项 锁是如何解决事务并发解决脏读 解决不可重复读 解决幻读 死锁当2个或以上事务都在等待对方释放锁，产生循环等待，即形成了死锁 如何解决： 类似的业务逻辑以固定的顺序访问表和行 大事务拆小（大事务更倾向于死锁） 在同一个事务中，尽可能做到一次锁定所需要的所有资源 如果业务允许，可以降低事务隔离级别 为表添加合适的索引（如果不走索引将会为表的每一行记录添加上锁，产生表锁）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作，事务是一组不可再分割的操作集合（工作逻辑单元） mysql中如何开启事务： 123begin / start transaction -- 手工commit / rollback -- 事务提交或回滚set session autocommit = on/off; -- 设定事务是否自动开启 事务ACID特性 原子性（Atomicity） 最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚 一致性（Consistency） 事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致 隔离性（Isolation） 一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般设定为不可见） 持久性（Durability） 事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失 事务并发带来的问题脏读： 不可重复读： 幻读： 事务隔离级别SQL92 ANSI/ISO标准：http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt 隔离级别 解决问题 说明 Read Uncommitted（未提交读） 未解决并发问题 事务未提交对其他事务也是可见的，产生脏读 Read Committed（提交读） 脏读 一个事务开始之后，只能看到自己提交的事务所做的修改，产生不可重复读 Repeatable Read（可重复读） 不可重复读 在同一个事务中多次读取同样的数据结果是一样的，这种隔离级别未定义解决幻读的问题 Serializable（串行化） ALL 最高的隔离级别，通过强制事务的串行执行 InnoDB对事物隔离级别的支持 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（未提交读） 可能 可能 可能 Read Committed（提交读） 不可能 可能 可能 Repeatable Read（可重复读） 不可能 不可能 对InnoDB不可能 Serializable（串行化） 不可能 不可能 不可能 在 InnoDB 引擎中，默认隔离级别是Repeatable Read（可重复读），也可以防止幻读 隔离级别到底是如何实现的？ 锁、MVVC]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询优化]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Mysql 查询执行路径 Mysql 客户端/服务端通信](#Mysql 客户端/服务端通信) 查询缓存 查询优化处理 查询执行引擎 返回客户端 详解Mysql 客户端/服务端通信Mysql客户端与服务端的通信方式是“半双工” 全双工：双向通信，发送同时也可以接收 半双工：双向通信，同时只能接收或者是发送，无法同时做操作 单工：只能单一方向传送 半双工通信：在任何一个时刻，要么是有服务器向客户端发送数据，要么是客户端向服务端发送数据，这两个动作不能同时发生。所以我们无法也无需将一个消息切成小块进行传输 特点和限制：客户端一旦开始发送消息，另一端要接收完整个消息才能响应。 客户端一旦开始接收数据没法停下来发送指令。 通信查询状态对于一个mysql连接，或者说一个线程，时刻都有一个状态来标识这个连接正在做什么 官方状态全集：https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html 我们可以通过以下命令查看： 12show full processlist;show processlist; 执行结果： 1234567mysql&gt; show processlist;+------+------+-----------+------+---------+------+-------+------------------+| Id | User | Host | db | Command | Time | State | Info |+------+------+-----------+------+---------+------+-------+------------------+| 9543 | root | localhost | NULL | Query | 0 | init | show processlist |+------+------+-----------+------+---------+------+-------+------------------+1 row in set (0.00 sec) 整理常见的状态： 状态 说明 Sleep 线程正在等待客户端发送数据 Query 连接形成正在执行查询 Locked 线程正在等待表锁的释放 Sorting result 线程正在对结果进行排序 Sending data 向请求端发送数据 可以通过 kill {id} 的方式进行杀除连接 查询缓存工作原理： 缓存 SELECT 操作的结果集和SQL语句 新的 SELECT 语句，先去查询缓存，判断是否存在可用的记录集 判断标准： 与缓存的SQL语句是否完全一样（区分大小写） 查看缓存设置通过 show variables like &#39;query_cache%&#39;; 命令查询： 1234567891011mysql&gt; show variables like &apos;query_cache%&apos;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+5 rows in set (0.00 sec) query_cache_type 0：不启用查询缓存，默认值 1：启用查询缓存，只要符合查询缓存要求，客户端的查询语句和记录集都可以缓存起来（加上 SQL_NO_CACHE 将不缓存） 2：启用查询缓存，只要查询语句中添加参数 SQL_CACHE ，且符合查询缓存的要求，客户端的查询语句和记录集都可以缓存起来 query_cache_size总的缓存池的大小，允许设置最小值为 40K，默认 1M，推荐设置为 ：32M、64M、128M 超过该大小，会将之前的缓存失效 query_cache_limit限制单次查询，缓存区最大能缓存的查询记录集，默认设置为 1M 查看缓存情况可以通过 show status like &#39;Qcache%&#39;;： 1234567891011121314mysql&gt; show status like &apos;Qcache%&apos;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031352 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 150 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+8 rows in set (0.00 sec) 不会缓存的情况 当查询语句中有一些不确定的数据时，则不会被缓存 如包含函数 NOW() 、CURRENT_DATE() 等类似的函数，或者用户自定义的函数，存储函数，用户变量等都不会被缓存 当查询的结构大于 query_cache_limit 设置的值时 对于 InnoDB 引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之后，所有与这个表相关的查询都无法被缓存 update table set name=’hello’ where id=3; 查询的表是系统表 查询语句不涉及到表 select 1; 为什么Mysql默认关闭了缓存 在查询之前必须先检查是否命中缓存，浪费计算资源 如果这个查询可以缓存，那么执行完成后，Mysql发现查询缓存中没有这个查询，则会将结构存入查询缓存，带来额外的系统消耗 针对表进行写入或更新操作时，将对应表的所有缓存都设置失效 如果查询缓存很大或者碎片很多时，这个操作可能带来很大的系统消耗 适用场景： 以读为主的业务，数据生成之后就不常改变的业务 查询优化处理查询优化处理的三个阶段： 解析sql 通过lex词法分析，yacc语法分析将sql语句解析成解析树（Yacc 与 Lex语法教程） 预处理阶段 根据mysql的语法的规则进一步检查解析树的合法性，如：检查数据的表和列是否存在，解析名字和别名的设置。还会进行权限的验证 查询优化器 优化器的主要作用就是找到最优的执行计划 解析sql和预处理阶段主要是解析和校验的一个过程，我们重点来讲下查询优化器 查询优化器如何找到最优执行计划Mysql的查询优化器是基于成本计算的原则。他会尝试各种执行计划。 数据抽样的方式进行试验（随机的读取一个4K的数据块进行分析） 使用等价变化规则 5=5 and a&gt;5 改写成 a&gt;5 a5 and a=5 基于联合索引，调整条件位置 … 优化count 、min、max等函数 min函数只需找索引最左边 ，max函数只需要索引最右边 myisam引擎 count(*) 无需遍历全表 覆盖索引扫描 子查询优化 提前终止查询 用了limit关键字或者使用不存在的条件 IN的优化 先进性排序，再采用二分查找的方式（所以尽量使用 in ，而少用 or ） …… 执行计划使用 EXPLAIN ： 12345678910111213mysql&gt; explain select * from table01 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table01 type: systempossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 0 Extra: const row not found1 row in set (0.00 sec) idselect查询的序列号，标识执行的顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同又不同即两种情况同时存在，id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 select_type查询的类型，主要是用于区分普通查询、联合查询、子查询等 SIMPLE：简单的 select 查询，查询中不包含子查询或者 union PRIMARY：查询中包含子部分，最外层查询则被标记为 primary SUBQUERY/MATERIALIZED：SUBQUERY 表示在 select 或 where 列表中包含了子查询，MATERIALIZED 表示 where 后面 in 条件的子查询 UNION：若第二个 select 出现在 union 之后，则被标记为 union UNION RESULT：从union表获取结果的select table查询涉及到的表 直接显示表名或者表的别名 &lt;unionM,N&gt; 由ID为M,N 查询 union 产生的结果 由ID为N查询生产的结果 type访问类型，sql查询优化中一个很重要的指标，结果值从好到坏依次是： 1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL system：表只有一行记录（等于系统表），const 类型的特例，基本不会出现，可以忽略不计 const：表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引 eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描 ref：非唯一性索引扫描，返回匹配某个单独值的所有行，本质是也是一种索引访问 range：只检索给定范围的行，使用一个索引来选择行 index：Full Index Scan，索引全表扫描，把索引从头到尾扫一遍 ALL：Full Table Scan，遍历全表以找到匹配的行 在实际应用中，尽量要在 range 级别以上 possible_keys查询过程中有可能用到的索引 key实际使用的索引，如果为NULL，则没有使用索引 rows根据表统计信息或者索引选用情况，大致估算出找到所需的记录所需要读取的行数 filtered它指返回结果的行占需要读到的行（rows列的值）的百分比 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好 Extra十分重要的额外信息 Using filesort：mysql对数据使用一个外部的文件内容进行了排序，而不是按照表内的索引进行排序读取 Using temporary：使用临时表保存中间结果，也就是说mysql在对查询结果排序时使用了临时表，常见于order by 或 group by Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了访问表的数据行，效率高 Using where：使用了where过滤条件 select tables optimized away：基于索引优化MIN/MAX操作或者MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即可完成优化 查询执行引擎调用插件式的存储引擎的原子API的功能进行执行计划的执行 返回客户端 有需要做缓存的，执行缓存操作 增量的返回结果：开始生成第一条结果时，mysql就开始往请求方逐步返回数据 好处：mysql服务器无须保存过多的数据，浪费内存。用户体验好，马上就拿到了数据 慢查询分析定位如何定位慢SQL 业务驱动 测试驱动 慢查询日志 前面2种是通过人为的方式来定位，我们主要看下第三种方式 慢查询日志慢查询日志配置通过 show variables like &#39;slow_query_log&#39;; 查看： 1234567mysql&gt; show variables like &apos;slow_query_log&apos;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+1 row in set (0.00 sec) 通过 set global slow_query_log = on 开启日志 查看日志文件地址： 12345678mysql&gt; show variables like &apos;slow_query%&apos;;+---------------------+-------------------------------------------+| Variable_name | Value |+---------------------+-------------------------------------------+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/instance-dq9parum-slow.log |+---------------------+-------------------------------------------+2 rows in set (0.00 sec) 如上所示，日志地址在 /var/lib/mysql/instance-dq9parum-slow.log 通过 set global log_queries_not_using_indexes = on 设置没有命中索引的需要记录日志 通过 set global long_query_time = 0.1 （单位：秒）设置查询超过多少时间的需要记录日志 慢查询日志分析查看 /var/lib/mysql/instance-dq9parum-slow.log： 12345# Time: 181219 22:39:30# User@Host: root[root] @ [36.22.250.90] Id: 10887# Query_time: 0.000321 Lock_time: 0.000145 Rows_sent: 1 Rows_examined: 2SET timestamp=1545230370;select * from table01 where name in(&apos;name&apos;); Time：日志记录的时间 User@Host：执行的用户及主机 Query_time：查询耗费时间 Lock_time：锁表时间 Rows_sent：发送给请求方的记录条数 Rows_examined：语句扫描的记录条数 SET timestamp：语句执行的时间点 select ….：执行的具体语句 慢查询日志分析工具 mysqldumpslow mysqlsla pt-query-digest]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储引擎]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言介绍 插拔式的插件方式 存储引擎是指定在表之上的，即一个库中的每一个表都可以指定专用的存储引擎 不管表采用什么样的存储引擎，都会在数据区，产生对应的一个frm文件（表结构定义描述文件） 1-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user.frm 各存储引擎对比查看官网：https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html CSV 存储引擎数据存储以CSV文件： 1-rw-rw---- 1 mysql mysql 0 12月 18 19:27 table_csv.CSV 看其文件内容： 121,&quot;chen&quot;2,&quot;jian&quot; 存储的就是我们的表数据 特点： 不能定义索引、列定义必须为NOT NULL、不能设置自增列 不适用大表或者数据的在线处理 CSV数据的存储用 , 隔开，可直接编辑CSV文件进行数据的编排 数据安全性低（编辑之后，要生效使用flush table XXX 命令） 应用场景： 数据的快速导出导入 表格直接转换成CSV Archive 存储引擎压缩协议进行数据的存储，数据存储为 ARZ 文件格式 1-rw-rw---- 1 mysql mysql 8674 12月 18 19:40 table_archive.ARZ 特点： 只支持 insert 和 select 两种操作 只允许自增ID列建立索引 行级锁 不支持事务 数据占用磁盘少 应用场景： 日志系统 大量的设备数据采集 Memory 存储引擎数据都是存储在内存中，IO效率要比其他引擎高很多，服务重启数据丢失，内存数据表默认只有16M 特点： 支持hash索引，B tree索引，默认hash（查找复杂度 0(1) ） 字段长度都是固定长度 varchar(32)=char(32) 不支持大数据存储类型字段如 blog ，text 表级锁 应用场景： 等值查找热度较高数据 查询结果内存中的计算，大多数都是采用这种存储引擎作为临时表存储需计算的数据 实际应用中不常用 Myisam 存储引擎Mysql5.5 版本之前的默认存储引擎 较多的系统表也还是使用这个存储引擎 系统临时表也会用到 Myisam 存储引擎（Memory 存储引擎不支持的情况下，比如数据超过了16M） 12-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table_myisam.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table_myisam.MYI 特点： select count(*) from table 无需进行数据的扫描（有专门存储） 数据（.MYD）和索引（.MYI）分开存储 表级锁 不支持事务 InnoDB 存储引擎Mysql5.5及以后版本的默认存储引擎 1-rw-rw---- 1 mysql mysql 98304 12月 6 19:00 table_innodb.ibd 特点： 支持事务ACID 行级锁 聚集索引（主键索引）方式进行数据存储 支持外键关系保证数据完整性（尽量不要用）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql索引]]></title>
    <url>%2F2019%2F02%2F26%2Fmysql%2FMysql%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引是为了加速对表中数据行的检索而创建的一种分散存储的数据结构 为什么要用索引： 索引能极大的减少存储引擎需要扫描的数据量 索引可以把随机IO变成顺序IO 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表 Mysql 为什么使用 B+Tree二叉查找树 动画演示 平衡二叉查找树 动画演示 缺点： 太深了 数据处的(高)深度决定着他的IO操作次数，IO操作耗时大 太小了 每一个磁盘块(节点/页)保存的数据量太小了 没有很好的利用操作磁盘IO的数据交换特性 没有利用好磁盘IO的预读能力(空间局部性原理)，从而带来频繁的IO操作 多路平衡查找树动画演示 B-Tree B+Tree B-Tree 和 B+Tree区别 B+节点关键字搜索采用闭合区间 B+非叶节点不保存数据相关信息，只保存关键字和子节点的引用 B+关键字对应的数据保存在叶子节点中 B+叶子节点是顺序排列的，并且相邻节点具有顺序引用的关系 为什么选用 B+Tree B+树是B-树的变种(PLUS版)多路绝对平衡查找树，他拥有B-树的优势 B+树扫库、表能力更强 B+树的磁盘读写能力更强 B+树的排序能力更强 B+树的查询效率更加稳定 Mysql B+Tree 索引体现Myisam Engine 在 Myisam 引擎中，数据库对应的表会有这么几个文件 123-rw-rw---- 1 mysql mysql 8556 12月 18 16:30 table01.frm-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table01.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table01.MYI .MYD 文件存储的是具体的数据内容 .MYI 文件存储的是索引树 如上图，在 Myisam 引擎中，索引指向的是数据的地址 Innodb Engine 12-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user01.frm-rw-rw---- 1 mysql mysql 98304 12月 6 18:56 sys_user01.ibd 在 Innodb 引擎中，只有 .ibd 文件 Innodb 引擎中，它是以主键为索引来组织数据的存储（没有指定主键，它会隐式创建），它的叶子节点存储的是具体的数据 它分为主键索引（聚集索引）和辅助索引（非聚集索引）： 主键索引叶子节点存储具体的数据 辅助索引叶子节点存储主键值 当辅助索引获取到主键值后，再通过主键索引查找到具体的数据 这里会有2个问题： 为什么辅助索引叶子节点不存储主键索引数据的引用呢？ 当数据的引用发生变化时，需要更新所有辅助索引的数据引用 为什么需要主键索引，且都是通过主键索引去查数据 这和 Innodb 的设计初衷有关，它认为主键是最常用的查询条件 索引知识补充列的离散性离散性表示数据重复率 在建索引的时候，离散性越高，选择性就越好，命中索引的概率也就越高 最左匹配原则对索引中关键字进行计算(对比)，一定是从左往右依次进行，且不可跳过 比如说，在我们建标时，会有一个排序规则，通过会设置成 utf8_general_ci，这会把数据转成 ASCII 码： 12abc -&gt; 97 98 99adc -&gt; 97 100 99 联合索引 单列索引 节点中关键字[name] 联合索引 节点中关键字[name,phoneNum] 单列索引是特殊的联合索引 联合索引列选择原则： 经常用的列优先 【最左匹配原则】 选择性(离散度)高的列优先【离散度高原则】 宽度小的列优先【最少空间原则】 例子如下是最常用的sql： 12select * from users where name = ?;select * from users where name = ? and phoneNum = ?; 解决方案，在 name 和 phoneNum 上都建索引： 12create index idx_name on users(name);create index idx_name_phoneNum on users(name,phoneNum); 问题在哪？ 根据最左匹配原则，这两个sql都可以命中第二个索引，所以第一个索引是冗余的 覆盖索引如果查询列可通过索引节点中的关键字直接返回，则该索引称之为覆盖索引，覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能 比如我建了下面这个索引： 1create index idx_name_phoneNum on users(name,phoneNum); 当我们这么查时： 1select name,phoneNum from users where name = ?; 上面的sql只查询 name 和 phoneNum，当命中索引时，不需要到叶子节点获取数据，直接在中间节点就可以把数据直接返回，这就是覆盖索引 总结 索引列的数据长度能少则少 索引一定不是越多越好，越全越好，一定是建合适的 匹配列前缀可用到索引 like 9999%（不一定，要看离散性），like %9999%、like %9999用不到索引 Where 条件中 not in 和 &lt;&gt;操作无法使用索引 匹配范围值，order by 也可用到索引 多用指定列查询，只返回自己想到的数据列，少用select * 联合索引中如果不是按照索引最左列开始查找，无法使用索引 联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引 联合索引中如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo + github pages建立个人博客]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github-pages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 hexo安装hexo官方文档：https://hexo.io/zh-cn/docs/ 按照官网文档安装hexo，安装hexo之前需要先安装 node（推荐使用 nvm 安装） 和 git 基本使用 初始化网站： 12hexo init &lt;dirName&gt; # 也可以新建一个空目录，然后执行 hexo initnpm install # npm安装 生成静态文件： 1hexo g # 或者使用 hexo generate 启动本地服务： 1hexo s # 或者使用 hexo server，然后通过http://127.0.0.1:4000访问 常用命令：1234hexo n == hexo new # 新建文章、页面等hexo g == hexo generate # 生成静态文件hexo s == hexo server # 启动服务hexo d == hexo deploy # 发布 主题官方主题地址：https://hexo.io/themes/ 这里使用的是 next，地址：http://theme-next.iissnan.com/ 只要将主题放到 themes 目录下，然后修改站点配置文件 _config.yml 中的 theme 值即可 具体设置可以参考上面的next文档 使用github部署hexo修改站点配置文件 _config.yml ：1234deploy: type: git repo: git@github.com:cpp288/cpp288.github.io.git #这里的网址填你自己的 branch: master 配置github ssh key： ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot; 生成新的key文件，邮箱地址填你的Github地址，后面直接回车进行 将生成的工钥 id_rsa.pub 配置到 github 上 执行 ssh -T git@github.com 如下提示则成功1Hi cpp288! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 安装扩展：1npm install hexo-deployer-git --save 部署到 github：1hexo d 相关问题电脑重装了系统/多台电脑写博客？ 参考博客： https://www.zhihu.com/question/21193762 https://blog.csdn.net/heimu24/article/details/81210640 如何添加本地图片？ 在 source 目录下新建目录，将图片放在其中（可以建多级目录），hexo 会在 generate 时将图片放到 public 中，使用 markdown 图片语法即可 相关博客 我是如何利用Github Pages搭建起我的博客，细数一路的坑 Hexo和Next主题的相关设置（持续更新） 使腾讯404公益页面支持HTTPS 【持续更新】最全Hexo博客搭建+主题优化+插件配置+常用操作+错误分析]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
