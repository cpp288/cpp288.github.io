<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[文章收藏]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%96%87%E7%AB%A0%E6%94%B6%E8%97%8F%2F</url>
    <content type="text"><![CDATA[framework 应聘架构师，面试最容易被问啥？ 微服务注册中心Nacos Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 Spring Cloud Alibaba系列教程-03-搭建生产可用的Nacos集群 熔断限流Spring Cloud Alibaba Sentinel Spring Cloud Alibaba基础教程：使用Sentinel实现接口限流 Sentinel Client: 整合Apollo规则持久化 分布式事务Seata 开发者说：深度剖析开源分布式事务方案 Seata 的事务协调器 其它Spring Cloud Bus 干货｜Spring Cloud Bus 消息总线介绍 Spring Cloud Stream 干货｜Spring Cloud Stream 体系及原理介绍 Service MeshIstio 什么是 istio component消息队列RocketMQ 从RocketMQ我们学到了什么？（NameServer篇） 实践 到底什么时候该使用MQ？ 数据库MySql 抱歉，没早点把这么全面的InnoDB锁机制发给你 favorites架构师之路（58沈剑） 架构师之路18年精选100篇]]></content>
      <categories>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用skywalking做分布式系统链路监控]]></title>
    <url>%2F2019%2F04%2F12%2Fmicro-service%2Fapm%2F%E4%BD%BF%E7%94%A8skywalking%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E9%93%BE%E8%B7%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[版本： skywalking：6.0.0-GA elasticsearch：6.5.4 rocketbot：最新（master分支）2019.04.12 skywalking官网 skywalking 可以使用 H2、elasticsearch、MySql做为数据存储，推荐使用 elasticsearch 网上有相关的 docker-compose （参考），但是只有 5.0.0 版本的 Install安装 elasticsearch本次安装的版本：6.5.4（单机部署），使用 docker 安装 skywalking 6.0.0-GA 支持 6.x 版本以上 elasticsearch（用过 5.x 版本，安装失败，未使用 7.x 版本） 官方安装文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 12docker pull elasticsearch:6.5.4docker run -p 9200:9200 -p 9300:9300 -v esdata:/usr/share/elasticsearch/data -d --name es 93109ce1d590 docker images： 1elasticsearch 6.5.4 93109ce1d590 3 months ago 774MB 设置阿里镜像，不然很慢 安装 skywalkingskywalking 使用本地单机方式安装 下载在 apache 官网下载：https://www.apache.org/dyn/closer.cgi/incubator/skywalking/6.0.0-GA/apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 传至服务器并解压： 1tar -zxvf apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 配置配置 ./config/application.yml 设置地址信息和TTL信息： 1234567891011121314151617core: default: restHost: 0.0.0.0 restPort: 12800 restContextPath: / gRPCHost: 192.168.173.113 gRPCPort: 11800 downsampling: - Hour - Day - Month # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted. recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; # Unit is minute minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; # Unit is minute hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; # Unit is hour dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; # Unit is day monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; # Unit is month 使用 elasticsearch 做为 storage，注释掉默认的 H2 配置 12345678910111213141516171819storage:# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125; elasticsearch: # nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html # Execute the bulk every 2000 requests bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # flush the bulk every 20mb bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 10 seconds whatever the number of requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # the number of concurrent requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; 相关告警规则设置：./config/alarm-settings.yml 启动在 ./bin 目录下，有相关的启动脚本，主要的是： startup.sh 启动 server 和 UI oapService.sh 单独启动 server webappService.sh 单独启动UI Agent官方文档 将 /agent 目录 copy 至需要监控服务的服务器，目录结构： activations config：配置 logs：日志 optional-plugins：可选插件 plugins：启用的插件 skywalking-agent.jar：执行jar文件 配置配置文件：./config/agent.config 123456# 配置应用的名称 The service name in UIagent.service_name=$&#123;SW_AGENT_NAME:Your_ApplicationName&#125;# 配置server collector地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.173.113:11800&#125;# 日志级别logging.level=$&#123;SW_LOGGING_LEVEL:DEBUG&#125; 启动这里使用的是用 jar 启动的方式（tomcat war启动的方式见官方文档） 在 java -jar 中增加 skywalking agent 参数（必须在 -jar 前面）: 1java -javaagent:/home/wl/skywalking-agent/skywalking-agent.jar -DSW_AGENT_NAME=xxx -jar xxx.jar 安装 Rocketbot由于 skywalking 自带的UI不是特别友好，这里选择使用 Rocketbot GitHub地址：https://github.com/TinyAllen/rocketbot 这里使用的是 docker 安装的方式，按照 GitHub 的教程安装即可（此次安装由于 Rocketbot 的 shell 脚本问题，搞的久了点） 按照步骤： 1234npm installnpm run builddocker build -t rocketbot .docker run -p 8080:80 -d -e SKYWALKING_URL=192.168.173.113:12800 rocketbot 注意：在 docker run 的时候，由于 rockerbot 容器中没有 skywalking，指定的 SKYWALKING_URL 必须是ip地址 相关参考 elasticsearch 官网 skywalking 官网 APM巅峰对决：skywalking P.K. Pinpoint]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>skywalking</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos版本迭代整理（持续更新）]]></title>
    <url>%2F2019%2F03%2F07%2Fmicro-service%2Fnacos%E7%89%88%E6%9C%AC%E8%BF%AD%E4%BB%A3%E6%95%B4%E7%90%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[官方文档：https://nacos.io/zh-cn/index.html 官方博客：https://nacos.io/zh-cn/blog/index.html 核心功能： 注册中心 配置中心 nacos服务监控：https://nacos.io/zh-cn/docs/monitor-guide.html 0.9.0发布时间：2019.2.28 Nacos 0.9.0 发布，稳定的快速迭代 Nacos 0.9.0版本发布啦 更新内容： Nacos-Sync稳定性提升 Nacos Server功能拆分部署（通过启动参数实现拆分部署） 启动Nacos server时候，增加-f参数，意思是function mode，和对应模块标示来进行启动，如果不穿，或者传入有误，都将启动全部功能。 配置中心参数对应config，注册中心参数对应naming Nacos python语言体系的支持 1.0.0发布时间：2019.4.10 Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 相关博客 阿里巴巴基于 Nacos 实现环境隔离的实践 2019.3.13]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos做为注册中心]]></title>
    <url>%2F2019%2F03%2F06%2Fmicro-service%2Fnacos%E5%81%9A%E4%B8%BA%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[Nacos 是一个更易于帮助构建云原生应用的动态服务发现、配置和服务管理平台，提供「注册中心」、「配置中心」和「动态DNS服务」三大功能。 使用的相关版本： nacos server：0.9.0 nacos client：0.9.1 spring boot：1.5.17.RELEASE spring cloud：Edgware.SR4 spring-cloud-starter-alibaba-nacos-discovery：0.1.1.RELEASE（对应spring boot 1.x版本） nacos官方文档：https://nacos.io 部署nacos server，按照官方文档部署就行（分为单机部署和集群部署，两者的启动方式稍有不同），现已支持拆分部署 下面介绍的是和spring cloud做集成 相关对比 比较点 Eureka Zookeeper Consul Nacos 运维熟悉度 相对陌生 熟悉 更陌生 陌生 一致性（CAP） AP CP AP AP 一致性协议 HTTP 定时轮训 ZAB RAFT ～ 通讯方式 HTTP REST 自定义协议 HTTP REST ～ 更新机制 Peer 2 Peer（服务器之间） + Scheduler（服务器和客户端） ZK Watch Agent 监听的方式 ～ 适用规模 &lt; 30K &lt;20K &lt;5K 100K+ 性能问题 简单的更新机制、复杂设计、规模较大时 GC 频繁 扩容麻烦、规模较大时 GC 频繁 3K 节点以上，更新列表缓慢 刚开源 dashboard 有 没有，可以自己实现 有 有 各自缺点： Eureka： 客户端注册服务上报所有信息，节点多的情况下，网络，服务端压力过大，且浪费内存 客户端更新服务信息通过简单的轮询机制，当服务数量巨大时，服务器压力过大。 集群伸缩性不强，服务端集群通过广播式的复制，增加服务器压力 Eureka2.0 闭源（Spring Cloud最新版本还是使用的1.X版本的Eureka） Zookeeper： 维护成本较高，客户端，session状态，网络故障等问题，会导致服务异常 集群伸缩性限制，内存，GC和连接 主节点挂的情况下，会进行leader选举，在此过程中服务将不可用 无控制台管理 Consul： 未经大规模市场验证，无法保证可靠性 Go语言编写，内部异常排查困难 Nacos： 刚刚开源不久，社区热度不够，依然存在bug 上面对比摘自与 小马哥技术周报 简单使用加入依赖： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;!-- spring boot 1.x使用0.1.x版本，spring boot 2.x使用0.2.x版本 --&gt; &lt;version&gt;0.1.1.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 这里需要替换 nacos-client 版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 注意点： spring-cloud-starter-alibaba-nacos-discovery 依赖的版本和 spring boot 版本有关 spring-cloud-starter-alibaba-nacos-discovery 默认使用的 nacos-client 的版本较低，会有问题（比如namespace设置无效），这里替换了较高的版本 application.properties： 123456spring.application.name=nacos-testserver.port=8525# nacos server地址spring.cloud.nacos.discovery.server-addr=192.168.173.80:8848# namespace idspring.cloud.nacos.discovery.namespace=077d70f7-e430-4b4c-926a-44a9bfef003c 其它配置可以参考官网 注意：这里设置的namespace是界面上显示的id，不设置会进入public默认的命名空间 namespace：常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等 启动服务：]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java拦截器（interceptor）和过滤器（filter）]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E6%8B%A6%E6%88%AA%E5%99%A8%EF%BC%88interceptor%EF%BC%89%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%88filter%EF%BC%89%2F</url>
    <content type="text"><![CDATA[从概念上来讲，filter是servlet规范定义的，而interceptor是spring定义的 过滤器和拦截器在对请求进行拦截时： 发生的时机不一样，filter是在servlet容器外，interceptor在servlet容器内，且可以对请求的3个关键步骤进行拦截处理 另外filter在过滤是只能对request和response进行操作，而interceptor可以对request、response、handler、modelAndView、exception进行操作。 相关DEMO： 过滤器（Filter）：12345678910111213141516171819202122232425262728293031323334353637383940@Component@WebFilter(filterName = "urlFilter", urlPatterns = "/test")// 配置拦截路径public class UrlFilter implements Filter &#123; /** * filter初始化的时候调用，即web容器启动时调用 * web容器启动时根据web.xml文件，依次加载ServletContext -&gt; listener -&gt; filter -&gt; servlet * * @param filterConfig * @throws ServletException */ @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println("UrlFilter init..."); &#125; /** * filter执行功能，根据参数来看，可以对request,response和chain（是否放行）进行操作 * * @param request * @param response * @param chain * @throws IOException * @throws ServletException */ @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println("UrlFilter doFilter before..."); chain.doFilter(request, response); System.out.println("UrlFilter doFilter after..."); &#125; /** * filter在服务器正常关闭(比如System.exit(0))等情况下会调用 */ @Override public void destroy() &#123; System.out.println("UrlFilter destroy..."); &#125;&#125; 拦截器（Interceptor）12345678910111213141516171819@Componentpublic class UrlInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("UrlInterceptor preHandle..."); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("UrlInterceptor postHandle..."); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("UrlInterceptor afterCompletion..."); &#125;&#125; 注册拦截器：1234567891011@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Autowired private UrlInterceptor urlInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(urlInterceptor).addPathPatterns("/test"); &#125;&#125; 执行结果分析 这里用的是spring boot来搭建并启动web服务（使用spring boot bean的方式配置） 123456789@RestControllerpublic class TestController &#123; @GetMapping(value = "/test") public String test() &#123; System.out.println("do test..."); return "ok"; &#125;&#125; 访问该api打印日志：123456UrlFilter doFilter before...UrlInterceptor preHandle...do test...UrlInterceptor postHandle...UrlInterceptor afterCompletion...UrlFilter doFilter after... 相关博客文章： https://blog.csdn.net/dshf_1/article/details/81112595]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java各版本异步并发编程]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E5%90%84%E7%89%88%E6%9C%AC%E5%BC%82%E6%AD%A5%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[所谓异步调用其实就是实现一个可无需等待被调用函数的返回值而让操作继续运行的方法。在 Java 语言中，简单的讲就是另启一个线程来完成调用中的部分计算，使调用继续运行或返回，而不需要等待计算结果 java5之前在java5之前，主要通过 Thread 或者实现 Runnable 来创建线程，可以通过 Thread 的一些方法来控制线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ThreadDemo &#123; public static void main(String[] args) &#123; normalThread(); completableThread(); &#125; /** * 普通线程 */ private static void normalThread() &#123; Thread thread = new Thread(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()), "Sub"); thread.start(); System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); &#125; /** * 获取线程是否已经完成 * 在获取 completableRunnable.isCompleted() 值时并不一定是true * 我们会想到可见性的问题，所以在 completed 字段加上 volatile 关键字 * 但是还是会出现上面的问题，这里涉及到线程的执行顺序，当Sub线程还未执行到 completed = true; 时，主线程已经执行完了 * 要解决这个问题需要使用 thread.join() 方法，主线程等待Sub线程执行完成 */ private static void completableThread() &#123; CompletableRunnable completableRunnable = new CompletableRunnable(); Thread thread = new Thread(completableRunnable, "Sub"); thread.start();// try &#123;// thread.join();// &#125; catch (InterruptedException e) &#123;// e.printStackTrace();// &#125; System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); System.out.printf("runnable is completed : " + completableRunnable.isCompleted()); &#125; /** * 可完成的 */ private static class CompletableRunnable implements Runnable&#123; private boolean completed = false; @Override public void run() &#123; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()); completed = true; &#125; public boolean isCompleted() &#123; return completed; &#125; &#125;&#125; java5之前实现的局限性： 缺少线程管理的原生支持（没有线程池） 缺少”锁”的api（缺少Lock这样的api） 缺少执行完成的原生支持 执行结果获取困难 java5线程池java5增加了线程池，由 Doug Lea 编写 12345678910111213public class ExecutorDemo &#123; public static void main(String[] args) &#123; // 执行器服务，线程池 ThreadPoolExecutor 是它的一种实现 ExecutorService executor = Executors.newFixedThreadPool(1); executor.execute(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName())); // 合理的关闭线程池是非常重要的 executor.shutdown(); &#125;&#125; Future增加了 Future，提供了可以获取执行结果的方法（Callable是有返回值操作，相对于Runnable） 12345678910111213141516171819202122232425public class FutureDemo &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(1); Future&lt;String&gt; future = executorService.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return "[Thread : " + Thread.currentThread().getName() + "]Hello World..."; &#125; &#125;); // 可以知道该线程是否执行完成// future.isDone(); try &#123; String v = future.get(); System.out.println(v); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; executorService.shutdown(); &#125;&#125; Future的限制： 无法手动完成 阻塞式结果返回 future.get() 无法链式调用多个Future，从 ExecutorService#invokeAll 方法中只能返回Future的集合 无法合并多个Future的结果，从 ExecutorService#invokeAll 方法中只能返回Future的集合 java7Fork/JoinForkJoin是Java7提供的原生多线程并行处理框架，其基本思想是将大人物分割成小任务，最后将小任务聚合起来得到结果。 它非常类似于HADOOP提供的MapReduce框架，只是MapReduce的任务可以针对集群内的所有计算节点，可以充分利用集群的能力完成计算任务。ForkJoin更加类似于单机版的MapReduce Fork/Join使用两个类完成以上两件事情： ForkJoinTask： 我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join的操作机制，通常我们不直接继承ForkjoinTask类，只需要直接继承其子类。 RecursiveAction，用于没有返回结果的任务 RecursiveTask，用于有返回值的任务 ForkJoinPool： task要通过ForkJoinPool来执行，分割的子任务也会添加到当前工作线程的双端队列中，进入队列的头部。当一个工作线程中没有任务时，会从其他工作线程的队列尾部获取一个任务。 计算整数之和 DEMO：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ForkJoinDemo &#123; public static void main(String[] args) &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); LongAccumulator accumulator = new LongAccumulator(((left, right) -&gt; left + right), 0); List&lt;Long&gt; params = new ArrayList&lt;&gt;(); for (long i = 0; i &lt; 10000000; i++) &#123; params.add(i); &#125; long start = System.currentTimeMillis(); forkJoinPool.invoke(new LongSumTask(params, accumulator)); long end = System.currentTimeMillis(); System.out.println(accumulator.get()); System.out.printf("消耗时间：%d %s\n", end - start, "ms"); forkJoinPool.shutdown(); &#125; static class LongSumTask extends RecursiveAction &#123; private final List&lt;Long&gt; elements; private final LongAccumulator accumulator; LongSumTask(List&lt;Long&gt; elements, LongAccumulator accumulator) &#123; this.elements = elements; this.accumulator = accumulator; &#125; @Override public void compute() &#123; int size = elements.size(); int parts = size / 2; // 使用简单的二分法，将计算平分，当元素只有一个的时候使用 LongAccumulator 进行累加计算 if (size &gt; 1) &#123; List&lt;Long&gt; left = elements.subList(0, parts); List&lt;Long&gt; right = elements.subList(parts, size); new LongSumTask(left, accumulator).fork().join(); new LongSumTask(right, accumulator).fork().join(); &#125; else &#123; if (elements.isEmpty()) &#123; return; &#125; Long num = elements.get(0); accumulator.accumulate(num); &#125; &#125; &#125;&#125; java8CompletableFuture在Java8中，CompletableFuture 提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法 CompletableFuture 实现了 Future 和 CompletionStage123public class CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt; &#123; // ...&#125; 相关的操作可以查看官方API或者相关博客 DEMO：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class CompletableFutureDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 1. 完成操作（可以被其它线程去做）// CompletableFuture&lt;String&gt; completableFuture = new CompletableFuture&lt;&gt;();// completableFuture.complete("Hello World");// String v = completableFuture.get();// System.out.println(v); // 2. runAsync 异步执行，阻塞操作// CompletableFuture asyncCompletableFuture = CompletableFuture.runAsync(() -&gt; &#123;// System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// // 这里仍然是阻塞的// asyncCompletableFuture.get();//// System.out.println("Starting..."); // 3. supplyAsync 异步执行，阻塞操作// CompletableFuture&lt;String&gt; asyncCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123;// // 获取数据操作，比如来自于数据库// return String.format("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// String v = asyncCompletableFuture.get();// System.out.println(v);// System.out.println("Starting..."); // 4. 合并操作 CompletableFuture&lt;String&gt; combinedCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; // 获取数据操作，比如来自于数据库 return String.format("[Thread : %s]Hello World...", Thread.currentThread().getName()); &#125;).thenApply(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " - 来自于数据库"; &#125;).thenApplyAsync(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " at " + LocalDate.now(); &#125;).exceptionally(e -&gt; &#123; // 异常处理 e.printStackTrace(); return ""; &#125;); while (!combinedCompletableFuture.isDone()) &#123; &#125; String v = combinedCompletableFuture.get(); System.out.println(v); System.out.println("Starting..."); &#125;&#125; 事实上，如果每个操作都很简单的话，没有必要用这种多线程异步的方式，因为创建线程还需要时间，还不如直接同步执行来得快。 事实证明，只有当每个操作很复杂需要花费相对很长的时间（比如，调用多个其它的系统的接口）的时候用 CompletableFuture 才合适，不然区别真的不大，还不如顺序同步执行。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在sonarqube的pmd插件中整合阿里p3c开发规范]]></title>
    <url>%2F2019%2F02%2F28%2Fdevops%2F%E5%A6%82%E4%BD%95%E5%9C%A8sonarqube%E7%9A%84pmd%E6%8F%92%E4%BB%B6%E4%B8%AD%E6%95%B4%E5%90%88%E9%98%BF%E9%87%8Cp3c%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[sonar-pmd是sonar官方的支持pmd的插件，但是还不支持p3c，需要在pmd插件源码中添加p3c支持(p3c是阿里在pmd基础上根据阿里巴巴开发手册实现了其中的49开发规则) 插件源码下载地址：https://github.com/mrprince/sonar-p3c-pmd 阿里p3c github：https://github.com/alibaba/p3c 此次使用的sonar版本：6.5 此源码工程已经添加了P3C支持：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.p3c&lt;/groupId&gt; &lt;artifactId&gt;p3c-pmd&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 在这个PMD插件中，已经在默认的268条规则上增加了48条阿里代码规则 修改PMD插件源码相关文件： pmd.properties (src/main/resources/org/sonar/l10n/pmd.properties) rules-p3c.xml (src/main/resources/org/sonar/plugins/pmd/rules-p3c.xml) pmd-model.xml (src/main/resources/com/sonar/sqale/pmd-model.xml) 增加规则该规范中少了一条 AvoidManuallyCreateThreadRule 规则，以添加该规则为例子 在 pmd.properties 中增加规则名称：1rule.pmd.AvoidManuallyCreateThreadRule.name=[p3c]avoid manually create thread. 在 rules-p3c.xml 中增加对应的p3c规则：1234&lt;rule key="AvoidManuallyCreateThreadRule"&gt; &lt;priority&gt;MAJOR&lt;/priority&gt; &lt;configKey&gt;&lt;![CDATA[rulesets/java/ali-concurrent.xml/AvoidManuallyCreateThreadRule]]&gt;&lt;/configKey&gt;&lt;/rule&gt; 在 pmd-model.xml 增加：12345678910111213&lt;chc&gt; &lt;rule-repo&gt;pmd&lt;/rule-repo&gt; &lt;rule-key&gt;AvoidManuallyCreateThreadRule&lt;/rule-key&gt; &lt;prop&gt; &lt;key&gt;remediationFunction&lt;/key&gt; &lt;txt&gt;CONSTANT_ISSUE&lt;/txt&gt; &lt;/prop&gt; &lt;prop&gt; &lt;key&gt;offset&lt;/key&gt; &lt;val&gt;2&lt;/val&gt; &lt;txt&gt;min&lt;/txt&gt; &lt;/prop&gt;&lt;/chc&gt; 在 src/main/resources/org/sonar/l10n/pmd/rules/pmd-p3c 包中增加相关sonar举例（必须增加，不然测试用例跑不通）：12345&lt;p&gt;Look for qualified this usages in the same class.&lt;/p&gt;&lt;p&gt;Examples:&lt;/p&gt;&lt;pre&gt; // 新增规则，没有示例&lt;/pre&gt; 如果要删除规则，按照上面的方式删除即可 其它设置修改p3c提示语可以下载阿里p3c源码，源码地址：https://github.com/alibaba/p3c 描述内容都在 p3c/p3c-pmd/src/main/resources/messages.xml 文件中，修改其中的描述内容即可 然后将其maven打包（可以deploy在公司的私有仓库中） 修改pmd插件在sonarqube中的插件显示名可以修改 sonar-p3c-pmd 工程中的 PmdConstants 类 REPOSITORY_NAME 值即可 sonar配置整合插件将 sonar-p3c-pmd 插件通过maven打包，然后将打好的jar包放在sonar目录下的 extensions/plugins 目录中 重启 sonar 服务，通过 ./bin/linux-x86-64/sonar.sh restart 命令 查看插件是否安装正确（如果sonar启动失败，表示插件有问题） 创建质量配置在质量配置页面中，创建一个java规则 创建完成以后，进行激活规则操作，在资源库中找到上传的插件进行激活相关p3c规则 在项目中配置对应的质量规则即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置优化]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参数作用域 全局参数（global）： 1set global autocommit = ON/OFF; 会话参数（session），会话参数不单独设置则会采用全局参数： 1set session autocommit = ON/OFF; 注意点： 全局参数的设定对于已经存在的会话无法生效（需要重新开启会话） 会话参数的设定随着会话的销毁而失效 全局类的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效 配置文件mysql --help 寻找配置文件的位置和加载顺序： 12Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 因为参数比较多，可以通过命令过滤： 1mysql --help | grep -A 1 &apos;Default options are read from the following files in the given order&apos; 连接数配置设置 max_connections 可配置最大连接数，mysql5.6 默认是151个连接： 12345+--------------------+-------+| Variable_name | Value |+--------------------+-------+| max_connections | 151 |+--------------------+-------+ 这个设置受其它两个配置影响： 系统句柄数配置 使用 ulimit -a 或者查看 /etc/security/limits.conf 配置文件 1open files (-n) 65535 mysql句柄数配置 查看 /usr/lib/systemd/system/mysqld.service 配置文件 1LimitNOFILE = 6000 内存参数配置 sort_buffer_size connection 排序缓冲区大小 当查询语句中有需要文件排序功能时，马上为 connection 分配配置的内存大小，建议256K（默认值）～ 2M之内 join_buffer_size connection关联查询缓冲区大小 当查询语句中有关联查询时，马上分配配置大小的内存用这个关联查询，所以有可能在一个查询语句中会分配很多个关联查询缓冲区 ，建议256K（默认值）～1M之间 Innodb_buffer_pool_size innodb buffer/cache 的大小（默认128M） innodb buffer/cache中存着数据缓存、索引缓存、缓冲数据、内部结构这些数据，所以大的缓冲池可以减小多次磁盘I/O访问相同的表数据以提高性能 计算公式： 1Innodb_buffer_pool_size = (总物理内存 - 系统运行所用 - connection 所用) * 90% 其它参数配置参考帖子：https://www.cnblogs.com/wyy123/p/6092976.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql MVCC]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-MVCC%2F</url>
    <content type="text"><![CDATA[MVCC：Multiversion concurrency control （多版本并发控制） 并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的堵塞，从而引发读操作的并发问题。 Mysql中MVCC逻辑流程在我们的 mysql 表中，都会有个默认列： DB_TRX_ID：数据行的版本号 DB_ROLL_PT：删除版本号 这些版本号就是事务ID 插入 在数据行版本号中，加入当前的事务ID 删除 在删除版本号中，加入当前的事务ID 这里需要注意的是，虽然数据删除了，但是 mysql 中还是有记录的 修改 修改操作是先做命中的数据行的copy，将原行数据的删除版本号的值设置为当前的事务ID 查询 规则： 查询数据行版本早于当前事务版本的数据行 行的版本号小于或等于事务ID，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的 查找删除版本号为NULL或者大于当前事务版本号的记录 确保取出来的行记录在事务开启之前没有被删除 Mysql中MVCC版本控制案例数据准备： 12insert into teacher(name,age) value (&apos;seven&apos;,18); insert into teacher(name,age) value (&apos;qing&apos;,20); 执行语句： 123456789##### tx1 #####begin; -- 1select * from users ; -- 2commit;##### tx2 #####begin; -- 3update teacher set age =28 where id =1; -- 4commit; 案例一上面的执行语句顺序：1，2，3，4，2 按照MVCC的流程，当update语句还没有提交之前，再去select查询时，还是读到的是之前的数据，符合预期 案例二上看的执行语句顺序：3，4，1，2 这次是先update，然后在select，这里都没有做commit操作，按照MVCC的流程，select读取到了update没有提交的数据，为什么会这样？ 如果按照MVCC流程会有这个问题，但是，在执行update时，会上X锁，这时候select会去做快照读，看下面的分析 Undo log 实现事务的原子性 事务处理过程中如果出现了错误或者用户执行了 ROLLBACK 语句，Mysql可以利用Undo Log中的备份将数据恢复到事务开始之前的状态 在 InnoDB 中用来实现多版本并发控制 事务未提交之前，Undo保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读 快照读： SQL读取的数据是快照版本，也就是历史版本，普通的SELECT就是快照读 InnoDB快照读，数据的读取将由 cache（事务修改过的数据） + undo（原本数据） 两部分组成 当前读： SQL读取的数据是最新版本 通过锁机制来保证读取的数据无法通过其他事务进行修改 UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE都是当前读 Redo logredo log是为了实现事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的未入磁盘数据进行持久化这一特性 指定redo log记录在 {datadir}/ib_logfile1&amp;ib_logfile2 可通过 innodb_log_group_home_dir 配置指定 目录存储 一旦事务成功提交且数据持久化落盘之后，此时redo log中的对应事务数据记录就失去了意义，所以redo log的写入是日志文件循环写入的 指定redo log日志文件组中的数量 innodb_log_files_in_group 默认为2 指定redo log每一个日志文件最大存储量 innodb_log_file_size 默认48M 指定redo log在 cache/buffer 中的 buffer 池大小 innodb_log_buffer_size 默认16M Redo buffer 持久化Redo log的策略， Innodb_flush_log_at_trx_commit : 取值 0 每秒提交 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（可能丢失一秒内的事务数据） 取值 1 每次事务提交执行 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（默认值，最安全，性能最差的方式） 取值 2 每次事务提交执行 Redo buffer -&gt; Redo log OS cache 再每一秒执行 -&gt; flush cache to disk]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql InnoDB锁机制]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-InnoDB%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[表锁和行锁锁是用于管理不同事务对共享资源的并发访问 表锁与行锁的区别: 锁定粒度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 InnoDB 存储引擎支持行锁和表锁（表锁是通过行锁实现的） InnoDB 锁类型锁类型： 共享锁（行锁）：Shared Locks 排它锁（行锁）：Exclusive Locks 意向共享锁（表锁）：IntentionShared Locks 意向排它锁（表锁）：Intention Exclusive Locks 自增锁：AUTO-INC Locks 行锁的算法： 记录锁 Record Locks 间隙锁 Gap Locks 临键锁 Next-key Locks 共享锁与排他锁共享锁又称为读锁，简称 S锁 ，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改 加锁释锁方式： 12select * from users WHERE id=1 LOCK IN SHARE MODE; commit/rollback; 举个例子： 12345678### session1 ###begin;select * from sys_user where id=1 lock in share mode; # 获取S锁commit;### session2 ###select * from sys_user where id=1; # 可以正常执行update sys_user set name=&apos;k2&apos; where id=1; # 当上面没有commit，该语句将被阻塞 排他锁又称为写锁，简称 X锁 ，排他锁不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的锁（共享锁、排他锁），只有该获取了排他锁的事务是可以对数据行进行读取和修改，（其他事务要读取数据可来自于快照） 加锁释锁方式： 123delete / update / insert 默认加上X锁SELECT * FROM table_name WHERE ... FOR UPDATE;commit/rollback; 例子： 123456789### session1 ###begin;update sys_user set name=&apos;k3&apos; where id=1; # 自动获取X锁commit;### session2 ###select * from sys_user where id=1 for update; # 等待上面commitselect * from sys_user where id=1 lock in share mode; # 等待上面commitselect * from sys_user where id=1; # 没影响 那么 InnoDB 行锁到底锁了什么？InnoDB的行锁是通过给索引上的索引项加锁来实现的 只有通过索引条件进行数据检索，InnoDB才使用行级锁，否则，InnoDB 将使用表锁（锁住索引的所有记录） 所以在执行 delete / update / insert 时，也需要考虑索引，因为没有命中索引会变成表锁 表锁： 1lock tables xx read/write; 意向共享锁与意向排它锁 意向共享锁（IS） 表示事务准备给数据行加入共享锁，即一个数据行加共享锁前必须先取得该表的IS锁 意向排它锁（IX） 表示事务准备给数据行加入排他锁，即一个数据行加排他锁前必须先取得该表的IX锁 简单来说，这两种锁就是一个标志位，在拿锁之前，先要判断IS/IX 意向锁（IS、IX）是 InnoDB 数据操作之前自动加的，不需要用户干预 当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁 自增锁针对自增列自增长的一个特殊的表级别锁 1show variables like &apos;innodb_autoinc_lock_mode&apos;; 默认取值1，代表连续，事务未提交ID永久丢失 记录锁、间隙锁、临键锁临键锁（Next-Key）临键锁是 InnoDB 默认的行锁算法 当sql执行按照索引进行数据的检索时，查询条件为范围查找（between and、&lt;、&gt;等）并有数据命中，则此时sql语句加上的锁为 Next-Key locks，锁住索引的记录 + 区间（左开右闭） 例子： 当数据库里与 id 为1、4、7、10四条数据，那么： 它可以有效的方式幻读 间隙锁（Gap）当sql执行按照索引进行数据的检索时，查询条件的数据不存在，这时sql语句加上的锁即为Gap locks，锁住索引不存在的区间（左开右开） Gap locks只在RR事务隔离级别存在 记录锁（Record）当sql执行按照唯一性（Primary key、Unique key）索引进行数据的检索时，查询条件等值匹配且查询的数据时存在，这时sql语句加上的锁为记录锁，锁住具体的索引项 锁是如何解决事务并发解决脏读 解决不可重复读 解决幻读 死锁当2个或以上事务都在等待对方释放锁，产生循环等待，即形成了死锁 如何解决： 类似的业务逻辑以固定的顺序访问表和行 大事务拆小（大事务更倾向于死锁） 在同一个事务中，尽可能做到一次锁定所需要的所有资源 如果业务允许，可以降低事务隔离级别 为表添加合适的索引（如果不走索引将会为表的每一行记录添加上锁，产生表锁）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作，事务是一组不可再分割的操作集合（工作逻辑单元） mysql中如何开启事务： 123begin / start transaction -- 手工commit / rollback -- 事务提交或回滚set session autocommit = on/off; -- 设定事务是否自动开启 事务ACID特性 原子性（Atomicity） 最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚 一致性（Consistency） 事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致 隔离性（Isolation） 一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般设定为不可见） 持久性（Durability） 事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失 事务并发带来的问题脏读： 不可重复读： 幻读： 事务隔离级别SQL92 ANSI/ISO标准：http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt 隔离级别 解决问题 说明 Read Uncommitted（未提交读） 未解决并发问题 事务未提交对其他事务也是可见的，产生脏读 Read Committed（提交读） 脏读 一个事务开始之后，只能看到自己提交的事务所做的修改，产生不可重复读 Repeatable Read（可重复读） 不可重复读 在同一个事务中多次读取同样的数据结果是一样的，这种隔离级别未定义解决幻读的问题 Serializable（串行化） ALL 最高的隔离级别，通过强制事务的串行执行 InnoDB对事物隔离级别的支持 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（未提交读） 可能 可能 可能 Read Committed（提交读） 不可能 可能 可能 Repeatable Read（可重复读） 不可能 不可能 对InnoDB不可能 Serializable（串行化） 不可能 不可能 不可能 在 InnoDB 引擎中，默认隔离级别是Repeatable Read（可重复读），也可以防止幻读 隔离级别到底是如何实现的？ 锁、MVVC]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询优化]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Mysql 查询执行路径 Mysql 客户端/服务端通信](#Mysql 客户端/服务端通信) 查询缓存 查询优化处理 查询执行引擎 返回客户端 详解Mysql 客户端/服务端通信Mysql客户端与服务端的通信方式是“半双工” 全双工：双向通信，发送同时也可以接收 半双工：双向通信，同时只能接收或者是发送，无法同时做操作 单工：只能单一方向传送 半双工通信：在任何一个时刻，要么是有服务器向客户端发送数据，要么是客户端向服务端发送数据，这两个动作不能同时发生。所以我们无法也无需将一个消息切成小块进行传输 特点和限制：客户端一旦开始发送消息，另一端要接收完整个消息才能响应。 客户端一旦开始接收数据没法停下来发送指令。 通信查询状态对于一个mysql连接，或者说一个线程，时刻都有一个状态来标识这个连接正在做什么 官方状态全集：https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html 我们可以通过以下命令查看： 12show full processlist;show processlist; 执行结果： 1234567mysql&gt; show processlist;+------+------+-----------+------+---------+------+-------+------------------+| Id | User | Host | db | Command | Time | State | Info |+------+------+-----------+------+---------+------+-------+------------------+| 9543 | root | localhost | NULL | Query | 0 | init | show processlist |+------+------+-----------+------+---------+------+-------+------------------+1 row in set (0.00 sec) 整理常见的状态： 状态 说明 Sleep 线程正在等待客户端发送数据 Query 连接形成正在执行查询 Locked 线程正在等待表锁的释放 Sorting result 线程正在对结果进行排序 Sending data 向请求端发送数据 可以通过 kill {id} 的方式进行杀除连接 查询缓存工作原理： 缓存 SELECT 操作的结果集和SQL语句 新的 SELECT 语句，先去查询缓存，判断是否存在可用的记录集 判断标准： 与缓存的SQL语句是否完全一样（区分大小写） 查看缓存设置通过 show variables like &#39;query_cache%&#39;; 命令查询： 1234567891011mysql&gt; show variables like &apos;query_cache%&apos;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+5 rows in set (0.00 sec) query_cache_type 0：不启用查询缓存，默认值 1：启用查询缓存，只要符合查询缓存要求，客户端的查询语句和记录集都可以缓存起来（加上 SQL_NO_CACHE 将不缓存） 2：启用查询缓存，只要查询语句中添加参数 SQL_CACHE ，且符合查询缓存的要求，客户端的查询语句和记录集都可以缓存起来 query_cache_size总的缓存池的大小，允许设置最小值为 40K，默认 1M，推荐设置为 ：32M、64M、128M 超过该大小，会将之前的缓存失效 query_cache_limit限制单次查询，缓存区最大能缓存的查询记录集，默认设置为 1M 查看缓存情况可以通过 show status like &#39;Qcache%&#39;;： 1234567891011121314mysql&gt; show status like &apos;Qcache%&apos;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031352 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 150 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+8 rows in set (0.00 sec) 不会缓存的情况 当查询语句中有一些不确定的数据时，则不会被缓存 如包含函数 NOW() 、CURRENT_DATE() 等类似的函数，或者用户自定义的函数，存储函数，用户变量等都不会被缓存 当查询的结构大于 query_cache_limit 设置的值时 对于 InnoDB 引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之后，所有与这个表相关的查询都无法被缓存 update table set name=’hello’ where id=3; 查询的表是系统表 查询语句不涉及到表 select 1; 为什么Mysql默认关闭了缓存 在查询之前必须先检查是否命中缓存，浪费计算资源 如果这个查询可以缓存，那么执行完成后，Mysql发现查询缓存中没有这个查询，则会将结构存入查询缓存，带来额外的系统消耗 针对表进行写入或更新操作时，将对应表的所有缓存都设置失效 如果查询缓存很大或者碎片很多时，这个操作可能带来很大的系统消耗 适用场景： 以读为主的业务，数据生成之后就不常改变的业务 查询优化处理查询优化处理的三个阶段： 解析sql 通过lex词法分析，yacc语法分析将sql语句解析成解析树（Yacc 与 Lex语法教程） 预处理阶段 根据mysql的语法的规则进一步检查解析树的合法性，如：检查数据的表和列是否存在，解析名字和别名的设置。还会进行权限的验证 查询优化器 优化器的主要作用就是找到最优的执行计划 解析sql和预处理阶段主要是解析和校验的一个过程，我们重点来讲下查询优化器 查询优化器如何找到最优执行计划Mysql的查询优化器是基于成本计算的原则。他会尝试各种执行计划。 数据抽样的方式进行试验（随机的读取一个4K的数据块进行分析） 使用等价变化规则 5=5 and a&gt;5 改写成 a&gt;5 a5 and a=5 基于联合索引，调整条件位置 … 优化count 、min、max等函数 min函数只需找索引最左边 ，max函数只需要索引最右边 myisam引擎 count(*) 无需遍历全表 覆盖索引扫描 子查询优化 提前终止查询 用了limit关键字或者使用不存在的条件 IN的优化 先进性排序，再采用二分查找的方式（所以尽量使用 in ，而少用 or ） …… 执行计划使用 EXPLAIN ： 12345678910111213mysql&gt; explain select * from table01 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table01 type: systempossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 0 Extra: const row not found1 row in set (0.00 sec) idselect查询的序列号，标识执行的顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同又不同即两种情况同时存在，id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 select_type查询的类型，主要是用于区分普通查询、联合查询、子查询等 SIMPLE：简单的 select 查询，查询中不包含子查询或者 union PRIMARY：查询中包含子部分，最外层查询则被标记为 primary SUBQUERY/MATERIALIZED：SUBQUERY 表示在 select 或 where 列表中包含了子查询，MATERIALIZED 表示 where 后面 in 条件的子查询 UNION：若第二个 select 出现在 union 之后，则被标记为 union UNION RESULT：从union表获取结果的select table查询涉及到的表 直接显示表名或者表的别名 &lt;unionM,N&gt; 由ID为M,N 查询 union 产生的结果 由ID为N查询生产的结果 type访问类型，sql查询优化中一个很重要的指标，结果值从好到坏依次是： 1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL system：表只有一行记录（等于系统表），const 类型的特例，基本不会出现，可以忽略不计 const：表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引 eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描 ref：非唯一性索引扫描，返回匹配某个单独值的所有行，本质是也是一种索引访问 range：只检索给定范围的行，使用一个索引来选择行 index：Full Index Scan，索引全表扫描，把索引从头到尾扫一遍 ALL：Full Table Scan，遍历全表以找到匹配的行 在实际应用中，尽量要在 range 级别以上 possible_keys查询过程中有可能用到的索引 key实际使用的索引，如果为NULL，则没有使用索引 rows根据表统计信息或者索引选用情况，大致估算出找到所需的记录所需要读取的行数 filtered它指返回结果的行占需要读到的行（rows列的值）的百分比 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好 Extra十分重要的额外信息 Using filesort：mysql对数据使用一个外部的文件内容进行了排序，而不是按照表内的索引进行排序读取 Using temporary：使用临时表保存中间结果，也就是说mysql在对查询结果排序时使用了临时表，常见于order by 或 group by Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了访问表的数据行，效率高 Using where：使用了where过滤条件 select tables optimized away：基于索引优化MIN/MAX操作或者MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即可完成优化 查询执行引擎调用插件式的存储引擎的原子API的功能进行执行计划的执行 返回客户端 有需要做缓存的，执行缓存操作 增量的返回结果：开始生成第一条结果时，mysql就开始往请求方逐步返回数据 好处：mysql服务器无须保存过多的数据，浪费内存。用户体验好，马上就拿到了数据 慢查询分析定位如何定位慢SQL 业务驱动 测试驱动 慢查询日志 前面2种是通过人为的方式来定位，我们主要看下第三种方式 慢查询日志慢查询日志配置通过 show variables like &#39;slow_query_log&#39;; 查看： 1234567mysql&gt; show variables like &apos;slow_query_log&apos;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+1 row in set (0.00 sec) 通过 set global slow_query_log = on 开启日志 查看日志文件地址： 12345678mysql&gt; show variables like &apos;slow_query%&apos;;+---------------------+-------------------------------------------+| Variable_name | Value |+---------------------+-------------------------------------------+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/instance-dq9parum-slow.log |+---------------------+-------------------------------------------+2 rows in set (0.00 sec) 如上所示，日志地址在 /var/lib/mysql/instance-dq9parum-slow.log 通过 set global log_queries_not_using_indexes = on 设置没有命中索引的需要记录日志 通过 set global long_query_time = 0.1 （单位：秒）设置查询超过多少时间的需要记录日志 慢查询日志分析查看 /var/lib/mysql/instance-dq9parum-slow.log： 12345# Time: 181219 22:39:30# User@Host: root[root] @ [36.22.250.90] Id: 10887# Query_time: 0.000321 Lock_time: 0.000145 Rows_sent: 1 Rows_examined: 2SET timestamp=1545230370;select * from table01 where name in(&apos;name&apos;); Time：日志记录的时间 User@Host：执行的用户及主机 Query_time：查询耗费时间 Lock_time：锁表时间 Rows_sent：发送给请求方的记录条数 Rows_examined：语句扫描的记录条数 SET timestamp：语句执行的时间点 select ….：执行的具体语句 慢查询日志分析工具 mysqldumpslow mysqlsla pt-query-digest]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储引擎]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言介绍 插拔式的插件方式 存储引擎是指定在表之上的，即一个库中的每一个表都可以指定专用的存储引擎 不管表采用什么样的存储引擎，都会在数据区，产生对应的一个frm文件（表结构定义描述文件） 1-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user.frm 各存储引擎对比查看官网：https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html CSV 存储引擎数据存储以CSV文件： 1-rw-rw---- 1 mysql mysql 0 12月 18 19:27 table_csv.CSV 看其文件内容： 121,&quot;chen&quot;2,&quot;jian&quot; 存储的就是我们的表数据 特点： 不能定义索引、列定义必须为NOT NULL、不能设置自增列 不适用大表或者数据的在线处理 CSV数据的存储用 , 隔开，可直接编辑CSV文件进行数据的编排 数据安全性低（编辑之后，要生效使用flush table XXX 命令） 应用场景： 数据的快速导出导入 表格直接转换成CSV Archive 存储引擎压缩协议进行数据的存储，数据存储为 ARZ 文件格式 1-rw-rw---- 1 mysql mysql 8674 12月 18 19:40 table_archive.ARZ 特点： 只支持 insert 和 select 两种操作 只允许自增ID列建立索引 行级锁 不支持事务 数据占用磁盘少 应用场景： 日志系统 大量的设备数据采集 Memory 存储引擎数据都是存储在内存中，IO效率要比其他引擎高很多，服务重启数据丢失，内存数据表默认只有16M 特点： 支持hash索引，B tree索引，默认hash（查找复杂度 0(1) ） 字段长度都是固定长度 varchar(32)=char(32) 不支持大数据存储类型字段如 blog ，text 表级锁 应用场景： 等值查找热度较高数据 查询结果内存中的计算，大多数都是采用这种存储引擎作为临时表存储需计算的数据 实际应用中不常用 Myisam 存储引擎Mysql5.5 版本之前的默认存储引擎 较多的系统表也还是使用这个存储引擎 系统临时表也会用到 Myisam 存储引擎（Memory 存储引擎不支持的情况下，比如数据超过了16M） 12-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table_myisam.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table_myisam.MYI 特点： select count(*) from table 无需进行数据的扫描（有专门存储） 数据（.MYD）和索引（.MYI）分开存储 表级锁 不支持事务 InnoDB 存储引擎Mysql5.5及以后版本的默认存储引擎 1-rw-rw---- 1 mysql mysql 98304 12月 6 19:00 table_innodb.ibd 特点： 支持事务ACID 行级锁 聚集索引（主键索引）方式进行数据存储 支持外键关系保证数据完整性（尽量不要用）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql索引]]></title>
    <url>%2F2019%2F02%2F26%2Fmysql%2FMysql%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引是为了加速对表中数据行的检索而创建的一种分散存储的数据结构 为什么要用索引： 索引能极大的减少存储引擎需要扫描的数据量 索引可以把随机IO变成顺序IO 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表 Mysql 为什么使用 B+Tree二叉查找树 动画演示 平衡二叉查找树 动画演示 缺点： 太深了 数据处的(高)深度决定着他的IO操作次数，IO操作耗时大 太小了 每一个磁盘块(节点/页)保存的数据量太小了 没有很好的利用操作磁盘IO的数据交换特性 没有利用好磁盘IO的预读能力(空间局部性原理)，从而带来频繁的IO操作 多路平衡查找树动画演示 B-Tree B+Tree B-Tree 和 B+Tree区别 B+节点关键字搜索采用闭合区间 B+非叶节点不保存数据相关信息，只保存关键字和子节点的引用 B+关键字对应的数据保存在叶子节点中 B+叶子节点是顺序排列的，并且相邻节点具有顺序引用的关系 为什么选用 B+Tree B+树是B-树的变种(PLUS版)多路绝对平衡查找树，他拥有B-树的优势 B+树扫库、表能力更强 B+树的磁盘读写能力更强 B+树的排序能力更强 B+树的查询效率更加稳定 Mysql B+Tree 索引体现Myisam Engine 在 Myisam 引擎中，数据库对应的表会有这么几个文件 123-rw-rw---- 1 mysql mysql 8556 12月 18 16:30 table01.frm-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table01.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table01.MYI .MYD 文件存储的是具体的数据内容 .MYI 文件存储的是索引树 如上图，在 Myisam 引擎中，索引指向的是数据的地址 Innodb Engine 12-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user01.frm-rw-rw---- 1 mysql mysql 98304 12月 6 18:56 sys_user01.ibd 在 Innodb 引擎中，只有 .ibd 文件 Innodb 引擎中，它是以主键为索引来组织数据的存储（没有指定主键，它会隐式创建），它的叶子节点存储的是具体的数据 它分为主键索引（聚集索引）和辅助索引（非聚集索引）： 主键索引叶子节点存储具体的数据 辅助索引叶子节点存储主键值 当辅助索引获取到主键值后，再通过主键索引查找到具体的数据 这里会有2个问题： 为什么辅助索引叶子节点不存储主键索引数据的引用呢？ 当数据的引用发生变化时，需要更新所有辅助索引的数据引用 为什么需要主键索引，且都是通过主键索引去查数据 这和 Innodb 的设计初衷有关，它认为主键是最常用的查询条件 索引知识补充列的离散性离散性表示数据重复率 在建索引的时候，离散性越高，选择性就越好，命中索引的概率也就越高 最左匹配原则对索引中关键字进行计算(对比)，一定是从左往右依次进行，且不可跳过 比如说，在我们建标时，会有一个排序规则，通过会设置成 utf8_general_ci，这会把数据转成 ASCII 码： 12abc -&gt; 97 98 99adc -&gt; 97 100 99 联合索引 单列索引 节点中关键字[name] 联合索引 节点中关键字[name,phoneNum] 单列索引是特殊的联合索引 联合索引列选择原则： 经常用的列优先 【最左匹配原则】 选择性(离散度)高的列优先【离散度高原则】 宽度小的列优先【最少空间原则】 例子如下是最常用的sql： 12select * from users where name = ?;select * from users where name = ? and phoneNum = ?; 解决方案，在 name 和 phoneNum 上都建索引： 12create index idx_name on users(name);create index idx_name_phoneNum on users(name,phoneNum); 问题在哪？ 根据最左匹配原则，这两个sql都可以命中第二个索引，所以第一个索引是冗余的 覆盖索引如果查询列可通过索引节点中的关键字直接返回，则该索引称之为覆盖索引，覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能 比如我建了下面这个索引： 1create index idx_name_phoneNum on users(name,phoneNum); 当我们这么查时： 1select name,phoneNum from users where name = ?; 上面的sql只查询 name 和 phoneNum，当命中索引时，不需要到叶子节点获取数据，直接在中间节点就可以把数据直接返回，这就是覆盖索引 总结 索引列的数据长度能少则少 索引一定不是越多越好，越全越好，一定是建合适的 匹配列前缀可用到索引 like 9999%（不一定，要看离散性），like %9999%、like %9999用不到索引 Where 条件中 not in 和 &lt;&gt;操作无法使用索引 匹配范围值，order by 也可用到索引 多用指定列查询，只返回自己想到的数据列，少用select * 联合索引中如果不是按照索引最左列开始查找，无法使用索引 联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引 联合索引中如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo + github pages建立个人博客]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github-pages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 hexo安装hexo官方文档：https://hexo.io/zh-cn/docs/ 按照官网文档安装hexo，安装hexo之前需要先安装 node（推荐使用 nvm 安装） 和 git 基本使用 初始化网站： 12hexo init &lt;dirName&gt; # 也可以新建一个空目录，然后执行 hexo initnpm install # npm安装 生成静态文件： 1hexo g # 或者使用 hexo generate 启动本地服务： 1hexo s # 或者使用 hexo server，然后通过http://127.0.0.1:4000访问 常用命令：1234hexo n == hexo new # 新建文章、页面等hexo g == hexo generate # 生成静态文件hexo s == hexo server # 启动服务hexo d == hexo deploy # 发布 主题官方主题地址：https://hexo.io/themes/ 这里使用的是 next，地址：http://theme-next.iissnan.com/ 只要将主题放到 themes 目录下，然后修改站点配置文件 _config.yml 中的 theme 值即可 具体设置可以参考上面的next文档 使用github部署hexo修改站点配置文件 _config.yml ：1234deploy: type: git repo: git@github.com:cpp288/cpp288.github.io.git #这里的网址填你自己的 branch: master 配置github ssh key： ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot; 生成新的key文件，邮箱地址填你的Github地址，后面直接回车进行 将生成的工钥 id_rsa.pub 配置到 github 上 执行 ssh -T git@github.com 如下提示则成功1Hi cpp288! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 安装扩展：1npm install hexo-deployer-git --save 部署到 github：1hexo d 相关问题电脑重装了系统/多台电脑写博客？ 参考博客： https://www.zhihu.com/question/21193762 https://blog.csdn.net/heimu24/article/details/81210640 如何添加本地图片？ 在 source 目录下新建目录，将图片放在其中（可以建多级目录），hexo 会在 generate 时将图片放到 public 中，使用 markdown 图片语法即可 相关博客 我是如何利用Github Pages搭建起我的博客，细数一路的坑 Hexo和Next主题的相关设置（持续更新） 使腾讯404公益页面支持HTTPS 【持续更新】最全Hexo博客搭建+主题优化+插件配置+常用操作+错误分析]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
