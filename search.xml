<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何在sonarqube的pmd插件中整合阿里p3c开发规范]]></title>
    <url>%2F2019%2F02%2F28%2Fdevops%2F%E5%A6%82%E4%BD%95%E5%9C%A8sonarqube%E7%9A%84pmd%E6%8F%92%E4%BB%B6%E4%B8%AD%E6%95%B4%E5%90%88%E9%98%BF%E9%87%8Cp3c%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[sonar-pmd是sonar官方的支持pmd的插件，但是还不支持p3c，需要在pmd插件源码中添加p3c支持(p3c是阿里在pmd基础上根据阿里巴巴开发手册实现了其中的49开发规则) 插件源码下载地址：https://github.com/mrprince/sonar-p3c-pmd 阿里p3c github：https://github.com/alibaba/p3c 此源码工程已经添加了P3C支持：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.p3c&lt;/groupId&gt; &lt;artifactId&gt;p3c-pmd&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 在这个PMD插件中，已经在默认的268条规则上增加了48条阿里代码规则 修改PMD插件源码相关文件： pmd.properties (src/main/resources/org/sonar/l10n/pmd.properties) rules-p3c.xml (src/main/resources/org/sonar/plugins/pmd/rules-p3c.xml) pmd-model.xml (src/main/resources/com/sonar/sqale/pmd-model.xml) 增加规则该规范中少了一条 AvoidManuallyCreateThreadRule 规则，以添加该规则为例子 在 pmd.properties 中增加规则名称：1rule.pmd.AvoidManuallyCreateThreadRule.name=[p3c]avoid manually create thread. 在 rules-p3c.xml 中增加对应的p3c规则：1234&lt;rule key="AvoidManuallyCreateThreadRule"&gt; &lt;priority&gt;MAJOR&lt;/priority&gt; &lt;configKey&gt;&lt;![CDATA[rulesets/java/ali-concurrent.xml/AvoidManuallyCreateThreadRule]]&gt;&lt;/configKey&gt;&lt;/rule&gt; 在 pmd-model.xml 增加：12345678910111213&lt;chc&gt; &lt;rule-repo&gt;pmd&lt;/rule-repo&gt; &lt;rule-key&gt;AvoidManuallyCreateThreadRule&lt;/rule-key&gt; &lt;prop&gt; &lt;key&gt;remediationFunction&lt;/key&gt; &lt;txt&gt;CONSTANT_ISSUE&lt;/txt&gt; &lt;/prop&gt; &lt;prop&gt; &lt;key&gt;offset&lt;/key&gt; &lt;val&gt;2&lt;/val&gt; &lt;txt&gt;min&lt;/txt&gt; &lt;/prop&gt;&lt;/chc&gt; 在 src/main/resources/org/sonar/l10n/pmd/rules/pmd-p3c 包中增加相关sonar举例（必须增加，不然测试用例跑不通）：12345&lt;p&gt;Look for qualified this usages in the same class.&lt;/p&gt;&lt;p&gt;Examples:&lt;/p&gt;&lt;pre&gt; // 新增规则，没有示例&lt;/pre&gt; 如果要删除规则，按照上面的方式删除即可 其它设置修改p3c提示语可以下载阿里p3c源码，源码地址：https://github.com/alibaba/p3c 描述内容都在 p3c/p3c-pmd/src/main/resources/messages.xml 文件中，修改其中的描述内容即可 然后将其maven打包（可以deploy在公司的私有仓库中） 修改pmd插件在sonarqube中的插件显示名可以修改 sonar-p3c-pmd 工程中的 PmdConstants 类 REPOSITORY_NAME 值即可 sonar配置整合插件将 sonar-p3c-pmd 插件通过maven打包，然后将打好的jar包放在sonar目录下的 extensions/plugins 目录中 重启 sonar 服务，通过 ./bin/linux-x86-64/sonar.sh restart 命令 查看插件是否安装正确（如果sonar启动失败，表示插件有问题） 创建质量配置在质量配置页面中，创建一个java规则 创建完成以后，进行激活规则操作，在资源库中找到上传的插件进行激活相关p3c规则 在项目中配置对应的质量规则即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置优化]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参数作用域 全局参数（global）： 1set global autocommit = ON/OFF; 会话参数（session），会话参数不单独设置则会采用全局参数： 1set session autocommit = ON/OFF; 注意点： 全局参数的设定对于已经存在的会话无法生效（需要重新开启会话） 会话参数的设定随着会话的销毁而失效 全局类的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效 配置文件mysql --help 寻找配置文件的位置和加载顺序： 12Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 因为参数比较多，可以通过命令过滤： 1mysql --help | grep -A 1 &apos;Default options are read from the following files in the given order&apos; 连接数配置设置 max_connections 可配置最大连接数，mysql5.6 默认是151个连接： 12345+--------------------+-------+| Variable_name | Value |+--------------------+-------+| max_connections | 151 |+--------------------+-------+ 这个设置受其它两个配置影响： 系统句柄数配置 使用 ulimit -a 或者查看 /etc/security/limits.conf 配置文件 1open files (-n) 65535 mysql句柄数配置 查看 /usr/lib/systemd/system/mysqld.service 配置文件 1LimitNOFILE = 6000 内存参数配置 sort_buffer_size connection 排序缓冲区大小 当查询语句中有需要文件排序功能时，马上为 connection 分配配置的内存大小，建议256K（默认值）～ 2M之内 join_buffer_size connection关联查询缓冲区大小 当查询语句中有关联查询时，马上分配配置大小的内存用这个关联查询，所以有可能在一个查询语句中会分配很多个关联查询缓冲区 ，建议256K（默认值）～1M之间 Innodb_buffer_pool_size innodb buffer/cache 的大小（默认128M） innodb buffer/cache中存着数据缓存、索引缓存、缓冲数据、内部结构这些数据，所以大的缓冲池可以减小多次磁盘I/O访问相同的表数据以提高性能 计算公式： 1Innodb_buffer_pool_size = (总物理内存 - 系统运行所用 - connection 所用) * 90% 其它参数配置参考帖子：https://www.cnblogs.com/wyy123/p/6092976.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql MVCC]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-MVCC%2F</url>
    <content type="text"><![CDATA[MVCC：Multiversion concurrency control （多版本并发控制） 并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的堵塞，从而引发读操作的并发问题。 Mysql中MVCC逻辑流程在我们的 mysql 表中，都会有个默认列： DB_TRX_ID：数据行的版本号 DB_ROLL_PT：删除版本号 这些版本号就是事务ID 插入 在数据行版本号中，加入当前的事务ID 删除 在删除版本号中，加入当前的事务ID 这里需要注意的是，虽然数据删除了，但是 mysql 中还是有记录的 修改 修改操作是先做命中的数据行的copy，将原行数据的删除版本号的值设置为当前的事务ID 查询 规则： 查询数据行版本早于当前事务版本的数据行 行的版本号小于或等于事务ID，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的 查找删除版本号为NULL或者大于当前事务版本号的记录 确保取出来的行记录在事务开启之前没有被删除 Mysql中MVCC版本控制案例数据准备： 12insert into teacher(name,age) value (&apos;seven&apos;,18); insert into teacher(name,age) value (&apos;qing&apos;,20); 执行语句： 123456789##### tx1 #####begin; -- 1select * from users ; -- 2commit;##### tx2 #####begin; -- 3update teacher set age =28 where id =1; -- 4commit; 案例一上面的执行语句顺序：1，2，3，4，2 按照MVCC的流程，当update语句还没有提交之前，再去select查询时，还是读到的是之前的数据，符合预期 案例二上看的执行语句顺序：3，4，1，2 这次是先update，然后在select，这里都没有做commit操作，按照MVCC的流程，select读取到了update没有提交的数据，为什么会这样？ 如果按照MVCC流程会有这个问题，但是，在执行update时，会上X锁，这时候select会去做快照读，看下面的分析 Undo log 实现事务的原子性 事务处理过程中如果出现了错误或者用户执行了 ROLLBACK 语句，Mysql可以利用Undo Log中的备份将数据恢复到事务开始之前的状态 在 InnoDB 中用来实现多版本并发控制 事务未提交之前，Undo保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读 快照读： SQL读取的数据是快照版本，也就是历史版本，普通的SELECT就是快照读 InnoDB快照读，数据的读取将由 cache（事务修改过的数据） + undo（原本数据） 两部分组成 当前读： SQL读取的数据是最新版本 通过锁机制来保证读取的数据无法通过其他事务进行修改 UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE都是当前读 Redo logredo log是为了实现事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的未入磁盘数据进行持久化这一特性 指定redo log记录在 {datadir}/ib_logfile1&amp;ib_logfile2 可通过 innodb_log_group_home_dir 配置指定 目录存储 一旦事务成功提交且数据持久化落盘之后，此时redo log中的对应事务数据记录就失去了意义，所以redo log的写入是日志文件循环写入的 指定redo log日志文件组中的数量 innodb_log_files_in_group 默认为2 指定redo log每一个日志文件最大存储量 innodb_log_file_size 默认48M 指定redo log在 cache/buffer 中的 buffer 池大小 innodb_log_buffer_size 默认16M Redo buffer 持久化Redo log的策略， Innodb_flush_log_at_trx_commit : 取值 0 每秒提交 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（可能丢失一秒内的事务数据） 取值 1 每次事务提交执行 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（默认值，最安全，性能最差的方式） 取值 2 每次事务提交执行 Redo buffer -&gt; Redo log OS cache 再每一秒执行 -&gt; flush cache to disk]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql InnoDB锁机制]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-InnoDB%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[表锁和行锁锁是用于管理不同事务对共享资源的并发访问 表锁与行锁的区别: 锁定粒度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 InnoDB 存储引擎支持行锁和表锁（表锁是通过行锁实现的） InnoDB 锁类型锁类型： 共享锁（行锁）：Shared Locks 排它锁（行锁）：Exclusive Locks 意向共享锁（表锁）：IntentionShared Locks 意向排它锁（表锁）：Intention Exclusive Locks 自增锁：AUTO-INC Locks 行锁的算法： 记录锁 Record Locks 间隙锁 Gap Locks 临键锁 Next-key Locks 共享锁与排他锁共享锁又称为读锁，简称 S锁 ，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改 加锁释锁方式： 12select * from users WHERE id=1 LOCK IN SHARE MODE; commit/rollback; 举个例子： 12345678### session1 ###begin;select * from sys_user where id=1 lock in share mode; # 获取S锁commit;### session2 ###select * from sys_user where id=1; # 可以正常执行update sys_user set name=&apos;k2&apos; where id=1; # 当上面没有commit，该语句将被阻塞 排他锁又称为写锁，简称 X锁 ，排他锁不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的锁（共享锁、排他锁），只有该获取了排他锁的事务是可以对数据行进行读取和修改，（其他事务要读取数据可来自于快照） 加锁释锁方式： 123delete / update / insert 默认加上X锁SELECT * FROM table_name WHERE ... FOR UPDATE;commit/rollback; 例子： 123456789### session1 ###begin;update sys_user set name=&apos;k3&apos; where id=1; # 自动获取X锁commit;### session2 ###select * from sys_user where id=1 for update; # 等待上面commitselect * from sys_user where id=1 lock in share mode; # 等待上面commitselect * from sys_user where id=1; # 没影响 那么 InnoDB 行锁到底锁了什么？InnoDB的行锁是通过给索引上的索引项加锁来实现的 只有通过索引条件进行数据检索，InnoDB才使用行级锁，否则，InnoDB 将使用表锁（锁住索引的所有记录） 所以在执行 delete / update / insert 时，也需要考虑索引，因为没有命中索引会变成表锁 表锁： 1lock tables xx read/write; 意向共享锁与意向排它锁 意向共享锁（IS） 表示事务准备给数据行加入共享锁，即一个数据行加共享锁前必须先取得该表的IS锁 意向排它锁（IX） 表示事务准备给数据行加入排他锁，即一个数据行加排他锁前必须先取得该表的IX锁 简单来说，这两种锁就是一个标志位，在拿锁之前，先要判断IS/IX 意向锁（IS、IX）是 InnoDB 数据操作之前自动加的，不需要用户干预 当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁 自增锁针对自增列自增长的一个特殊的表级别锁 1show variables like &apos;innodb_autoinc_lock_mode&apos;; 默认取值1，代表连续，事务未提交ID永久丢失 记录锁、间隙锁、临键锁临键锁（Next-Key）临键锁是 InnoDB 默认的行锁算法 当sql执行按照索引进行数据的检索时，查询条件为范围查找（between and、&lt;、&gt;等）并有数据命中，则此时sql语句加上的锁为 Next-Key locks，锁住索引的记录 + 区间（左开右闭） 例子： 当数据库里与 id 为1、4、7、10四条数据，那么： 它可以有效的方式幻读 间隙锁（Gap）当sql执行按照索引进行数据的检索时，查询条件的数据不存在，这时sql语句加上的锁即为Gap locks，锁住索引不存在的区间（左开右开） Gap locks只在RR事务隔离级别存在 记录锁（Record）当sql执行按照唯一性（Primary key、Unique key）索引进行数据的检索时，查询条件等值匹配且查询的数据时存在，这时sql语句加上的锁为记录锁，锁住具体的索引项 锁是如何解决事务并发解决脏读 解决不可重复读 解决幻读 死锁当2个或以上事务都在等待对方释放锁，产生循环等待，即形成了死锁 如何解决： 类似的业务逻辑以固定的顺序访问表和行 大事务拆小（大事务更倾向于死锁） 在同一个事务中，尽可能做到一次锁定所需要的所有资源 如果业务允许，可以降低事务隔离级别 为表添加合适的索引（如果不走索引将会为表的每一行记录添加上锁，产生表锁）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作，事务是一组不可再分割的操作集合（工作逻辑单元） mysql中如何开启事务： 123begin / start transaction -- 手工commit / rollback -- 事务提交或回滚set session autocommit = on/off; -- 设定事务是否自动开启 事务ACID特性 原子性（Atomicity） 最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚 一致性（Consistency） 事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致 隔离性（Isolation） 一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般设定为不可见） 持久性（Durability） 事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失 事务并发带来的问题脏读： 不可重复读： 幻读： 事务隔离级别SQL92 ANSI/ISO标准：http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt 隔离级别 解决问题 说明 Read Uncommitted（未提交读） 未解决并发问题 事务未提交对其他事务也是可见的，产生脏读 Read Committed（提交读） 脏读 一个事务开始之后，只能看到自己提交的事务所做的修改，产生不可重复读 Repeatable Read（可重复读） 不可重复读 在同一个事务中多次读取同样的数据结果是一样的，这种隔离级别未定义解决幻读的问题 Serializable（串行化） ALL 最高的隔离级别，通过强制事务的串行执行 InnoDB对事物隔离级别的支持 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（未提交读） 可能 可能 可能 Read Committed（提交读） 不可能 可能 可能 Repeatable Read（可重复读） 不可能 不可能 对InnoDB不可能 Serializable（串行化） 不可能 不可能 不可能 在 InnoDB 引擎中，默认隔离级别是Repeatable Read（可重复读），也可以防止幻读 隔离级别到底是如何实现的？ 锁、MVVC]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询优化]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Mysql 查询执行路径 Mysql 客户端/服务端通信](#Mysql 客户端/服务端通信) 查询缓存 查询优化处理 查询执行引擎 返回客户端 详解Mysql 客户端/服务端通信Mysql客户端与服务端的通信方式是“半双工” 全双工：双向通信，发送同时也可以接收 半双工：双向通信，同时只能接收或者是发送，无法同时做操作 单工：只能单一方向传送 半双工通信：在任何一个时刻，要么是有服务器向客户端发送数据，要么是客户端向服务端发送数据，这两个动作不能同时发生。所以我们无法也无需将一个消息切成小块进行传输 特点和限制：客户端一旦开始发送消息，另一端要接收完整个消息才能响应。 客户端一旦开始接收数据没法停下来发送指令。 通信查询状态对于一个mysql连接，或者说一个线程，时刻都有一个状态来标识这个连接正在做什么 官方状态全集：https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html 我们可以通过以下命令查看： 12show full processlist;show processlist; 执行结果： 1234567mysql&gt; show processlist;+------+------+-----------+------+---------+------+-------+------------------+| Id | User | Host | db | Command | Time | State | Info |+------+------+-----------+------+---------+------+-------+------------------+| 9543 | root | localhost | NULL | Query | 0 | init | show processlist |+------+------+-----------+------+---------+------+-------+------------------+1 row in set (0.00 sec) 整理常见的状态： 状态 说明 Sleep 线程正在等待客户端发送数据 Query 连接形成正在执行查询 Locked 线程正在等待表锁的释放 Sorting result 线程正在对结果进行排序 Sending data 向请求端发送数据 可以通过 kill {id} 的方式进行杀除连接 查询缓存工作原理： 缓存 SELECT 操作的结果集和SQL语句 新的 SELECT 语句，先去查询缓存，判断是否存在可用的记录集 判断标准： 与缓存的SQL语句是否完全一样（区分大小写） 查看缓存设置通过 show variables like &#39;query_cache%&#39;; 命令查询： 1234567891011mysql&gt; show variables like &apos;query_cache%&apos;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+5 rows in set (0.00 sec) query_cache_type 0：不启用查询缓存，默认值 1：启用查询缓存，只要符合查询缓存要求，客户端的查询语句和记录集都可以缓存起来（加上 SQL_NO_CACHE 将不缓存） 2：启用查询缓存，只要查询语句中添加参数 SQL_CACHE ，且符合查询缓存的要求，客户端的查询语句和记录集都可以缓存起来 query_cache_size总的缓存池的大小，允许设置最小值为 40K，默认 1M，推荐设置为 ：32M、64M、128M 超过该大小，会将之前的缓存失效 query_cache_limit限制单次查询，缓存区最大能缓存的查询记录集，默认设置为 1M 查看缓存情况可以通过 show status like &#39;Qcache%&#39;;： 1234567891011121314mysql&gt; show status like &apos;Qcache%&apos;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031352 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 150 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+8 rows in set (0.00 sec) 不会缓存的情况 当查询语句中有一些不确定的数据时，则不会被缓存 如包含函数 NOW() 、CURRENT_DATE() 等类似的函数，或者用户自定义的函数，存储函数，用户变量等都不会被缓存 当查询的结构大于 query_cache_limit 设置的值时 对于 InnoDB 引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之后，所有与这个表相关的查询都无法被缓存 update table set name=’hello’ where id=3; 查询的表是系统表 查询语句不涉及到表 select 1; 为什么Mysql默认关闭了缓存 在查询之前必须先检查是否命中缓存，浪费计算资源 如果这个查询可以缓存，那么执行完成后，Mysql发现查询缓存中没有这个查询，则会将结构存入查询缓存，带来额外的系统消耗 针对表进行写入或更新操作时，将对应表的所有缓存都设置失效 如果查询缓存很大或者碎片很多时，这个操作可能带来很大的系统消耗 适用场景： 以读为主的业务，数据生成之后就不常改变的业务 查询优化处理查询优化处理的三个阶段： 解析sql 通过lex词法分析，yacc语法分析将sql语句解析成解析树（Yacc 与 Lex语法教程） 预处理阶段 根据mysql的语法的规则进一步检查解析树的合法性，如：检查数据的表和列是否存在，解析名字和别名的设置。还会进行权限的验证 查询优化器 优化器的主要作用就是找到最优的执行计划 解析sql和预处理阶段主要是解析和校验的一个过程，我们重点来讲下查询优化器 查询优化器如何找到最优执行计划Mysql的查询优化器是基于成本计算的原则。他会尝试各种执行计划。 数据抽样的方式进行试验（随机的读取一个4K的数据块进行分析） 使用等价变化规则 5=5 and a&gt;5 改写成 a&gt;5 a5 and a=5 基于联合索引，调整条件位置 … 优化count 、min、max等函数 min函数只需找索引最左边 ，max函数只需要索引最右边 myisam引擎 count(*) 无需遍历全表 覆盖索引扫描 子查询优化 提前终止查询 用了limit关键字或者使用不存在的条件 IN的优化 先进性排序，再采用二分查找的方式（所以尽量使用 in ，而少用 or ） …… 执行计划使用 EXPLAIN ： 12345678910111213mysql&gt; explain select * from table01 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table01 type: systempossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 0 Extra: const row not found1 row in set (0.00 sec) idselect查询的序列号，标识执行的顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同又不同即两种情况同时存在，id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 select_type查询的类型，主要是用于区分普通查询、联合查询、子查询等 SIMPLE：简单的 select 查询，查询中不包含子查询或者 union PRIMARY：查询中包含子部分，最外层查询则被标记为 primary SUBQUERY/MATERIALIZED：SUBQUERY 表示在 select 或 where 列表中包含了子查询，MATERIALIZED 表示 where 后面 in 条件的子查询 UNION：若第二个 select 出现在 union 之后，则被标记为 union UNION RESULT：从union表获取结果的select table查询涉及到的表 直接显示表名或者表的别名 &lt;unionM,N&gt; 由ID为M,N 查询 union 产生的结果 由ID为N查询生产的结果 type访问类型，sql查询优化中一个很重要的指标，结果值从好到坏依次是： 1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL system：表只有一行记录（等于系统表），const 类型的特例，基本不会出现，可以忽略不计 const：表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引 eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描 ref：非唯一性索引扫描，返回匹配某个单独值的所有行，本质是也是一种索引访问 range：只检索给定范围的行，使用一个索引来选择行 index：Full Index Scan，索引全表扫描，把索引从头到尾扫一遍 ALL：Full Table Scan，遍历全表以找到匹配的行 在实际应用中，尽量要在 range 级别以上 possible_keys查询过程中有可能用到的索引 key实际使用的索引，如果为NULL，则没有使用索引 rows根据表统计信息或者索引选用情况，大致估算出找到所需的记录所需要读取的行数 filtered它指返回结果的行占需要读到的行（rows列的值）的百分比 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好 Extra十分重要的额外信息 Using filesort：mysql对数据使用一个外部的文件内容进行了排序，而不是按照表内的索引进行排序读取 Using temporary：使用临时表保存中间结果，也就是说mysql在对查询结果排序时使用了临时表，常见于order by 或 group by Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了访问表的数据行，效率高 Using where：使用了where过滤条件 select tables optimized away：基于索引优化MIN/MAX操作或者MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即可完成优化 查询执行引擎调用插件式的存储引擎的原子API的功能进行执行计划的执行 返回客户端 有需要做缓存的，执行缓存操作 增量的返回结果：开始生成第一条结果时，mysql就开始往请求方逐步返回数据 好处：mysql服务器无须保存过多的数据，浪费内存。用户体验好，马上就拿到了数据 慢查询分析定位如何定位慢SQL 业务驱动 测试驱动 慢查询日志 前面2种是通过人为的方式来定位，我们主要看下第三种方式 慢查询日志慢查询日志配置通过 show variables like &#39;slow_query_log&#39;; 查看： 1234567mysql&gt; show variables like &apos;slow_query_log&apos;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+1 row in set (0.00 sec) 通过 set global slow_query_log = on 开启日志 查看日志文件地址： 12345678mysql&gt; show variables like &apos;slow_query%&apos;;+---------------------+-------------------------------------------+| Variable_name | Value |+---------------------+-------------------------------------------+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/instance-dq9parum-slow.log |+---------------------+-------------------------------------------+2 rows in set (0.00 sec) 如上所示，日志地址在 /var/lib/mysql/instance-dq9parum-slow.log 通过 set global log_queries_not_using_indexes = on 设置没有命中索引的需要记录日志 通过 set global long_query_time = 0.1 （单位：秒）设置查询超过多少时间的需要记录日志 慢查询日志分析查看 /var/lib/mysql/instance-dq9parum-slow.log： 12345# Time: 181219 22:39:30# User@Host: root[root] @ [36.22.250.90] Id: 10887# Query_time: 0.000321 Lock_time: 0.000145 Rows_sent: 1 Rows_examined: 2SET timestamp=1545230370;select * from table01 where name in(&apos;name&apos;); Time：日志记录的时间 User@Host：执行的用户及主机 Query_time：查询耗费时间 Lock_time：锁表时间 Rows_sent：发送给请求方的记录条数 Rows_examined：语句扫描的记录条数 SET timestamp：语句执行的时间点 select ….：执行的具体语句 慢查询日志分析工具 mysqldumpslow mysqlsla pt-query-digest]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储引擎]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言介绍 插拔式的插件方式 存储引擎是指定在表之上的，即一个库中的每一个表都可以指定专用的存储引擎 不管表采用什么样的存储引擎，都会在数据区，产生对应的一个frm文件（表结构定义描述文件） 1-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user.frm 各存储引擎对比查看官网：https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html CSV 存储引擎数据存储以CSV文件： 1-rw-rw---- 1 mysql mysql 0 12月 18 19:27 table_csv.CSV 看其文件内容： 121,&quot;chen&quot;2,&quot;jian&quot; 存储的就是我们的表数据 特点： 不能定义索引、列定义必须为NOT NULL、不能设置自增列 不适用大表或者数据的在线处理 CSV数据的存储用 , 隔开，可直接编辑CSV文件进行数据的编排 数据安全性低（编辑之后，要生效使用flush table XXX 命令） 应用场景： 数据的快速导出导入 表格直接转换成CSV Archive 存储引擎压缩协议进行数据的存储，数据存储为 ARZ 文件格式 1-rw-rw---- 1 mysql mysql 8674 12月 18 19:40 table_archive.ARZ 特点： 只支持 insert 和 select 两种操作 只允许自增ID列建立索引 行级锁 不支持事务 数据占用磁盘少 应用场景： 日志系统 大量的设备数据采集 Memory 存储引擎数据都是存储在内存中，IO效率要比其他引擎高很多，服务重启数据丢失，内存数据表默认只有16M 特点： 支持hash索引，B tree索引，默认hash（查找复杂度 0(1) ） 字段长度都是固定长度 varchar(32)=char(32) 不支持大数据存储类型字段如 blog ，text 表级锁 应用场景： 等值查找热度较高数据 查询结果内存中的计算，大多数都是采用这种存储引擎作为临时表存储需计算的数据 实际应用中不常用 Myisam 存储引擎Mysql5.5 版本之前的默认存储引擎 较多的系统表也还是使用这个存储引擎 系统临时表也会用到 Myisam 存储引擎（Memory 存储引擎不支持的情况下，比如数据超过了16M） 12-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table_myisam.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table_myisam.MYI 特点： select count(*) from table 无需进行数据的扫描（有专门存储） 数据（.MYD）和索引（.MYI）分开存储 表级锁 不支持事务 InnoDB 存储引擎Mysql5.5及以后版本的默认存储引擎 1-rw-rw---- 1 mysql mysql 98304 12月 6 19:00 table_innodb.ibd 特点： 支持事务ACID 行级锁 聚集索引（主键索引）方式进行数据存储 支持外键关系保证数据完整性（尽量不要用）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql索引]]></title>
    <url>%2F2019%2F02%2F26%2Fmysql%2FMysql%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引是为了加速对表中数据行的检索而创建的一种分散存储的数据结构 为什么要用索引： 索引能极大的减少存储引擎需要扫描的数据量 索引可以把随机IO变成顺序IO 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表 Mysql 为什么使用 B+Tree二叉查找树 动画演示 平衡二叉查找树 动画演示 缺点： 太深了 数据处的(高)深度决定着他的IO操作次数，IO操作耗时大 太小了 每一个磁盘块(节点/页)保存的数据量太小了 没有很好的利用操作磁盘IO的数据交换特性 没有利用好磁盘IO的预读能力(空间局部性原理)，从而带来频繁的IO操作 多路平衡查找树动画演示 B-Tree B+Tree B-Tree 和 B+Tree区别 B+节点关键字搜索采用闭合区间 B+非叶节点不保存数据相关信息，只保存关键字和子节点的引用 B+关键字对应的数据保存在叶子节点中 B+叶子节点是顺序排列的，并且相邻节点具有顺序引用的关系 为什么选用 B+Tree B+树是B-树的变种(PLUS版)多路绝对平衡查找树，他拥有B-树的优势 B+树扫库、表能力更强 B+树的磁盘读写能力更强 B+树的排序能力更强 B+树的查询效率更加稳定 Mysql B+Tree 索引体现Myisam Engine 在 Myisam 引擎中，数据库对应的表会有这么几个文件 123-rw-rw---- 1 mysql mysql 8556 12月 18 16:30 table01.frm-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table01.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table01.MYI .MYD 文件存储的是具体的数据内容 .MYI 文件存储的是索引树 如上图，在 Myisam 引擎中，索引指向的是数据的地址 Innodb Engine 12-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user01.frm-rw-rw---- 1 mysql mysql 98304 12月 6 18:56 sys_user01.ibd 在 Innodb 引擎中，只有 .ibd 文件 Innodb 引擎中，它是以主键为索引来组织数据的存储（没有指定主键，它会隐式创建），它的叶子节点存储的是具体的数据 它分为主键索引（聚集索引）和辅助索引（非聚集索引）： 主键索引叶子节点存储具体的数据 辅助索引叶子节点存储主键值 当辅助索引获取到主键值后，再通过主键索引查找到具体的数据 这里会有2个问题： 为什么辅助索引叶子节点不存储主键索引数据的引用呢？ 当数据的引用发生变化时，需要更新所有辅助索引的数据引用 为什么需要主键索引，且都是通过主键索引去查数据 这和 Innodb 的设计初衷有关，它认为主键是最常用的查询条件 索引知识补充列的离散性离散性表示数据重复率 在建索引的时候，离散性越高，选择性就越好，命中索引的概率也就越高 最左匹配原则对索引中关键字进行计算(对比)，一定是从左往右依次进行，且不可跳过 比如说，在我们建标时，会有一个排序规则，通过会设置成 utf8_general_ci，这会把数据转成 ASCII 码： 12abc -&gt; 97 98 99adc -&gt; 97 100 99 联合索引 单列索引 节点中关键字[name] 联合索引 节点中关键字[name,phoneNum] 单列索引是特殊的联合索引 联合索引列选择原则： 经常用的列优先 【最左匹配原则】 选择性(离散度)高的列优先【离散度高原则】 宽度小的列优先【最少空间原则】 例子如下是最常用的sql： 12select * from users where name = ?;select * from users where name = ? and phoneNum = ?; 解决方案，在 name 和 phoneNum 上都建索引： 12create index idx_name on users(name);create index idx_name_phoneNum on users(name,phoneNum); 问题在哪？ 根据最左匹配原则，这两个sql都可以命中第二个索引，所以第一个索引是冗余的 覆盖索引如果查询列可通过索引节点中的关键字直接返回，则该索引称之为覆盖索引，覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能 比如我建了下面这个索引： 1create index idx_name_phoneNum on users(name,phoneNum); 当我们这么查时： 1select name,phoneNum from users where name = ?; 上面的sql只查询 name 和 phoneNum，当命中索引时，不需要到叶子节点获取数据，直接在中间节点就可以把数据直接返回，这就是覆盖索引 总结 索引列的数据长度能少则少 索引一定不是越多越好，越全越好，一定是建合适的 匹配列前缀可用到索引 like 9999%（不一定，要看离散性），like %9999%、like %9999用不到索引 Where 条件中 not in 和 &lt;&gt;操作无法使用索引 匹配范围值，order by 也可用到索引 多用指定列查询，只返回自己想到的数据列，少用select * 联合索引中如果不是按照索引最左列开始查找，无法使用索引 联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引 联合索引中如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo + github pages建立个人博客]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github-pages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 hexo安装hexo官方文档：https://hexo.io/zh-cn/docs/ 按照官网文档安装hexo，安装hexo之前需要先安装 node（推荐使用 nvm 安装） 和 git 基本使用 初始化网站： 12hexo init &lt;dirName&gt; # 也可以新建一个空目录，然后执行 hexo initnpm install # npm安装 生成静态文件： 1hexo g # 或者使用 hexo generate 启动本地服务： 1hexo s # 或者使用 hexo server，然后通过http://127.0.0.1:4000访问 常用命令：1234hexo n == hexo new # 新建文章、页面等hexo g == hexo generate # 生成静态文件hexo s == hexo server # 启动服务hexo d == hexo deploy # 发布 主题官方主题地址：https://hexo.io/themes/ 这里使用的是 next，地址：http://theme-next.iissnan.com/ 只要将主题放到 themes 目录下，然后修改站点配置文件 _config.yml 中的 theme 值即可 具体设置可以参考上面的next文档 使用github部署hexo修改站点配置文件 _config.yml ：1234deploy: type: git repo: git@github.com:cpp288/cpp288.github.io.git #这里的网址填你自己的 branch: master 配置github ssh key： ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot; 生成新的key文件，邮箱地址填你的Github地址，后面直接回车进行 将生成的工钥 id_rsa.pub 配置到 github 上 执行 ssh -T git@github.com 如下提示则成功1Hi cpp288! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 安装扩展：1npm install hexo-deployer-git --save 部署到 github：1hexo d 相关问题电脑重装了系统/多台电脑写博客？ 参考博客： https://www.zhihu.com/question/21193762 https://blog.csdn.net/heimu24/article/details/81210640 如何添加本地图片？ 在 source 目录下新建目录，将图片放在其中（可以建多级目录），hexo 会在 generate 时将图片放到 public 中，使用 markdown 图片语法即可 相关博客 我是如何利用Github Pages搭建起我的博客，细数一路的坑 Hexo和Next主题的相关设置（持续更新） 使腾讯404公益页面支持HTTPS 【持续更新】最全Hexo博客搭建+主题优化+插件配置+常用操作+错误分析]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
