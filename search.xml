<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis集群主从复制原理]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E9%9B%86%E7%BE%A4%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[复制的作用是把redis的数据复制多个副本部署在不同的服务器上，如果其中一台服务器出现故障，也能快速迁移到其它服务器上提供服务。 主从复制就是我们常见的master/slave模式，主redis可以进行读写操作，当写操作导致数据发生变化时，会讲数据同步到从reids，而一般情况下，从redis是只读的，并接收主redis同步过来的数据。一个主redis可以有多个从redis 配置在redis中配置master/slave是非常容易的，只需要在slave的配置文件中加入slaveof主redis的地址、端口。而master不需要做任何变化 比如两台服务器，分别安装redis：server01和server02，将server01作为master，server02作为slave，配置如下： 在从节点server02的redis.conf文件中增加slaveof server01-ip server01-port 将主节点server01的bindip注释掉，允许所有ip访问 访问从节点server02的redis客户端，输入INFO replication，可以查看节点信息 原理（复制方式）redis提供了3中主从复制方式： 全量复制 增量复制 无硬盘复制 全量复制Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份 完成上面几个步骤后就完成了slave服务器数据初始化的所有操作，savle服务器此时可以接收来自用户的读请求。 master/slave复制策略是采用乐观复制，也就是说可以容忍在一定时间内master/slave数据的内容是不同的，但是两者的数据会最终同步。具体来说，redis的主从同步过程本身是异步的，意味着master执行完客户端请求的命令后会立即返回结果给客户端，然后异步的方式把命令同步给slave。这一特征保证启用master/slave后master的性能不会受到影响。 另一方面，如果在这个数据不一致的窗口期间，master/slave因为网络问题断开连接，而这个时候，master 是无法得知某个命令最终同步给了多少个slave数据库。不过redis提供了一个配置项来限制只有数据至少同步给多少个slave的时候，master才是可写的: min-slaves-to-write 3：表示只有当3个或以上的slave连接到master，master才是可写的 min-slaves-max-lag 10：表示允许slave最长失去连接的时间，如果10秒还没收到slave的响应，则master认为该slave以断开 增量复制从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份 master node会在内存中创建一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制 但是如果没有找到对应的offset，那么就会执行一次全量同步 无硬盘复制Redis复制的工作原理基于RDB方式的持久化实现的，也就是master在后台保存RDB快照，slave接收到rdb文件并载入，但是这种方式会存在一些问题： 当master禁用RDB时，如果执行了复制初始化操作，Redis依然会生成RDB快照，当master下次启动时执行该 RDB文件的恢复，但是因为复制发生的时间点不确定，所以恢复的数据可能是任何时间点的。就会造成数据出现问题 当硬盘性能比较慢的情况下(网络硬盘)，那初始化复制过程会对性能产生影响 因此2.8.18以后的版本，Redis引入了无硬盘复制选项，可以不需要通过RDB文件去同步，直接发送数据，通过以下配置来开启该功能：1repl-diskless-sync yes master在内存中直接创建rdb，然后发送给slave，不会在落地到自己本地磁盘]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Cluster]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis-Cluster%2F</url>
    <content type="text"><![CDATA[即使是使用哨兵，此时的redis集群的每个数据库依然存有集群中的所有数据，从而导致集群的总数据存储量受限于可用存储内存最小的节点，形成木桶效应。因为redis是基于内存存储的，所以这个问题尤为突出。 在redis3.0之前，我们是通过在客户端去做分片，通过hash的方式对key进行分片存储。分片虽然能够解决各个节点的存储压力，但是维护成本高，增加、移除节点比较繁琐。因此在3.0之后的版本支持了集群功能，集群的特点在于拥有和单机实例一样的性能，同时在网络分区以后能够提供一定的可访问性以及对主数据库故障恢复的支持。 哨兵和集群是两个独立的功能，当不需要对数据进行分片使用哨兵就够了，如果要进行水平扩容，集群是一个比较好的方式 拓扑结构一个redis-cluster由多个redis节点构成，不同节点组服务的数据没有交集。 节点组内分为主备两类节点，对应master和slave节点，两者数据准实时一致，通过异步化的主备复制机制来保证。一个节点组有且只有一个master节点，可以有0到多个slave节点，在这个节点组中只有master节点对用户提供写服务，读服务可以由master和slave提供 redis-cluster是基于gossip协议实现的无中心化节点的集群，因为去中心化的架构不存在统一的配置中心，各个节点对整个集群状态的认知是来自于节点之间的信息交互。在redis-cluster中，这个信息交互是通过Redis Cluster Bus来完成的 数据分区分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，每个节点负责整个数据的一个子集，redis-cluster采用哈希分区规则，采用虚拟槽分区。 虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合中，整数定义为槽（slot）。redis-cluster槽的范围是0 ~ 16383。 槽是集群内数据管理和迁移的基本单位，采用大范围的槽的主要目的是为了方便数据的拆分和集群的扩展，每个节点负责一定数量的槽，计算公式：1slot = CRC16(key)%16383 如下图所示： HashTags通过分片手段，可以将数据合理的划分到不同的节点上，但是有时候，我们希望对相关联的业务以原子方式进行操作，比如： 在单节点上执行MSET，是一个原子操作，但是在集群环境下，它的操作就不是原子操作，是因为多个key可能会被分配到不同的机器上 所以，就会有一个矛盾点，即要求key尽可能的分散在不同机器上，又要求相关联的key分配到相同的机器上，这该如何解决呢？ 从之前的分析中可以了解到，分片其实就是一个hash的过程，对key做hash取模后划分到不同的机器上。所以要做到上面这点，需要考虑如何让相关联的key得到的hash值都相同，在redis中引入了HashTags的概念，可以使得数据分布算法可以根据key的某一个部分进行计算，然后让相关的key落到同一个数据分片中。 举个例子：加入对于用户的信息进行存储：user:user1:id、user:user1:name，那么通过hashtag的方式：user:{user1}:id、user:{user1}:name 当一个key包含{}的时候，就不对整个key做hash，而是仅对{}包含的字符串做hash 重定向客户端Redis Cluster并不会代理查询，那么如果客户端访问了一个key并不存在的节点，该如何处理？比如获取key为msg的值，msg计算出来的槽编号为254，当前节点正好不负责编号为254的槽，那么就会返回客户端下面的信息：1-MOVED 254 127.0.0.1:6381 表示客户端想要的254槽由运行在IP为127.0.0.1，端口为6381的master示例服务上，如果恰好由当前节点负责，则当前节点会立即返回结果 分片迁移在一个稳定的redis-cluster下，每一个slot对应的节点是确定的，但是在以下情况节点和分片对应的关系会发生变更： 新加入master节点 某个节点宕机 也就是说当动态添加或减少节点时，需要将16384个槽做个再分配，槽中的键值也要迁移（这一过程处于半自动状态，需要人工介入） 新增一个主节点： 新增一个节点D，redis-cluster从各个节点的前面各拿取一部分slot到D上，最后大致会变成： 节点A覆盖1365 ～ 5460 节点B覆盖6827 ～ 10922 节点C覆盖12288 ～ 16383 节点D覆盖0 ～ 1364，5461 ～ 6826，10923 ～ 12287 删除一个节点： 先将节点的数据移动到其它节点上，然后执行删除 槽迁移的过程槽迁移的过程中有一个不稳定状态，这个不稳定状态会有一些规则，这些规则定义客户端的行为，从而使得redis-cluster不必宕机的情况下也可以执行槽的迁移。如下图（迁移槽编号为1，2，3的）： 简单的工作流程： 向Master B发送状态变更命令，把Master B对应的slot状态设置为IMPORTING 向Master A发送状态变更命令，把Master A对应的slot状态设置为MIGRATING 当状态变成IMPROTING或者MIGRATING时，对于slot内部数据提供读写服务的行为和通常状态下是有区别的 MIGRATING状态 如果客户端访问的key还没有迁移出去，则正常处理这个key 如果key已经迁移或者根本就不存在这个key，则回复客户端ASK信息让它跳转到Master B去执行 IMPORTING状态当来自客户端的正常访问不是从ASK跳转过来的，说明客户端还不知道迁移正在进行，很有可能操作了一个目前还没迁移完成的并且还存在与Master A上的key，如果此时在A上已经修改了，那么B和A的修改则会发生冲突。 对于Master B上的slot所有非ASK跳转过来的操作，Master B都不会去处理，而是通过MOVED命令让客户端调转到Master A上去处理]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵机制]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[再master/slave模式中，当master遇到异常中断后，需要从slave中选举一个新的master继续对外提供服务，这种机制有很多，比如在zk中的leader选举、kafka中可以基于zk的节点实现master选举。所以在redis中也需要一种机制去实现master的决策，redis没有提供自动master选举功能，需要借助一个哨兵来进行监控。 哨兵的作用就是监控redis系统的运行情况，功能包括两个： 监控master和slave是否正常运行 master出现故障时自动将slave数据库升级为master 哨兵是一个独立的进程，使用哨兵后的架构图： 哨兵集群为了解决master选举问题，又引出了一个单点问题，就是哨兵的可用性问题，在一个一主多从的redis系统中，可以使用多个哨兵进行监控来保证系统足够稳定，此时哨兵不仅会监控master和slave，同时还会互相监控。这种方式成为哨兵集群，哨兵集群需要解决故障发现和master决策协商机制问题。 哨兵之间的相互感知哨兵节点之间会因为共同监视同一个master从而产生关联，一个新加入的哨兵节点需要和其他监视相同master节点的哨兵相互感知： 需要相互感知的哨兵都向他们共同监视的master节点订阅channel:sentinel:hello 新键入的哨兵节点向这个channel发布一条消息，包含自己本身的信息，这样订阅了这个channel的哨兵就可以发现这个新的哨兵 新加入的哨兵和其他哨兵节点建立长连接 master故障发现sentinel节点会定期向master节点发送心跳包来判断存活状态，一旦master节点没有正确响应，sentinel会把master设置为“主观不可用状态”，然后会把“主观不可用”发送给其他所有的sentinel节点去确认，当确认的sentinel节点数大于quorum时，则会认为master是“客观不可用”，接着就开始进入选举新的master流程。 这里会遇到一个问题，就是sentinel中，本身是一个集群，如果多个节点同时发现master节点达到客观不可用状态，那谁来决策选择哪个节点作为master呢？ 这个时候就需要从sentinel集群中选择一个leader来做决策，这里用到了一致性算法Raft算法，它和Paxos算法类似，都是分布式一致性算法，但是它比Paxos算法更容易理解，它们都是基于投票算法，只要保证半数节点通过提议即可 动画演示地址：http://thesecretlivesofdata.com/raft 配置实现创建sentinel.conf文件，文件主要配置：1234567891011// sentinel monitor name ip port quorum// name表示要监控的master的名字，自定义// ip和port表示master的ip和端口号// quorum表示最低通过票数，也就是说需要几个哨兵节点统一才可以sentinel monitor mymaster 192.168.11.131 6397 1// 表示如果5s内mymaster没响应，就认为SDOWNsentinel down-after-milliseconds mymaster 5000// 表示15s后，mymaster仍没活过来，则启动failover，从剩下的slave中选一个升级为mastersentinel failover-timeout mymaster 15000 两种方式启动哨兵：12redis-sentinel sentinel.confredis-server /path/sentinel.conf --sentinel 哨兵监控一个系统时，只需要配置监控master即可，哨兵会自动发现所有slave]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis中字符串的二进制安全]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E4%B8%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[什么是二进制安全 二进制安全是指，在传输数据时，保证二进制数据的信息安全，也就是不被篡改、破译等，如果被攻击，能够及时检测出来。 Redis中的二进制安全C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。 举个例子，如果有一种使用空字符来分割多个单词的特殊数据格式，如下图所示，那么这种格式就不能使用C字符串来保存，因为C字符串所用的函数只会识别出其中的”Redis”，而忽略之后的”Cluster”。 虽然数据库一般用于保存文本数据，但使用数据库来保存二进制数据的场景也不少见，因此，为了确保Redis可以适用于各种不同的使用场景，SDS的API都是二进制安全的（binary-safe），所有SDS的API都会以处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入时是什么样的，它被读取时就是什么样。 这也是我们将SDS的buf属性称为字节数组的原因：Redis不是用这个数组来保存字符，而是用它来保存一系列二进制数据。 例如，使用SDS来保存之前提到的特殊数据格式就没有任何问题，因为SDS使用len属性的值而不是空字符来判断字符串是否结束 通过使用二进制安全的SDS，而不是C字符串，使得Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单线程的Redis性能为什么这么快]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2F%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84Redis%E6%80%A7%E8%83%BD%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[Redis采用了一种非常简单的做法，单线程来处理来自所有客户端的并发请求，Redis把任务封闭在一个线程中从而避免了线程安全问题。 至于为什么是单线程的，官方的解释是，CPU并不是Redis的瓶颈所在，Redis的瓶颈主要在机器的内存和网络的带宽。 Redis采用的是基于内存的、单进程、单线程模型的KV数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的KV数据库Memcached差！有兴趣的可以参考官方的基准程序测试《How fast is Redis？》（https://redis.io/topics/benchmarks） Redis为什么这么快： 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 多路I/O复用 Redis是跑在单线程中的，所有的操作都是按照顺序执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以I/O操作在一般情况下往往不能直接返回，这回导致某一文件的I/O阻塞导致整个进程无法对其他客户端提供服务，而I/O多路复用就是为了解决这个问题而出现的。 在这之前，先简单了解下几种I/O模型： 同步阻塞IO（Blocking IO）：传统的IO模型 同步非阻塞IO（Non-blocking IO）：默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK IO多路复用（IO Multiplexing）：也叫异步阻塞IO，即经典的Reactor设计模式，java中的selector和Linux中的epoll都是这种模型 异步IO（Asynchronous IO）：也叫异步非阻塞IO，即经典的Proactor设计模式 异步和同步、阻塞和非阻塞，感觉原理都差不多，来简单了解下： 同步和异步，是指用户线程和内核的交互方式 阻塞和非阻塞，是指用户线程调用内核IO操作的方式是阻塞还是非阻塞的]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的过期策略以及内存淘汰机制]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis采用的是定期删除+惰性删除策略，官方文档解释：https://redis.io/commands/expire 为什么不用定时删除策略定时删除，用一个定时器来负责监视key，过期则自动删除，虽然内存及时释放，但是十分消耗CPU资源。 在大并发请求下，CPU要将事件应用在处理请求，而不是删除key，因此没有采用这一策略。 定期删除+惰性删除定期删除，redis默认每隔100ms检查，是否有过期的key，有过期key则删除，需要说明的是，redis不是每隔100ms将所有的key检查一次，而是随机进行检查。 因此，如果只采用定期删除策略，会导致很多key到时间没有删除，于是，惰性删除派上用场了，也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间，那么是否过期了，过期此时就会删除。 若果定期删除没有删除key，然后也没有去请求key，也就是惰性删除也没有发生，这样，redis的内存会越来越高，那么就应该采用内存淘汰机制。 在redis.conf中有一行配置：1maxmemory-policy volatile-lru 该配置就是配内存淘汰策略的 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（推荐使用） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又当持久化存储的时候采用 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之Lua脚本]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E4%B9%8BLua%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[为什么要使用Lua脚本Redis中内嵌了对Lua环境的支持，允许开发者使用Lua语言编写脚本传到Redis中执行，直接在服务端原子的执行多个Redis命令。 Lua是一个高效的轻量级脚本语言（JavaScript、shell、sql、python、ruby…），用标准C语言编写并以源代码形式开放，其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和制定功能。 使用Lua脚本的好处： 减少网络开销，在Lua脚本中可以把多个命令放在同一个脚本中运行 原子操作，redis会将整个脚本作为一个整体执行，中间不会被其他命令插入 复用性，客户端发送的脚本会永远存储在redis中，其他客户端可以复用这一脚本来完成同样的逻辑 Lua脚本使用在Lua脚本中调用Redis命令在Lua脚本中调用Redis命令，可以使用redis.call函数调用：12redis.call(&apos;set&apos;, &apos;hello&apos;, &apos;world&apos;)local value = redis.call(&apos;get&apos;, &apos;hello&apos;) redis.call函数的返回值就是redis命令的执行结果，redis.call函数会将redis的数据类型返回值转换对应的Lua的数据类型，在脚本中可以使用return语句将值返回给redis客户端，如果没有执行return，默认返回为nil EVAL命令格式：1[EVAL][脚本内容][key参数的数量][key...][arg...] 可以通过key和arg这两个参数向脚本中传递数据，他们的值可以在脚本中分别使用KEYS和ARGV这两个类型的全局变量访问，比如： Lua脚本：1return redis.call(&apos;set&apos;,KEYS[1],ARGV[1]) // KEYS和ARGV必须大写 EVAL命令：1eval &quot;return redis.call(&apos;set&apos;,KEYS[1],ARGV[1])&quot; 1 lua1 hello 注意：EVAL命令是根据key参数的数量，也就是上面例子中的1来将后面所有参数分别存入脚本中KEYS和ARGV两个表类型的全局变量。当脚本不需要任何参数时也不能省略这个参数，如果没有则设置为0：1eval &quot;return redis.call(&apos;get&apos;,&apos;lua1&apos;)&quot; 0 EVALSHA命令考虑到通过eval执行lua脚本，脚本比较长的情况下，每次调用脚本都需要把整个脚本传给redis，比较占用带宽。为了解决这个问题，redis提供了EVALSHA命令，允许通过脚本内容的SHA1摘要来执行脚本。 该命令用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要： Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中 执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了就执行，否则返回“NOSCRIPT No matching script, Please use EVAL” 将脚本加入缓存并生成sha1摘要：1script load &quot;return redis.call(&apos;get&apos;,&quot;lua1&quot;)&quot; 使用EVALSHA执行：1evalsha &quot;a5a402e90df3hkfakyi32970058233hjfd574&quot; 0 我们在调用eval命令之前，先执行evalsha命令，如果提示脚本不存在，则再调用eval命令]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的数据持久化]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Redis支持两种方式的持久化： RDB方式：根据指定的规则“定时”将内存中的数据存储在硬盘上 AOF(append-only-file)方式：每次执行命令后将命令本身记录下来 两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用 RDB方式当符合一定条件时，Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，等 到持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失 fork的作用是复制一个与当前进程一样的进程。新进程的所有数据(变量、环境变量、程序计数器等)数值都和 原进程一致，但是是一个全新的进程，并作为原进程的子进程 什么情况下会进行RDB快照Redis会在以下几种情况下对数据进行快照: 根据配置规则进行自动快照 用户执行SAVE或者GBSAVE命令 执行FLUSHALL命令 执行复制(replication)时 根据配置规则进行自动快照Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下： 第一个参数是时间窗口 第二个是键的个数 也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。redis默认配置了三个规则：123save 900 1save 300 10save 60 10000 每条快照规则占一行，每条规则之间是“或”的关系。 在900秒(15分)内有一个以上的键被更改则进行快照。 用户执行SAVE或者GBSAVE命令除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务： save命令 当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令 bgsave命令 bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作。 通过LASTSAVE命令可以获取最近一次成功执行快照的时间; (自动快照采用的是异步快照操作) 执行FLUSHALL命令该命令会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作 执行复制时该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。 这里只需要了解当执行复制操作时，即使没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件 AOF方式当使用Redis存储非临时数据时，一般需要打开AOF持久化来降低进程终止导致的数据丢失。AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这一过程会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高AOF的性能 开启AOF默认情况下Redis没有开启AOF(append only file)方式的持久化，可以通过appendonly参数启用，在redis.conf中找到appendonly yes开启AOF持久化后每执行一条会更改Redis中的数据的命令后，Redis就会将该命令写入硬盘中的AOF文件。 AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是apendonly.aof。可以在redis.conf中的属性appendfilename appendonlyh.aof修改 AOF的实现AOF文件以纯文本的形式记录Redis执行的写命令例如开启AOF持久化的情况下执行如下4条命令：1234set foo 1set foo 2set foo 3get redis会将前3条命令写入AOF文件中，通过vim的方式可以看到aof文件中的内容 我们会发现AOF文件的内容正是Redis发送的原始通信协议的内容，从内容中我们发现Redis记录了3条命令，然后这时有一个问题是前面2条命令其实是冗余的，因为这两条的执行结果都会被第三条命令覆盖。随着执行的命令越来越多，AOF文件的大小也会越来越大，其实内存中实际的数据可能没有多少，那这样就会造成磁盘空间以及redis数据还原的过程比较长的问题。因此我们希望Redis可以自动优化AOF文件，就上面这个例子来说，前面两条是可以被删除的。而实际上Redis也考虑到了，可以配置一个条件，每当达到一定条件时Redis就会自动重写AOF文件，这个条件的配置：12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb auto-aof-rewrite-percentage表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据 auto-aof-rewrite-min-size表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。 另外，还可以通过BGREWRITEAOF命令手动执行AOF，执行完以后冗余的命令已经被删除了 在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些 AOF的重写原理Redis可以在AOF文件体积变得过大时，自动地在后台对 AOF进行重写: 重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。 重写的流程是这样： 主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。 在fork子进程这个过程中，服务端仍然可以对外提供服务，那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办?不用担心，这个过程中，主进程的数据更新操作，会缓存到aof_rewrite_buf中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。 当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名，此后所有的操作都会被写入新的aof文件。 如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据结构深入分析]]></title>
    <url>%2F2019%2F04%2F18%2Fredis%2FRedis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Redis提供了丰富的数据类型，包括了字符串、列表、hash、集合、有序集合。redis相关命令可查阅：http://doc.redisfans.com/ 字符串（String）字符串类型是redis中最基本的数据类型，它是二进制安全的（意思是redis的string可以包含任何数据，比如jpg图片或者序列化的对象）。一个字符类型键允许存储的最大容量是512M 内部数据结构在Redis内部，String类型通过int、SDS(simple dynamic string)作为结构存储： int用来存放整型数据 sds存放字节/字符串和浮点型数据 在C的标准字符串结构下进行了封装，用来提升基本操作的性能，同时也充分利用已有的 C的标准库，简化实现逻辑。我们可以在redis的源码中【sds.h】中看到具体实现 redis3.2分支引入了五种sdshdr类型，目的是为了满足不同长度字符串可以使用不同大小的Header，从而节省内存，每次在创建一个sds时根据sds的实际长度判断应该选择什么类型的sdshdr，不同类型的sdshdr占用的内存空间不同。这样细分一下可以省去很多不必要的内存开销，下面是3.2的sdshdr定义 123456789/* 8表示字符串最大长度是2^8-1 (长度为255) */struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len;/*表示当前sds的长度(单位是字节)*/ uint8_t alloc;/*表示已为sds分配的内存大小(单位是字节)*/ /*用一个字节表示当前sdshdr的类型，因为有sdshdr有五种类型，所以至少需要3位来表示*/ /*000:sdshdr5，001:sdshdr8，010:sdshdr16，011:sdshdr32，100:sdshdr64。高5位用不到所以都为0。*/ unsigned char flags; char buf[];/*sds实际存放的位置*/&#125;; 列表（List）列表类型(list)可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素或者获得列表的某一个片段。 列表类型内部使用双向链表实现，所以向列表两端添加元素的时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是很快的 内部数据结构redis版本不同，实现列表的方式是不同的： redis3.2之前，List类型的value对象内部以linkedlist或者ziplist来实现，当list的元素个数和单个元素的长度比较小的时候，Redis会采用ziplist(压缩列表)来实现来减少内存占用。否则就会采用linkedlist(双向链表)结构。 redis3.2之后，采用的一种叫quicklist的数据结构来存储list，列表的底层都由quicklist实现。 这两种存储方式都有优缺点： 双向链表在链表两端进行push和pop操作，在插入节点上复杂度比较低，但是内存开 销比较大; ziplist存储在一段连续的内存上，所以存储效率很高，但是插入和删除都需要频繁申请和释放内存; quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist，其实就是linkedlist和ziplist的结合，quicklist中每个节点ziplist都能够存储多个数据元素。其数据结构图如下： quicklist由quicklistnode组成，quicklistnode可以存放ziplist，也可以存放quicklistLZF，ziplist能够存储多个数据元素 列表结构的应用场景我们可以根据列表的数据结构特点，以及redis对列表操作来应用到以下几个场景： 栈（FILO）：使用LPUSH、LPOP命令实现 队列（FIFO）：使用LPUSH、RPOP命令实现 消息队列：使用LPUSH、BRPOP命令实现 具体的命令可以查看：http://doc.redisfans.com/ hashRedis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 数据结构map提供两种结构来存储，一种是hashtable、另一种是ziplist（数据量小的时候使用ziplist）。在redis中，哈希表分为三层（源码地址【dict.h】）： dictEntry管理一个key-value，同时保留同一个桶中相邻元素的指针，用来维护哈希桶的内部链：12345678910111213typedef struct dictEntry &#123; void *key; union &#123; // 因为value有多种类型，所以value用了union来存储 void *val; uint64_t u64; int64_t s64; double d; &#125; v; // 洗一个节点的地址，用来处理hash碰撞 // 所有分配到同一索引的元素通过next指针链接起来形成链表 // key和v都可以报错多种类型的数据 struct dictEntry *next;&#125; dictEntry; dictht实现一个hash表会使用一个buckets存放dictEntry的地址，一般情况下通过hash(key)%len得到的值就是buckets的索引，这个值决定了我们要将此dictEntry节点放入buckets的哪个索引里，这个buckets实际上就是我们说的hash表： 123456typedef struct dictht &#123; dictEntry **table; // buckets的地址 unsigned long size; // buckets的大小，总保持为2^n unsigned long sizemask; // 掩码，用来计算hash值对应的buckets索引 unsigned long used;// 当前dictht有多少个dictEntry节点&#125; dictht; dictdictht实际上就是hash表的核心，但是只有一个dictht还不够，比如rehash、遍历hash等操作，所以redis定义了一个叫dict的结构以支持字典的各种操作，当dictht需要扩容/缩容时，用来管理dictht的迁移： 1234567typedef struct dict &#123; dictType *type;// dictType里存放的时一堆工具函数的函数指针 void *privdata;// 保存type中的某些函数需要作为参数的数据 dictht ht[2];// 两个dictht，ht[0]平时用，ht[1]rehash时用 long rehashidx;// 当前rehash到buckets的哪个索引，-1时表示非rehash状态 int iterators;// 安全迭代器的计数&#125; dict; 比如我们要将一个数据存储到hash表中，那么会先计算key对应的hashcode，然后根据hashcode取模得到bucket的位置，再插入到链表中 集合（Set）集合类型中，每个元素都是不同的，也就是不能有重复数据，同时集合类型中的数据是无序的，集合类型和列表类型最大的区别就是有序性和唯一性 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在。由于集合类型在redis内部是使用的值为空的散列表（hash table），所以这些操作的时间复杂度都是O(1) 数据结构Set在底层数据结构是以intset或者hashtable存储的： 当set中只包含整数型的元素时，采用intset来存储 其它则用hashtable来存储，但是hashtable的value值为null，通过key来存储元素 有序集合（SortedSet/ZSet）有序集合，顾名思义，和之前的集合多了有序的功能。 在集合的基础上，有序集合为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除和判断元素是否操作等集合支持的操作，还能获得分数最高（或最低）的前N个元素、获得指定分数范围内的元素等与分数有关的操作（虽然集合中每个元素都是不同的，但是它们的分数却可以相同） 数据结构Zset的数据结构比较复杂一点，内部是以ziplist或者skiplist+hashtable来实现的，这里面最核心的一个结构就是skiplist（跳跃表）]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文章收藏]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%96%87%E7%AB%A0%E6%94%B6%E8%97%8F%2F</url>
    <content type="text"><![CDATA[Framework 应聘架构师，面试最容易被问啥？ 微服务注册中心Nacos Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 Spring Cloud Alibaba系列教程-03-搭建生产可用的Nacos集群 熔断限流Spring Cloud Alibaba Sentinel Spring Cloud Alibaba基础教程：使用Sentinel实现接口限流 Sentinel Client: 整合Apollo规则持久化 分布式事务Seata 开发者说：深度剖析开源分布式事务方案 Seata 的事务协调器 其它Spring Cloud Bus 干货｜Spring Cloud Bus 消息总线介绍 Spring Cloud Stream 干货｜Spring Cloud Stream 体系及原理介绍 Service MeshIstio 什么是 istio Component消息队列RocketMQ 从RocketMQ我们学到了什么？（NameServer篇） 实践 到底什么时候该使用MQ？ 数据库MySql 抱歉，没早点把这么全面的InnoDB锁机制发给你 Favorites架构师之路（58沈剑） 架构师之路18年精选100篇]]></content>
      <categories>
        <category>收藏</category>
      </categories>
      <tags>
        <tag>收藏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用skywalking做分布式系统链路监控]]></title>
    <url>%2F2019%2F04%2F12%2Fmicro-service%2Fapm%2F%E4%BD%BF%E7%94%A8skywalking%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E9%93%BE%E8%B7%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[版本： skywalking：6.0.0-GA elasticsearch：6.5.4 rocketbot：最新（master分支）2019.04.12 skywalking官网 skywalking 可以使用 H2、elasticsearch、MySql做为数据存储，推荐使用 elasticsearch 网上有相关的 docker-compose （参考），但是只有 5.0.0 版本的 Install安装 elasticsearch本次安装的版本：6.5.4（单机部署），使用 docker 安装 skywalking 6.0.0-GA 支持 6.x 版本以上 elasticsearch（用过 5.x 版本，安装失败，未使用 7.x 版本） 官方安装文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 12docker pull elasticsearch:6.5.4docker run -p 9200:9200 -p 9300:9300 -v esdata:/usr/share/elasticsearch/data -d --name es 93109ce1d590 docker images： 1elasticsearch 6.5.4 93109ce1d590 3 months ago 774MB 设置阿里镜像，不然很慢 安装 skywalkingskywalking 使用本地单机方式安装 下载在 apache 官网下载：https://www.apache.org/dyn/closer.cgi/incubator/skywalking/6.0.0-GA/apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 传至服务器并解压： 1tar -zxvf apache-skywalking-apm-incubating-6.0.0-GA.tar.gz 配置配置 ./config/application.yml 设置地址信息和TTL信息： 1234567891011121314151617core: default: restHost: 0.0.0.0 restPort: 12800 restContextPath: / gRPCHost: 192.168.173.113 gRPCPort: 11800 downsampling: - Hour - Day - Month # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted. recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:90&#125; # Unit is minute minuteMetricsDataTTL: $&#123;SW_CORE_MINUTE_METRIC_DATA_TTL:90&#125; # Unit is minute hourMetricsDataTTL: $&#123;SW_CORE_HOUR_METRIC_DATA_TTL:36&#125; # Unit is hour dayMetricsDataTTL: $&#123;SW_CORE_DAY_METRIC_DATA_TTL:45&#125; # Unit is day monthMetricsDataTTL: $&#123;SW_CORE_MONTH_METRIC_DATA_TTL:18&#125; # Unit is month 使用 elasticsearch 做为 storage，注释掉默认的 H2 配置 12345678910111213141516171819storage:# h2:# driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125;# url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125;# user: $&#123;SW_STORAGE_H2_USER:sa&#125; elasticsearch: # nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html # Execute the bulk every 2000 requests bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # flush the bulk every 20mb bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 10 seconds whatever the number of requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # the number of concurrent requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; 相关告警规则设置：./config/alarm-settings.yml 启动在 ./bin 目录下，有相关的启动脚本，主要的是： startup.sh 启动 server 和 UI oapService.sh 单独启动 server webappService.sh 单独启动UI Agent官方文档 将 /agent 目录 copy 至需要监控服务的服务器，目录结构： activations config：配置 logs：日志 optional-plugins：可选插件 plugins：启用的插件 skywalking-agent.jar：执行jar文件 配置配置文件：./config/agent.config 123456# 配置应用的名称 The service name in UIagent.service_name=$&#123;SW_AGENT_NAME:Your_ApplicationName&#125;# 配置server collector地址collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.173.113:11800&#125;# 日志级别logging.level=$&#123;SW_LOGGING_LEVEL:DEBUG&#125; 启动这里使用的是用 jar 启动的方式（tomcat war启动的方式见官方文档） 在 java -jar 中增加 skywalking agent 参数（必须在 -jar 前面）: 1java -javaagent:/home/wl/skywalking-agent/skywalking-agent.jar -DSW_AGENT_NAME=xxx -jar xxx.jar 安装 Rocketbot由于 skywalking 自带的UI不是特别友好，这里选择使用 Rocketbot GitHub地址：https://github.com/TinyAllen/rocketbot 这里使用的是 docker 安装的方式，按照 GitHub 的教程安装即可（此次安装由于 Rocketbot 的 shell 脚本问题，搞的久了点） 按照步骤： 1234npm installnpm run builddocker build -t rocketbot .docker run -p 8080:80 -d -e SKYWALKING_URL=192.168.173.113:12800 rocketbot 注意：在 docker run 的时候，由于 rockerbot 容器中没有 skywalking，指定的 SKYWALKING_URL 必须是ip地址 相关参考 elasticsearch 官网 skywalking 官网 APM巅峰对决：skywalking P.K. Pinpoint]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>skywalking</tag>
        <tag>APM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos版本迭代整理（持续更新）]]></title>
    <url>%2F2019%2F03%2F07%2Fmicro-service%2Fnacos%E7%89%88%E6%9C%AC%E8%BF%AD%E4%BB%A3%E6%95%B4%E7%90%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[官方文档：https://nacos.io/zh-cn/index.html 官方博客：https://nacos.io/zh-cn/blog/index.html 核心功能： 注册中心 配置中心 nacos服务监控：https://nacos.io/zh-cn/docs/monitor-guide.html 0.9.0发布时间：2019.2.28 Nacos 0.9.0 发布，稳定的快速迭代 Nacos 0.9.0版本发布啦 更新内容： Nacos-Sync稳定性提升 Nacos Server功能拆分部署（通过启动参数实现拆分部署） 启动Nacos server时候，增加-f参数，意思是function mode，和对应模块标示来进行启动，如果不穿，或者传入有误，都将启动全部功能。 配置中心参数对应config，注册中心参数对应naming Nacos python语言体系的支持 1.0.0发布时间：2019.4.10 Nacos 发布 1.0.0 GA 版本，可大规模投入到生产环境 相关博客 阿里巴巴基于 Nacos 实现环境隔离的实践 2019.3.13]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nacos做为注册中心]]></title>
    <url>%2F2019%2F03%2F06%2Fmicro-service%2Fnacos%E5%81%9A%E4%B8%BA%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[Nacos 是一个更易于帮助构建云原生应用的动态服务发现、配置和服务管理平台，提供「注册中心」、「配置中心」和「动态DNS服务」三大功能。 使用的相关版本： nacos server：0.9.0 nacos client：0.9.1 spring boot：1.5.17.RELEASE spring cloud：Edgware.SR4 spring-cloud-starter-alibaba-nacos-discovery：0.1.1.RELEASE（对应spring boot 1.x版本） nacos官方文档：https://nacos.io 部署nacos server，按照官方文档部署就行（分为单机部署和集群部署，两者的启动方式稍有不同），现已支持拆分部署 下面介绍的是和spring cloud做集成 相关对比 比较点 Eureka Zookeeper Consul Nacos 运维熟悉度 相对陌生 熟悉 更陌生 陌生 一致性（CAP） AP CP AP AP 一致性协议 HTTP 定时轮训 ZAB RAFT ～ 通讯方式 HTTP REST 自定义协议 HTTP REST ～ 更新机制 Peer 2 Peer（服务器之间） + Scheduler（服务器和客户端） ZK Watch Agent 监听的方式 ～ 适用规模 &lt; 30K &lt;20K &lt;5K 100K+ 性能问题 简单的更新机制、复杂设计、规模较大时 GC 频繁 扩容麻烦、规模较大时 GC 频繁 3K 节点以上，更新列表缓慢 刚开源 dashboard 有 没有，可以自己实现 有 有 各自缺点： Eureka： 客户端注册服务上报所有信息，节点多的情况下，网络，服务端压力过大，且浪费内存 客户端更新服务信息通过简单的轮询机制，当服务数量巨大时，服务器压力过大。 集群伸缩性不强，服务端集群通过广播式的复制，增加服务器压力 Eureka2.0 闭源（Spring Cloud最新版本还是使用的1.X版本的Eureka） Zookeeper： 维护成本较高，客户端，session状态，网络故障等问题，会导致服务异常 集群伸缩性限制，内存，GC和连接 主节点挂的情况下，会进行leader选举，在此过程中服务将不可用 无控制台管理 Consul： 未经大规模市场验证，无法保证可靠性 Go语言编写，内部异常排查困难 Nacos： 刚刚开源不久，社区热度不够，依然存在bug 上面对比摘自与 小马哥技术周报 简单使用加入依赖： 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;!-- spring boot 1.x使用0.1.x版本，spring boot 2.x使用0.2.x版本 --&gt; &lt;version&gt;0.1.1.RELEASE&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 这里需要替换 nacos-client 版本 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt; &lt;artifactId&gt;nacos-client&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt; 注意点： spring-cloud-starter-alibaba-nacos-discovery 依赖的版本和 spring boot 版本有关 spring-cloud-starter-alibaba-nacos-discovery 默认使用的 nacos-client 的版本较低，会有问题（比如namespace设置无效），这里替换了较高的版本 application.properties： 123456spring.application.name=nacos-testserver.port=8525# nacos server地址spring.cloud.nacos.discovery.server-addr=192.168.173.80:8848# namespace idspring.cloud.nacos.discovery.namespace=077d70f7-e430-4b4c-926a-44a9bfef003c 其它配置可以参考官网 注意：这里设置的namespace是界面上显示的id，不设置会进入public默认的命名空间 namespace：常用场景之一是不同环境的注册的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等 启动服务：]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>nacos</tag>
        <tag>微服务</tag>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java拦截器（interceptor）和过滤器（filter）]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E6%8B%A6%E6%88%AA%E5%99%A8%EF%BC%88interceptor%EF%BC%89%E5%92%8C%E8%BF%87%E6%BB%A4%E5%99%A8%EF%BC%88filter%EF%BC%89%2F</url>
    <content type="text"><![CDATA[从概念上来讲，filter是servlet规范定义的，而interceptor是spring定义的 过滤器和拦截器在对请求进行拦截时： 发生的时机不一样，filter是在servlet容器外，interceptor在servlet容器内，且可以对请求的3个关键步骤进行拦截处理 另外filter在过滤是只能对request和response进行操作，而interceptor可以对request、response、handler、modelAndView、exception进行操作。 相关DEMO： 过滤器（Filter）：12345678910111213141516171819202122232425262728293031323334353637383940@Component@WebFilter(filterName = "urlFilter", urlPatterns = "/test")// 配置拦截路径public class UrlFilter implements Filter &#123; /** * filter初始化的时候调用，即web容器启动时调用 * web容器启动时根据web.xml文件，依次加载ServletContext -&gt; listener -&gt; filter -&gt; servlet * * @param filterConfig * @throws ServletException */ @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println("UrlFilter init..."); &#125; /** * filter执行功能，根据参数来看，可以对request,response和chain（是否放行）进行操作 * * @param request * @param response * @param chain * @throws IOException * @throws ServletException */ @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; System.out.println("UrlFilter doFilter before..."); chain.doFilter(request, response); System.out.println("UrlFilter doFilter after..."); &#125; /** * filter在服务器正常关闭(比如System.exit(0))等情况下会调用 */ @Override public void destroy() &#123; System.out.println("UrlFilter destroy..."); &#125;&#125; 拦截器（Interceptor）12345678910111213141516171819@Componentpublic class UrlInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("UrlInterceptor preHandle..."); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("UrlInterceptor postHandle..."); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("UrlInterceptor afterCompletion..."); &#125;&#125; 注册拦截器：1234567891011@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Autowired private UrlInterceptor urlInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(urlInterceptor).addPathPatterns("/test"); &#125;&#125; 执行结果分析 这里用的是spring boot来搭建并启动web服务（使用spring boot bean的方式配置） 123456789@RestControllerpublic class TestController &#123; @GetMapping(value = "/test") public String test() &#123; System.out.println("do test..."); return "ok"; &#125;&#125; 访问该api打印日志：123456UrlFilter doFilter before...UrlInterceptor preHandle...do test...UrlInterceptor postHandle...UrlInterceptor afterCompletion...UrlFilter doFilter after... 相关博客文章： https://blog.csdn.net/dshf_1/article/details/81112595]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java各版本异步并发编程]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%2Fjava%E5%90%84%E7%89%88%E6%9C%AC%E5%BC%82%E6%AD%A5%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[所谓异步调用其实就是实现一个可无需等待被调用函数的返回值而让操作继续运行的方法。在 Java 语言中，简单的讲就是另启一个线程来完成调用中的部分计算，使调用继续运行或返回，而不需要等待计算结果 java5之前在java5之前，主要通过 Thread 或者实现 Runnable 来创建线程，可以通过 Thread 的一些方法来控制线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ThreadDemo &#123; public static void main(String[] args) &#123; normalThread(); completableThread(); &#125; /** * 普通线程 */ private static void normalThread() &#123; Thread thread = new Thread(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()), "Sub"); thread.start(); System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); &#125; /** * 获取线程是否已经完成 * 在获取 completableRunnable.isCompleted() 值时并不一定是true * 我们会想到可见性的问题，所以在 completed 字段加上 volatile 关键字 * 但是还是会出现上面的问题，这里涉及到线程的执行顺序，当Sub线程还未执行到 completed = true; 时，主线程已经执行完了 * 要解决这个问题需要使用 thread.join() 方法，主线程等待Sub线程执行完成 */ private static void completableThread() &#123; CompletableRunnable completableRunnable = new CompletableRunnable(); Thread thread = new Thread(completableRunnable, "Sub"); thread.start();// try &#123;// thread.join();// &#125; catch (InterruptedException e) &#123;// e.printStackTrace();// &#125; System.out.printf("[Thread : %s]Starting...\n", Thread.currentThread().getName()); System.out.printf("runnable is completed : " + completableRunnable.isCompleted()); &#125; /** * 可完成的 */ private static class CompletableRunnable implements Runnable&#123; private boolean completed = false; @Override public void run() &#123; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName()); completed = true; &#125; public boolean isCompleted() &#123; return completed; &#125; &#125;&#125; java5之前实现的局限性： 缺少线程管理的原生支持（没有线程池） 缺少”锁”的api（缺少Lock这样的api） 缺少执行完成的原生支持 执行结果获取困难 java5线程池java5增加了线程池，由 Doug Lea 编写 12345678910111213public class ExecutorDemo &#123; public static void main(String[] args) &#123; // 执行器服务，线程池 ThreadPoolExecutor 是它的一种实现 ExecutorService executor = Executors.newFixedThreadPool(1); executor.execute(() -&gt; System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName())); // 合理的关闭线程池是非常重要的 executor.shutdown(); &#125;&#125; Future增加了 Future，提供了可以获取执行结果的方法（Callable是有返回值操作，相对于Runnable） 12345678910111213141516171819202122232425public class FutureDemo &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(1); Future&lt;String&gt; future = executorService.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return "[Thread : " + Thread.currentThread().getName() + "]Hello World..."; &#125; &#125;); // 可以知道该线程是否执行完成// future.isDone(); try &#123; String v = future.get(); System.out.println(v); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; executorService.shutdown(); &#125;&#125; Future的限制： 无法手动完成 阻塞式结果返回 future.get() 无法链式调用多个Future，从 ExecutorService#invokeAll 方法中只能返回Future的集合 无法合并多个Future的结果，从 ExecutorService#invokeAll 方法中只能返回Future的集合 java7Fork/JoinForkJoin是Java7提供的原生多线程并行处理框架，其基本思想是将大人物分割成小任务，最后将小任务聚合起来得到结果。 它非常类似于HADOOP提供的MapReduce框架，只是MapReduce的任务可以针对集群内的所有计算节点，可以充分利用集群的能力完成计算任务。ForkJoin更加类似于单机版的MapReduce Fork/Join使用两个类完成以上两件事情： ForkJoinTask： 我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join的操作机制，通常我们不直接继承ForkjoinTask类，只需要直接继承其子类。 RecursiveAction，用于没有返回结果的任务 RecursiveTask，用于有返回值的任务 ForkJoinPool： task要通过ForkJoinPool来执行，分割的子任务也会添加到当前工作线程的双端队列中，进入队列的头部。当一个工作线程中没有任务时，会从其他工作线程的队列尾部获取一个任务。 计算整数之和 DEMO：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ForkJoinDemo &#123; public static void main(String[] args) &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); LongAccumulator accumulator = new LongAccumulator(((left, right) -&gt; left + right), 0); List&lt;Long&gt; params = new ArrayList&lt;&gt;(); for (long i = 0; i &lt; 10000000; i++) &#123; params.add(i); &#125; long start = System.currentTimeMillis(); forkJoinPool.invoke(new LongSumTask(params, accumulator)); long end = System.currentTimeMillis(); System.out.println(accumulator.get()); System.out.printf("消耗时间：%d %s\n", end - start, "ms"); forkJoinPool.shutdown(); &#125; static class LongSumTask extends RecursiveAction &#123; private final List&lt;Long&gt; elements; private final LongAccumulator accumulator; LongSumTask(List&lt;Long&gt; elements, LongAccumulator accumulator) &#123; this.elements = elements; this.accumulator = accumulator; &#125; @Override public void compute() &#123; int size = elements.size(); int parts = size / 2; // 使用简单的二分法，将计算平分，当元素只有一个的时候使用 LongAccumulator 进行累加计算 if (size &gt; 1) &#123; List&lt;Long&gt; left = elements.subList(0, parts); List&lt;Long&gt; right = elements.subList(parts, size); new LongSumTask(left, accumulator).fork().join(); new LongSumTask(right, accumulator).fork().join(); &#125; else &#123; if (elements.isEmpty()) &#123; return; &#125; Long num = elements.get(0); accumulator.accumulate(num); &#125; &#125; &#125;&#125; java8CompletableFuture在Java8中，CompletableFuture 提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法 CompletableFuture 实现了 Future 和 CompletionStage123public class CompletableFuture&lt;T&gt; implements Future&lt;T&gt;, CompletionStage&lt;T&gt; &#123; // ...&#125; 相关的操作可以查看官方API或者相关博客 DEMO：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class CompletableFutureDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 1. 完成操作（可以被其它线程去做）// CompletableFuture&lt;String&gt; completableFuture = new CompletableFuture&lt;&gt;();// completableFuture.complete("Hello World");// String v = completableFuture.get();// System.out.println(v); // 2. runAsync 异步执行，阻塞操作// CompletableFuture asyncCompletableFuture = CompletableFuture.runAsync(() -&gt; &#123;// System.out.printf("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// // 这里仍然是阻塞的// asyncCompletableFuture.get();//// System.out.println("Starting..."); // 3. supplyAsync 异步执行，阻塞操作// CompletableFuture&lt;String&gt; asyncCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123;// // 获取数据操作，比如来自于数据库// return String.format("[Thread : %s]Hello World...\n", Thread.currentThread().getName());// &#125;);//// String v = asyncCompletableFuture.get();// System.out.println(v);// System.out.println("Starting..."); // 4. 合并操作 CompletableFuture&lt;String&gt; combinedCompletableFuture = CompletableFuture.supplyAsync(() -&gt; &#123; // 获取数据操作，比如来自于数据库 return String.format("[Thread : %s]Hello World...", Thread.currentThread().getName()); &#125;).thenApply(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " - 来自于数据库"; &#125;).thenApplyAsync(value -&gt; &#123; System.out.printf("current thread : %s\n", Thread.currentThread().getName()); return value + " at " + LocalDate.now(); &#125;).exceptionally(e -&gt; &#123; // 异常处理 e.printStackTrace(); return ""; &#125;); while (!combinedCompletableFuture.isDone()) &#123; &#125; String v = combinedCompletableFuture.get(); System.out.println(v); System.out.println("Starting..."); &#125;&#125; 事实上，如果每个操作都很简单的话，没有必要用这种多线程异步的方式，因为创建线程还需要时间，还不如直接同步执行来得快。 事实证明，只有当每个操作很复杂需要花费相对很长的时间（比如，调用多个其它的系统的接口）的时候用 CompletableFuture 才合适，不然区别真的不大，还不如顺序同步执行。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在sonarqube的pmd插件中整合阿里p3c开发规范]]></title>
    <url>%2F2019%2F02%2F28%2Fdevops%2F%E5%A6%82%E4%BD%95%E5%9C%A8sonarqube%E7%9A%84pmd%E6%8F%92%E4%BB%B6%E4%B8%AD%E6%95%B4%E5%90%88%E9%98%BF%E9%87%8Cp3c%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[sonar-pmd是sonar官方的支持pmd的插件，但是还不支持p3c，需要在pmd插件源码中添加p3c支持(p3c是阿里在pmd基础上根据阿里巴巴开发手册实现了其中的49开发规则) 插件源码下载地址：https://github.com/mrprince/sonar-p3c-pmd 阿里p3c github：https://github.com/alibaba/p3c 此次使用的sonar版本：6.5 此源码工程已经添加了P3C支持：12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.p3c&lt;/groupId&gt; &lt;artifactId&gt;p3c-pmd&lt;/artifactId&gt; &lt;version&gt;1.3.4&lt;/version&gt;&lt;/dependency&gt; 在这个PMD插件中，已经在默认的268条规则上增加了48条阿里代码规则 修改PMD插件源码相关文件： pmd.properties (src/main/resources/org/sonar/l10n/pmd.properties) rules-p3c.xml (src/main/resources/org/sonar/plugins/pmd/rules-p3c.xml) pmd-model.xml (src/main/resources/com/sonar/sqale/pmd-model.xml) 增加规则该规范中少了一条 AvoidManuallyCreateThreadRule 规则，以添加该规则为例子 在 pmd.properties 中增加规则名称：1rule.pmd.AvoidManuallyCreateThreadRule.name=[p3c]avoid manually create thread. 在 rules-p3c.xml 中增加对应的p3c规则：1234&lt;rule key="AvoidManuallyCreateThreadRule"&gt; &lt;priority&gt;MAJOR&lt;/priority&gt; &lt;configKey&gt;&lt;![CDATA[rulesets/java/ali-concurrent.xml/AvoidManuallyCreateThreadRule]]&gt;&lt;/configKey&gt;&lt;/rule&gt; 在 pmd-model.xml 增加：12345678910111213&lt;chc&gt; &lt;rule-repo&gt;pmd&lt;/rule-repo&gt; &lt;rule-key&gt;AvoidManuallyCreateThreadRule&lt;/rule-key&gt; &lt;prop&gt; &lt;key&gt;remediationFunction&lt;/key&gt; &lt;txt&gt;CONSTANT_ISSUE&lt;/txt&gt; &lt;/prop&gt; &lt;prop&gt; &lt;key&gt;offset&lt;/key&gt; &lt;val&gt;2&lt;/val&gt; &lt;txt&gt;min&lt;/txt&gt; &lt;/prop&gt;&lt;/chc&gt; 在 src/main/resources/org/sonar/l10n/pmd/rules/pmd-p3c 包中增加相关sonar举例（必须增加，不然测试用例跑不通）：12345&lt;p&gt;Look for qualified this usages in the same class.&lt;/p&gt;&lt;p&gt;Examples:&lt;/p&gt;&lt;pre&gt; // 新增规则，没有示例&lt;/pre&gt; 如果要删除规则，按照上面的方式删除即可 其它设置修改p3c提示语可以下载阿里p3c源码，源码地址：https://github.com/alibaba/p3c 描述内容都在 p3c/p3c-pmd/src/main/resources/messages.xml 文件中，修改其中的描述内容即可 然后将其maven打包（可以deploy在公司的私有仓库中） 修改pmd插件在sonarqube中的插件显示名可以修改 sonar-p3c-pmd 工程中的 PmdConstants 类 REPOSITORY_NAME 值即可 sonar配置整合插件将 sonar-p3c-pmd 插件通过maven打包，然后将打好的jar包放在sonar目录下的 extensions/plugins 目录中 重启 sonar 服务，通过 ./bin/linux-x86-64/sonar.sh restart 命令 查看插件是否安装正确（如果sonar启动失败，表示插件有问题） 创建质量配置在质量配置页面中，创建一个java规则 创建完成以后，进行激活规则操作，在资源库中找到上传的插件进行激活相关p3c规则 在项目中配置对应的质量规则即可]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
        <tag>sonar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql配置优化]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[参数作用域 全局参数（global）： 1set global autocommit = ON/OFF; 会话参数（session），会话参数不单独设置则会采用全局参数： 1set session autocommit = ON/OFF; 注意点： 全局参数的设定对于已经存在的会话无法生效（需要重新开启会话） 会话参数的设定随着会话的销毁而失效 全局类的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效 配置文件mysql --help 寻找配置文件的位置和加载顺序： 12Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf 因为参数比较多，可以通过命令过滤： 1mysql --help | grep -A 1 &apos;Default options are read from the following files in the given order&apos; 连接数配置设置 max_connections 可配置最大连接数，mysql5.6 默认是151个连接： 12345+--------------------+-------+| Variable_name | Value |+--------------------+-------+| max_connections | 151 |+--------------------+-------+ 这个设置受其它两个配置影响： 系统句柄数配置 使用 ulimit -a 或者查看 /etc/security/limits.conf 配置文件 1open files (-n) 65535 mysql句柄数配置 查看 /usr/lib/systemd/system/mysqld.service 配置文件 1LimitNOFILE = 6000 内存参数配置 sort_buffer_size connection 排序缓冲区大小 当查询语句中有需要文件排序功能时，马上为 connection 分配配置的内存大小，建议256K（默认值）～ 2M之内 join_buffer_size connection关联查询缓冲区大小 当查询语句中有关联查询时，马上分配配置大小的内存用这个关联查询，所以有可能在一个查询语句中会分配很多个关联查询缓冲区 ，建议256K（默认值）～1M之间 Innodb_buffer_pool_size innodb buffer/cache 的大小（默认128M） innodb buffer/cache中存着数据缓存、索引缓存、缓冲数据、内部结构这些数据，所以大的缓冲池可以减小多次磁盘I/O访问相同的表数据以提高性能 计算公式： 1Innodb_buffer_pool_size = (总物理内存 - 系统运行所用 - connection 所用) * 90% 其它参数配置参考帖子：https://www.cnblogs.com/wyy123/p/6092976.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql MVCC]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-MVCC%2F</url>
    <content type="text"><![CDATA[MVCC：Multiversion concurrency control （多版本并发控制） 并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理。以达到用来避免写操作的堵塞，从而引发读操作的并发问题。 Mysql中MVCC逻辑流程在我们的 mysql 表中，都会有个默认列： DB_TRX_ID：数据行的版本号 DB_ROLL_PT：删除版本号 这些版本号就是事务ID 插入 在数据行版本号中，加入当前的事务ID 删除 在删除版本号中，加入当前的事务ID 这里需要注意的是，虽然数据删除了，但是 mysql 中还是有记录的 修改 修改操作是先做命中的数据行的copy，将原行数据的删除版本号的值设置为当前的事务ID 查询 规则： 查询数据行版本早于当前事务版本的数据行 行的版本号小于或等于事务ID，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的 查找删除版本号为NULL或者大于当前事务版本号的记录 确保取出来的行记录在事务开启之前没有被删除 Mysql中MVCC版本控制案例数据准备： 12insert into teacher(name,age) value (&apos;seven&apos;,18); insert into teacher(name,age) value (&apos;qing&apos;,20); 执行语句： 123456789##### tx1 #####begin; -- 1select * from users ; -- 2commit;##### tx2 #####begin; -- 3update teacher set age =28 where id =1; -- 4commit; 案例一上面的执行语句顺序：1，2，3，4，2 按照MVCC的流程，当update语句还没有提交之前，再去select查询时，还是读到的是之前的数据，符合预期 案例二上看的执行语句顺序：3，4，1，2 这次是先update，然后在select，这里都没有做commit操作，按照MVCC的流程，select读取到了update没有提交的数据，为什么会这样？ 如果按照MVCC流程会有这个问题，但是，在执行update时，会上X锁，这时候select会去做快照读，看下面的分析 Undo log 实现事务的原子性 事务处理过程中如果出现了错误或者用户执行了 ROLLBACK 语句，Mysql可以利用Undo Log中的备份将数据恢复到事务开始之前的状态 在 InnoDB 中用来实现多版本并发控制 事务未提交之前，Undo保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读 快照读： SQL读取的数据是快照版本，也就是历史版本，普通的SELECT就是快照读 InnoDB快照读，数据的读取将由 cache（事务修改过的数据） + undo（原本数据） 两部分组成 当前读： SQL读取的数据是最新版本 通过锁机制来保证读取的数据无法通过其他事务进行修改 UPDATE、DELETE、INSERT、SELECT … LOCK IN SHARE MODE、SELECT … FOR UPDATE都是当前读 Redo logredo log是为了实现事务的持久性 防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的未入磁盘数据进行持久化这一特性 指定redo log记录在 {datadir}/ib_logfile1&amp;ib_logfile2 可通过 innodb_log_group_home_dir 配置指定 目录存储 一旦事务成功提交且数据持久化落盘之后，此时redo log中的对应事务数据记录就失去了意义，所以redo log的写入是日志文件循环写入的 指定redo log日志文件组中的数量 innodb_log_files_in_group 默认为2 指定redo log每一个日志文件最大存储量 innodb_log_file_size 默认48M 指定redo log在 cache/buffer 中的 buffer 池大小 innodb_log_buffer_size 默认16M Redo buffer 持久化Redo log的策略， Innodb_flush_log_at_trx_commit : 取值 0 每秒提交 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（可能丢失一秒内的事务数据） 取值 1 每次事务提交执行 Redo buffer -&gt; Redo log OS cache -&gt; flush cache to disk（默认值，最安全，性能最差的方式） 取值 2 每次事务提交执行 Redo buffer -&gt; Redo log OS cache 再每一秒执行 -&gt; flush cache to disk]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql InnoDB锁机制]]></title>
    <url>%2F2019%2F02%2F28%2Fmysql%2FMysql-InnoDB%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[表锁和行锁锁是用于管理不同事务对共享资源的并发访问 表锁与行锁的区别: 锁定粒度：表锁 &gt; 行锁 加锁效率：表锁 &gt; 行锁 冲突概率：表锁 &gt; 行锁 并发性能：表锁 &lt; 行锁 InnoDB 存储引擎支持行锁和表锁（表锁是通过行锁实现的） InnoDB 锁类型锁类型： 共享锁（行锁）：Shared Locks 排它锁（行锁）：Exclusive Locks 意向共享锁（表锁）：IntentionShared Locks 意向排它锁（表锁）：Intention Exclusive Locks 自增锁：AUTO-INC Locks 行锁的算法： 记录锁 Record Locks 间隙锁 Gap Locks 临键锁 Next-key Locks 共享锁与排他锁共享锁又称为读锁，简称 S锁 ，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改 加锁释锁方式： 12select * from users WHERE id=1 LOCK IN SHARE MODE; commit/rollback; 举个例子： 12345678### session1 ###begin;select * from sys_user where id=1 lock in share mode; # 获取S锁commit;### session2 ###select * from sys_user where id=1; # 可以正常执行update sys_user set name=&apos;k2&apos; where id=1; # 当上面没有commit，该语句将被阻塞 排他锁又称为写锁，简称 X锁 ，排他锁不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的锁（共享锁、排他锁），只有该获取了排他锁的事务是可以对数据行进行读取和修改，（其他事务要读取数据可来自于快照） 加锁释锁方式： 123delete / update / insert 默认加上X锁SELECT * FROM table_name WHERE ... FOR UPDATE;commit/rollback; 例子： 123456789### session1 ###begin;update sys_user set name=&apos;k3&apos; where id=1; # 自动获取X锁commit;### session2 ###select * from sys_user where id=1 for update; # 等待上面commitselect * from sys_user where id=1 lock in share mode; # 等待上面commitselect * from sys_user where id=1; # 没影响 那么 InnoDB 行锁到底锁了什么？InnoDB的行锁是通过给索引上的索引项加锁来实现的 只有通过索引条件进行数据检索，InnoDB才使用行级锁，否则，InnoDB 将使用表锁（锁住索引的所有记录） 所以在执行 delete / update / insert 时，也需要考虑索引，因为没有命中索引会变成表锁 表锁： 1lock tables xx read/write; 意向共享锁与意向排它锁 意向共享锁（IS） 表示事务准备给数据行加入共享锁，即一个数据行加共享锁前必须先取得该表的IS锁 意向排它锁（IX） 表示事务准备给数据行加入排他锁，即一个数据行加排他锁前必须先取得该表的IX锁 简单来说，这两种锁就是一个标志位，在拿锁之前，先要判断IS/IX 意向锁（IS、IX）是 InnoDB 数据操作之前自动加的，不需要用户干预 当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁 自增锁针对自增列自增长的一个特殊的表级别锁 1show variables like &apos;innodb_autoinc_lock_mode&apos;; 默认取值1，代表连续，事务未提交ID永久丢失 记录锁、间隙锁、临键锁临键锁（Next-Key）临键锁是 InnoDB 默认的行锁算法 当sql执行按照索引进行数据的检索时，查询条件为范围查找（between and、&lt;、&gt;等）并有数据命中，则此时sql语句加上的锁为 Next-Key locks，锁住索引的记录 + 区间（左开右闭） 例子： 当数据库里与 id 为1、4、7、10四条数据，那么： 它可以有效的方式幻读 间隙锁（Gap）当sql执行按照索引进行数据的检索时，查询条件的数据不存在，这时sql语句加上的锁即为Gap locks，锁住索引不存在的区间（左开右开） Gap locks只在RR事务隔离级别存在 记录锁（Record）当sql执行按照唯一性（Primary key、Unique key）索引进行数据的检索时，查询条件等值匹配且查询的数据时存在，这时sql语句加上的锁为记录锁，锁住具体的索引项 锁是如何解决事务并发解决脏读 解决不可重复读 解决幻读 死锁当2个或以上事务都在等待对方释放锁，产生循环等待，即形成了死锁 如何解决： 类似的业务逻辑以固定的顺序访问表和行 大事务拆小（大事务更倾向于死锁） 在同一个事务中，尽可能做到一次锁定所需要的所有资源 如果业务允许，可以降低事务隔离级别 为表添加合适的索引（如果不走索引将会为表的每一行记录添加上锁，产生表锁）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql事务]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作，事务是一组不可再分割的操作集合（工作逻辑单元） mysql中如何开启事务： 123begin / start transaction -- 手工commit / rollback -- 事务提交或回滚set session autocommit = on/off; -- 设定事务是否自动开启 事务ACID特性 原子性（Atomicity） 最小的工作单元，整个工作单元要么一起提交成功，要么全部失败回滚 一致性（Consistency） 事务中操作的数据及状态改变是一致的，即写入资料的结果必须完全符合预设的规则，不会因为出现系统意外等原因导致状态的不一致 隔离性（Isolation） 一个事务所操作的数据在提交之前，对其他事务的可见性设定（一般设定为不可见） 持久性（Durability） 事务所做的修改就会永久保存，不会因为系统意外导致数据的丢失 事务并发带来的问题脏读： 不可重复读： 幻读： 事务隔离级别SQL92 ANSI/ISO标准：http://www.contrib.andrew.cmu.edu/~shadow/sql/sql1992.txt 隔离级别 解决问题 说明 Read Uncommitted（未提交读） 未解决并发问题 事务未提交对其他事务也是可见的，产生脏读 Read Committed（提交读） 脏读 一个事务开始之后，只能看到自己提交的事务所做的修改，产生不可重复读 Repeatable Read（可重复读） 不可重复读 在同一个事务中多次读取同样的数据结果是一样的，这种隔离级别未定义解决幻读的问题 Serializable（串行化） ALL 最高的隔离级别，通过强制事务的串行执行 InnoDB对事物隔离级别的支持 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（未提交读） 可能 可能 可能 Read Committed（提交读） 不可能 可能 可能 Repeatable Read（可重复读） 不可能 不可能 对InnoDB不可能 Serializable（串行化） 不可能 不可能 不可能 在 InnoDB 引擎中，默认隔离级别是Repeatable Read（可重复读），也可以防止幻读 隔离级别到底是如何实现的？ 锁、MVVC]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询优化]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Mysql 查询执行路径 Mysql 客户端/服务端通信](#Mysql 客户端/服务端通信) 查询缓存 查询优化处理 查询执行引擎 返回客户端 详解Mysql 客户端/服务端通信Mysql客户端与服务端的通信方式是“半双工” 全双工：双向通信，发送同时也可以接收 半双工：双向通信，同时只能接收或者是发送，无法同时做操作 单工：只能单一方向传送 半双工通信：在任何一个时刻，要么是有服务器向客户端发送数据，要么是客户端向服务端发送数据，这两个动作不能同时发生。所以我们无法也无需将一个消息切成小块进行传输 特点和限制：客户端一旦开始发送消息，另一端要接收完整个消息才能响应。 客户端一旦开始接收数据没法停下来发送指令。 通信查询状态对于一个mysql连接，或者说一个线程，时刻都有一个状态来标识这个连接正在做什么 官方状态全集：https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html 我们可以通过以下命令查看： 12show full processlist;show processlist; 执行结果： 1234567mysql&gt; show processlist;+------+------+-----------+------+---------+------+-------+------------------+| Id | User | Host | db | Command | Time | State | Info |+------+------+-----------+------+---------+------+-------+------------------+| 9543 | root | localhost | NULL | Query | 0 | init | show processlist |+------+------+-----------+------+---------+------+-------+------------------+1 row in set (0.00 sec) 整理常见的状态： 状态 说明 Sleep 线程正在等待客户端发送数据 Query 连接形成正在执行查询 Locked 线程正在等待表锁的释放 Sorting result 线程正在对结果进行排序 Sending data 向请求端发送数据 可以通过 kill {id} 的方式进行杀除连接 查询缓存工作原理： 缓存 SELECT 操作的结果集和SQL语句 新的 SELECT 语句，先去查询缓存，判断是否存在可用的记录集 判断标准： 与缓存的SQL语句是否完全一样（区分大小写） 查看缓存设置通过 show variables like &#39;query_cache%&#39;; 命令查询： 1234567891011mysql&gt; show variables like &apos;query_cache%&apos;;+------------------------------+---------+| Variable_name | Value |+------------------------------+---------+| query_cache_limit | 1048576 || query_cache_min_res_unit | 4096 || query_cache_size | 1048576 || query_cache_type | OFF || query_cache_wlock_invalidate | OFF |+------------------------------+---------+5 rows in set (0.00 sec) query_cache_type 0：不启用查询缓存，默认值 1：启用查询缓存，只要符合查询缓存要求，客户端的查询语句和记录集都可以缓存起来（加上 SQL_NO_CACHE 将不缓存） 2：启用查询缓存，只要查询语句中添加参数 SQL_CACHE ，且符合查询缓存的要求，客户端的查询语句和记录集都可以缓存起来 query_cache_size总的缓存池的大小，允许设置最小值为 40K，默认 1M，推荐设置为 ：32M、64M、128M 超过该大小，会将之前的缓存失效 query_cache_limit限制单次查询，缓存区最大能缓存的查询记录集，默认设置为 1M 查看缓存情况可以通过 show status like &#39;Qcache%&#39;;： 1234567891011121314mysql&gt; show status like &apos;Qcache%&apos;;+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Qcache_free_blocks | 1 || Qcache_free_memory | 1031352 || Qcache_hits | 0 || Qcache_inserts | 0 || Qcache_lowmem_prunes | 0 || Qcache_not_cached | 150 || Qcache_queries_in_cache | 0 || Qcache_total_blocks | 1 |+-------------------------+---------+8 rows in set (0.00 sec) 不会缓存的情况 当查询语句中有一些不确定的数据时，则不会被缓存 如包含函数 NOW() 、CURRENT_DATE() 等类似的函数，或者用户自定义的函数，存储函数，用户变量等都不会被缓存 当查询的结构大于 query_cache_limit 设置的值时 对于 InnoDB 引擎来说，当一个语句在事务中修改了某个表，那么在这个事务提交之后，所有与这个表相关的查询都无法被缓存 update table set name=’hello’ where id=3; 查询的表是系统表 查询语句不涉及到表 select 1; 为什么Mysql默认关闭了缓存 在查询之前必须先检查是否命中缓存，浪费计算资源 如果这个查询可以缓存，那么执行完成后，Mysql发现查询缓存中没有这个查询，则会将结构存入查询缓存，带来额外的系统消耗 针对表进行写入或更新操作时，将对应表的所有缓存都设置失效 如果查询缓存很大或者碎片很多时，这个操作可能带来很大的系统消耗 适用场景： 以读为主的业务，数据生成之后就不常改变的业务 查询优化处理查询优化处理的三个阶段： 解析sql 通过lex词法分析，yacc语法分析将sql语句解析成解析树（Yacc 与 Lex语法教程） 预处理阶段 根据mysql的语法的规则进一步检查解析树的合法性，如：检查数据的表和列是否存在，解析名字和别名的设置。还会进行权限的验证 查询优化器 优化器的主要作用就是找到最优的执行计划 解析sql和预处理阶段主要是解析和校验的一个过程，我们重点来讲下查询优化器 查询优化器如何找到最优执行计划Mysql的查询优化器是基于成本计算的原则。他会尝试各种执行计划。 数据抽样的方式进行试验（随机的读取一个4K的数据块进行分析） 使用等价变化规则 5=5 and a&gt;5 改写成 a&gt;5 a5 and a=5 基于联合索引，调整条件位置 … 优化count 、min、max等函数 min函数只需找索引最左边 ，max函数只需要索引最右边 myisam引擎 count(*) 无需遍历全表 覆盖索引扫描 子查询优化 提前终止查询 用了limit关键字或者使用不存在的条件 IN的优化 先进性排序，再采用二分查找的方式（所以尽量使用 in ，而少用 or ） …… 执行计划使用 EXPLAIN ： 12345678910111213mysql&gt; explain select * from table01 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: table01 type: systempossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 0 Extra: const row not found1 row in set (0.00 sec) idselect查询的序列号，标识执行的顺序 id相同，执行顺序由上至下 id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 id相同又不同即两种情况同时存在，id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 select_type查询的类型，主要是用于区分普通查询、联合查询、子查询等 SIMPLE：简单的 select 查询，查询中不包含子查询或者 union PRIMARY：查询中包含子部分，最外层查询则被标记为 primary SUBQUERY/MATERIALIZED：SUBQUERY 表示在 select 或 where 列表中包含了子查询，MATERIALIZED 表示 where 后面 in 条件的子查询 UNION：若第二个 select 出现在 union 之后，则被标记为 union UNION RESULT：从union表获取结果的select table查询涉及到的表 直接显示表名或者表的别名 &lt;unionM,N&gt; 由ID为M,N 查询 union 产生的结果 由ID为N查询生产的结果 type访问类型，sql查询优化中一个很重要的指标，结果值从好到坏依次是： 1system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL system：表只有一行记录（等于系统表），const 类型的特例，基本不会出现，可以忽略不计 const：表示通过索引一次就找到了，const 用于比较 primary key 或者 unique 索引 eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键 或 唯一索引扫描 ref：非唯一性索引扫描，返回匹配某个单独值的所有行，本质是也是一种索引访问 range：只检索给定范围的行，使用一个索引来选择行 index：Full Index Scan，索引全表扫描，把索引从头到尾扫一遍 ALL：Full Table Scan，遍历全表以找到匹配的行 在实际应用中，尽量要在 range 级别以上 possible_keys查询过程中有可能用到的索引 key实际使用的索引，如果为NULL，则没有使用索引 rows根据表统计信息或者索引选用情况，大致估算出找到所需的记录所需要读取的行数 filtered它指返回结果的行占需要读到的行（rows列的值）的百分比 表示返回结果的行数占需读取行数的百分比，filtered的值越大越好 Extra十分重要的额外信息 Using filesort：mysql对数据使用一个外部的文件内容进行了排序，而不是按照表内的索引进行排序读取 Using temporary：使用临时表保存中间结果，也就是说mysql在对查询结果排序时使用了临时表，常见于order by 或 group by Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免了访问表的数据行，效率高 Using where：使用了where过滤条件 select tables optimized away：基于索引优化MIN/MAX操作或者MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段在进行计算，查询执行计划生成的阶段即可完成优化 查询执行引擎调用插件式的存储引擎的原子API的功能进行执行计划的执行 返回客户端 有需要做缓存的，执行缓存操作 增量的返回结果：开始生成第一条结果时，mysql就开始往请求方逐步返回数据 好处：mysql服务器无须保存过多的数据，浪费内存。用户体验好，马上就拿到了数据 慢查询分析定位如何定位慢SQL 业务驱动 测试驱动 慢查询日志 前面2种是通过人为的方式来定位，我们主要看下第三种方式 慢查询日志慢查询日志配置通过 show variables like &#39;slow_query_log&#39;; 查看： 1234567mysql&gt; show variables like &apos;slow_query_log&apos;;+----------------+-------+| Variable_name | Value |+----------------+-------+| slow_query_log | OFF |+----------------+-------+1 row in set (0.00 sec) 通过 set global slow_query_log = on 开启日志 查看日志文件地址： 12345678mysql&gt; show variables like &apos;slow_query%&apos;;+---------------------+-------------------------------------------+| Variable_name | Value |+---------------------+-------------------------------------------+| slow_query_log | ON || slow_query_log_file | /var/lib/mysql/instance-dq9parum-slow.log |+---------------------+-------------------------------------------+2 rows in set (0.00 sec) 如上所示，日志地址在 /var/lib/mysql/instance-dq9parum-slow.log 通过 set global log_queries_not_using_indexes = on 设置没有命中索引的需要记录日志 通过 set global long_query_time = 0.1 （单位：秒）设置查询超过多少时间的需要记录日志 慢查询日志分析查看 /var/lib/mysql/instance-dq9parum-slow.log： 12345# Time: 181219 22:39:30# User@Host: root[root] @ [36.22.250.90] Id: 10887# Query_time: 0.000321 Lock_time: 0.000145 Rows_sent: 1 Rows_examined: 2SET timestamp=1545230370;select * from table01 where name in(&apos;name&apos;); Time：日志记录的时间 User@Host：执行的用户及主机 Query_time：查询耗费时间 Lock_time：锁表时间 Rows_sent：发送给请求方的记录条数 Rows_examined：语句扫描的记录条数 SET timestamp：语句执行的时间点 select ….：执行的具体语句 慢查询日志分析工具 mysqldumpslow mysqlsla pt-query-digest]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql存储引擎]]></title>
    <url>%2F2019%2F02%2F27%2Fmysql%2FMysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言介绍 插拔式的插件方式 存储引擎是指定在表之上的，即一个库中的每一个表都可以指定专用的存储引擎 不管表采用什么样的存储引擎，都会在数据区，产生对应的一个frm文件（表结构定义描述文件） 1-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user.frm 各存储引擎对比查看官网：https://dev.mysql.com/doc/refman/5.7/en/storage-engines.html CSV 存储引擎数据存储以CSV文件： 1-rw-rw---- 1 mysql mysql 0 12月 18 19:27 table_csv.CSV 看其文件内容： 121,&quot;chen&quot;2,&quot;jian&quot; 存储的就是我们的表数据 特点： 不能定义索引、列定义必须为NOT NULL、不能设置自增列 不适用大表或者数据的在线处理 CSV数据的存储用 , 隔开，可直接编辑CSV文件进行数据的编排 数据安全性低（编辑之后，要生效使用flush table XXX 命令） 应用场景： 数据的快速导出导入 表格直接转换成CSV Archive 存储引擎压缩协议进行数据的存储，数据存储为 ARZ 文件格式 1-rw-rw---- 1 mysql mysql 8674 12月 18 19:40 table_archive.ARZ 特点： 只支持 insert 和 select 两种操作 只允许自增ID列建立索引 行级锁 不支持事务 数据占用磁盘少 应用场景： 日志系统 大量的设备数据采集 Memory 存储引擎数据都是存储在内存中，IO效率要比其他引擎高很多，服务重启数据丢失，内存数据表默认只有16M 特点： 支持hash索引，B tree索引，默认hash（查找复杂度 0(1) ） 字段长度都是固定长度 varchar(32)=char(32) 不支持大数据存储类型字段如 blog ，text 表级锁 应用场景： 等值查找热度较高数据 查询结果内存中的计算，大多数都是采用这种存储引擎作为临时表存储需计算的数据 实际应用中不常用 Myisam 存储引擎Mysql5.5 版本之前的默认存储引擎 较多的系统表也还是使用这个存储引擎 系统临时表也会用到 Myisam 存储引擎（Memory 存储引擎不支持的情况下，比如数据超过了16M） 12-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table_myisam.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table_myisam.MYI 特点： select count(*) from table 无需进行数据的扫描（有专门存储） 数据（.MYD）和索引（.MYI）分开存储 表级锁 不支持事务 InnoDB 存储引擎Mysql5.5及以后版本的默认存储引擎 1-rw-rw---- 1 mysql mysql 98304 12月 6 19:00 table_innodb.ibd 特点： 支持事务ACID 行级锁 聚集索引（主键索引）方式进行数据存储 支持外键关系保证数据完整性（尽量不要用）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql索引]]></title>
    <url>%2F2019%2F02%2F26%2Fmysql%2FMysql%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引是为了加速对表中数据行的检索而创建的一种分散存储的数据结构 为什么要用索引： 索引能极大的减少存储引擎需要扫描的数据量 索引可以把随机IO变成顺序IO 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表 Mysql 为什么使用 B+Tree二叉查找树 动画演示 平衡二叉查找树 动画演示 缺点： 太深了 数据处的(高)深度决定着他的IO操作次数，IO操作耗时大 太小了 每一个磁盘块(节点/页)保存的数据量太小了 没有很好的利用操作磁盘IO的数据交换特性 没有利用好磁盘IO的预读能力(空间局部性原理)，从而带来频繁的IO操作 多路平衡查找树动画演示 B-Tree B+Tree B-Tree 和 B+Tree区别 B+节点关键字搜索采用闭合区间 B+非叶节点不保存数据相关信息，只保存关键字和子节点的引用 B+关键字对应的数据保存在叶子节点中 B+叶子节点是顺序排列的，并且相邻节点具有顺序引用的关系 为什么选用 B+Tree B+树是B-树的变种(PLUS版)多路绝对平衡查找树，他拥有B-树的优势 B+树扫库、表能力更强 B+树的磁盘读写能力更强 B+树的排序能力更强 B+树的查询效率更加稳定 Mysql B+Tree 索引体现Myisam Engine 在 Myisam 引擎中，数据库对应的表会有这么几个文件 123-rw-rw---- 1 mysql mysql 8556 12月 18 16:30 table01.frm-rw-rw---- 1 mysql mysql 0 12月 18 16:30 table01.MYD-rw-rw---- 1 mysql mysql 1024 12月 18 16:30 table01.MYI .MYD 文件存储的是具体的数据内容 .MYI 文件存储的是索引树 如上图，在 Myisam 引擎中，索引指向的是数据的地址 Innodb Engine 12-rw-rw---- 1 mysql mysql 8586 12月 6 18:56 sys_user01.frm-rw-rw---- 1 mysql mysql 98304 12月 6 18:56 sys_user01.ibd 在 Innodb 引擎中，只有 .ibd 文件 Innodb 引擎中，它是以主键为索引来组织数据的存储（没有指定主键，它会隐式创建），它的叶子节点存储的是具体的数据 它分为主键索引（聚集索引）和辅助索引（非聚集索引）： 主键索引叶子节点存储具体的数据 辅助索引叶子节点存储主键值 当辅助索引获取到主键值后，再通过主键索引查找到具体的数据 这里会有2个问题： 为什么辅助索引叶子节点不存储主键索引数据的引用呢？ 当数据的引用发生变化时，需要更新所有辅助索引的数据引用 为什么需要主键索引，且都是通过主键索引去查数据 这和 Innodb 的设计初衷有关，它认为主键是最常用的查询条件 索引知识补充列的离散性离散性表示数据重复率 在建索引的时候，离散性越高，选择性就越好，命中索引的概率也就越高 最左匹配原则对索引中关键字进行计算(对比)，一定是从左往右依次进行，且不可跳过 比如说，在我们建标时，会有一个排序规则，通过会设置成 utf8_general_ci，这会把数据转成 ASCII 码： 12abc -&gt; 97 98 99adc -&gt; 97 100 99 联合索引 单列索引 节点中关键字[name] 联合索引 节点中关键字[name,phoneNum] 单列索引是特殊的联合索引 联合索引列选择原则： 经常用的列优先 【最左匹配原则】 选择性(离散度)高的列优先【离散度高原则】 宽度小的列优先【最少空间原则】 例子如下是最常用的sql： 12select * from users where name = ?;select * from users where name = ? and phoneNum = ?; 解决方案，在 name 和 phoneNum 上都建索引： 12create index idx_name on users(name);create index idx_name_phoneNum on users(name,phoneNum); 问题在哪？ 根据最左匹配原则，这两个sql都可以命中第二个索引，所以第一个索引是冗余的 覆盖索引如果查询列可通过索引节点中的关键字直接返回，则该索引称之为覆盖索引，覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能 比如我建了下面这个索引： 1create index idx_name_phoneNum on users(name,phoneNum); 当我们这么查时： 1select name,phoneNum from users where name = ?; 上面的sql只查询 name 和 phoneNum，当命中索引时，不需要到叶子节点获取数据，直接在中间节点就可以把数据直接返回，这就是覆盖索引 总结 索引列的数据长度能少则少 索引一定不是越多越好，越全越好，一定是建合适的 匹配列前缀可用到索引 like 9999%（不一定，要看离散性），like %9999%、like %9999用不到索引 Where 条件中 not in 和 &lt;&gt;操作无法使用索引 匹配范围值，order by 也可用到索引 多用指定列查询，只返回自己想到的数据列，少用select * 联合索引中如果不是按照索引最左列开始查找，无法使用索引 联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引 联合索引中如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>笔记</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用hexo + github pages建立个人博客]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo-github-pages%E5%BB%BA%E7%AB%8B%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 hexo安装hexo官方文档：https://hexo.io/zh-cn/docs/ 按照官网文档安装hexo，安装hexo之前需要先安装 node（推荐使用 nvm 安装） 和 git 基本使用 初始化网站： 12hexo init &lt;dirName&gt; # 也可以新建一个空目录，然后执行 hexo initnpm install # npm安装 生成静态文件： 1hexo g # 或者使用 hexo generate 启动本地服务： 1hexo s # 或者使用 hexo server，然后通过http://127.0.0.1:4000访问 常用命令：1234hexo n == hexo new # 新建文章、页面等hexo g == hexo generate # 生成静态文件hexo s == hexo server # 启动服务hexo d == hexo deploy # 发布 主题官方主题地址：https://hexo.io/themes/ 这里使用的是 next，地址：http://theme-next.iissnan.com/ 只要将主题放到 themes 目录下，然后修改站点配置文件 _config.yml 中的 theme 值即可 具体设置可以参考上面的next文档 使用github部署hexo修改站点配置文件 _config.yml ：1234deploy: type: git repo: git@github.com:cpp288/cpp288.github.io.git #这里的网址填你自己的 branch: master 配置github ssh key： ssh-keygen -t rsa -C &quot;邮件地址@youremail.com&quot; 生成新的key文件，邮箱地址填你的Github地址，后面直接回车进行 将生成的工钥 id_rsa.pub 配置到 github 上 执行 ssh -T git@github.com 如下提示则成功1Hi cpp288! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 安装扩展：1npm install hexo-deployer-git --save 部署到 github：1hexo d 相关问题电脑重装了系统/多台电脑写博客？ 参考博客： https://www.zhihu.com/question/21193762 https://blog.csdn.net/heimu24/article/details/81210640 如何添加本地图片？ 在 source 目录下新建目录，将图片放在其中（可以建多级目录），hexo 会在 generate 时将图片放到 public 中，使用 markdown 图片语法即可 相关博客 我是如何利用Github Pages搭建起我的博客，细数一路的坑 Hexo和Next主题的相关设置（持续更新） 使腾讯404公益页面支持HTTPS 【持续更新】最全Hexo博客搭建+主题优化+插件配置+常用操作+错误分析]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
